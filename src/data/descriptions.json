{
	"XRServer": {
		"brief_description": "Server for AR and VR features.",
		"description": "The AR/VR server is the heart of our Advanced and Virtual Reality solution and handles all the processing."
	},
	"XRPositionalTracker": {
		"brief_description": "A tracked object.",
		"description": "An instance of this object represents a device that is tracked, such as a controller or anchor point. HMDs aren't represented here as they are handled internally.\nAs controllers are turned on and the [XRInterface](../XRInterface) detects them, instances of this object are automatically added to this list of active tracking objects accessible through the [XRServer](../XRServer).\nThe [XRController3D](../XRController3D) and [XRAnchor3D](../XRAnchor3D) both consume objects of this type and should be used in your project. The positional trackers are just under-the-hood objects that make this all work. These are mostly exposed so that GDExtension-based interfaces can interact with them."
	},
	"XRPose": {
		"brief_description": "This object contains all data related to a pose on a tracked object.",
		"description": "XR runtimes often identify multiple locations on devices such as controllers that are spatially tracked.\nOrientation, location, linear velocity and angular velocity are all provided for each pose by the XR runtime. This object contains this state of a pose."
	},
	"XROrigin3D": {
		"brief_description": "The origin point in AR/VR.",
		"description": "This is a special node within the AR/VR system that maps the physical location of the center of our tracking space to the virtual location within our game world.\nThere should be only one of these nodes in your scene and you must have one. All the XRCamera3D, XRController3D and XRAnchor3D nodes should be direct children of this node for spatial tracking to work correctly.\nIt is the position of this node that you update when your character needs to move through your game world while we're not moving in the real world. Movement in the real world is always in relation to this origin point.\nFor example, if your character is driving a car, the XROrigin3D node should be a child node of this car. Or, if you're implementing a teleport system to move your character, you should change the position of this node."
	},
	"XRNode3D": {
		"brief_description": "A spatial node that has its position automatically updated by the [XRServer](../XRServer).",
		"description": "This node can be bound to a specific pose of a [XRPositionalTracker](../XRPositionalTracker) and will automatically have its <a href=\"../Node3D#transform\">Node3D.transform<a> updated by the [XRServer](../XRServer). Nodes of this type must be added as children of the [XROrigin3D](../XROrigin3D) node."
	},
	"XRInterfaceExtension": {
		"brief_description": "Base class for XR interface extensions (plugins).",
		"description": "External XR interface plugins should inherit from this class."
	},
	"XRInterface": {
		"brief_description": "Base class for an XR interface implementation.",
		"description": "This class needs to be implemented to make an AR or VR platform available to Godot and these should be implemented as C++ modules or GDExtension modules. Part of the interface is exposed to GDScript so you can detect, enable and configure an AR or VR platform.\nInterfaces should be written in such a way that simply enabling them will give us a working setup. You can query the available interfaces through [XRServer](../XRServer)."
	},
	"XRController3D": {
		"brief_description": "A spatial node representing a spatially-tracked controller.",
		"description": "This is a helper spatial node that is linked to the tracking of controllers. It also offers several handy passthroughs to the state of buttons and such on the controllers.\nControllers are linked by their ID. You can create controller nodes before the controllers are available. If your game always uses two controllers (one for each hand), you can predefine the controllers with ID 1 and 2; they will become active as soon as the controllers are identified. If you expect additional controllers to be used, you should react to the signals and add XRController3D nodes to your scene.\nThe position of the controller node is automatically updated by the [XRServer](../XRServer). This makes this node ideal to add child nodes to visualize the controller.\nAs many XR runtimes now use a configurable action map all inputs are named."
	},
	"XRCamera3D": {
		"brief_description": "A camera node with a few overrules for AR/VR applied, such as location tracking.",
		"description": "This is a helper spatial node for our camera; note that, if stereoscopic rendering is applicable (VR-HMD), most of the camera properties are ignored, as the HMD information overrides them. The only properties that can be trusted are the near and far planes.\nThe position and orientation of this node is automatically updated by the XR Server to represent the location of the HMD if such tracking is available and can thus be used by game logic. Note that, in contrast to the XR Controller, the render thread has access to the most up-to-date tracking data of the HMD and the location of the XRCamera3D can lag a few milliseconds behind what is used for rendering as a result."
	},
	"XRAnchor3D": {
		"brief_description": "An anchor point in AR space.",
		"description": "The [XRAnchor3D](../XRAnchor3D) point is a spatial node that maps a real world location identified by the AR platform to a position within the game world. For example, as long as plane detection in ARKit is on, ARKit will identify and update the position of planes (tables, floors, etc) and create anchors for them.\nThis node is mapped to one of the anchors through its unique ID. When you receive a signal that a new anchor is available, you should add this node to your scene for that anchor. You can predefine nodes and set the ID; the nodes will simply remain on 0,0,0 until a plane is recognized.\nKeep in mind that, as long as plane detection is enabled, the size, placing and orientation of an anchor will be updated as the detection logic learns more about the real world out there especially if only part of the surface is in view."
	},
	"XMLParser": {
		"brief_description": "Low-level class for creating parsers for [XML](https://en.wikipedia.org/wiki/XML) files.",
		"description": "This class can serve as base to make custom XML parsers. Since XML is a very flexible standard, this interface is low-level so it can be applied to any possible schema."
	},
	"X509Certificate": {
		"brief_description": "An X509 certificate (e.g. for TLS).",
		"description": "The X509Certificate class represents an X509 certificate. Certificates can be loaded and saved like any other [Resource](../Resource).\nThey can be used as the server certificate in <a href=\"../StreamPeerTLS#accept_stream\">StreamPeerTLS.accept_stream<a> (along with the proper [CryptoKey](../CryptoKey)), and to specify the only certificate that should be accepted when connecting to an TLS server via <a href=\"../StreamPeerTLS#connect_to_stream\">StreamPeerTLS.connect_to_stream<a>."
	},
	"WorldEnvironment": {
		"brief_description": "Default environment properties for the entire scene (post-processing effects, lighting and background settings).",
		"description": "The [WorldEnvironment](../WorldEnvironment) node is used to configure the default [Environment](../Environment) for the scene.\nThe parameters defined in the [WorldEnvironment](../WorldEnvironment) can be overridden by an [Environment](../Environment) node set on the current [Camera3D](../Camera3D). Additionally, only one [WorldEnvironment](../WorldEnvironment) may be instantiated in a given scene at a time.\nThe [WorldEnvironment](../WorldEnvironment) allows the user to specify default lighting parameters (e.g. ambient lighting), various post-processing effects (e.g. SSAO, DOF, Tonemapping), and how to draw the background (e.g. solid color, skybox). Usually, these are added in order to improve the realism/color balance of the scene."
	},
	"WorldBoundaryShape3D": {
		"brief_description": "World boundary (infinite plane) shape resource for 3D physics.",
		"description": "3D world boundary shape to be added as a <i>direct</i> child of a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D) using a [CollisionShape3D](../CollisionShape3D) node. [WorldBoundaryShape3D](../WorldBoundaryShape3D) works like an infinite plane and will not allow any physics body to go to the negative side. Note that the [Plane](../Plane)'s normal matters; anything \"below\" the plane will collide with it. If the [WorldBoundaryShape3D](../WorldBoundaryShape3D) is used in a [PhysicsBody3D](../PhysicsBody3D), it will cause colliding objects placed \"below\" it to teleport \"above\" the plane.\n<b>Performance:</b> Being a primitive collision shape, [WorldBoundaryShape3D](../WorldBoundaryShape3D) is fast to check collisions against."
	},
	"WorldBoundaryShape2D": {
		"brief_description": "World boundary (infinite plane) shape resource for 2D physics.",
		"description": "2D world boundary shape to be added as a <i>direct</i> child of a [PhysicsBody2D](../PhysicsBody2D) or [Area2D](../Area2D) using a [CollisionShape2D](../CollisionShape2D) node. [WorldBoundaryShape2D](../WorldBoundaryShape2D) works like an infinite plane and will not allow any physics body to go to the negative side. Note that the <a href=\"#normal\">normal</a> matters; anything \"below\" the plane will collide with it. If the [WorldBoundaryShape2D](../WorldBoundaryShape2D) is used in a [PhysicsBody2D](../PhysicsBody2D), it will cause colliding objects placed \"below\" it to teleport \"above\" the plane.\n<b>Performance:</b> Being a primitive collision shape, [WorldBoundaryShape2D](../WorldBoundaryShape2D) is fast to check collisions against."
	},
	"World3D": {
		"brief_description": "Class that has everything pertaining to a world.",
		"description": "Class that has everything pertaining to a world. A physics space, a visual scenario and a sound space. Node3D nodes register their resources into the current world."
	},
	"World2D": {
		"brief_description": "Class that has everything pertaining to a 2D world.",
		"description": "Class that has everything pertaining to a 2D world. A physics space, a visual scenario and a sound space. 2D nodes register their resources into the current 2D world."
	},
	"WorkerThreadPool": {
		"brief_description": "",
		"description": ""
	},
	"Window": {
		"brief_description": "Base class for all windows.",
		"description": "A node that creates a window. The window can either be a native system window or embedded inside another [Window](../Window) (see <a href=\"../Viewport#gui_embed_subwindows\">Viewport.gui_embed_subwindows<a>).\nAt runtime, [Window](../Window)s will not close automatically when requested. You need to handle it manually using <a href=\"#close_requested\">close_requested</a> (this applies both to clicking close button and clicking outside popup)."
	},
	"WeakRef": {
		"brief_description": "Holds an [Object](../Object), but does not contribute to the reference count if the object is a reference.",
		"description": "A weakref can hold a [RefCounted](../RefCounted), without contributing to the reference counter. A weakref can be created from an [Object](../Object) using [method @GlobalScope.weakref]. If this object is not a reference, weakref still works, however, it does not have any effect on the object. Weakrefs are useful in cases where multiple classes have variables that refer to each other. Without weakrefs, using these classes could lead to memory leaks, since both references keep each other from being released. Making part of the variables a weakref can prevent this cyclic dependency, and allows the references to be released."
	},
	"VSplitContainer": {
		"brief_description": "Vertical split container.",
		"description": "Vertical split container. See [SplitContainer](../SplitContainer). This goes from top to bottom."
	},
	"VSlider": {
		"brief_description": "Vertical slider.",
		"description": "Vertical slider. See [Slider](../Slider). This one goes from bottom (min) to top (max).\n<b>Note:</b> The <a href=\"../Range#changed\">Range.changed<a> and <a href=\"../Range#value_changed\">Range.value_changed<a> signals are part of the [Range](../Range) class which this class inherits from."
	},
	"VSeparator": {
		"brief_description": "Vertical version of [Separator](../Separator).",
		"description": "Vertical version of [Separator](../Separator). Even though it looks vertical, it is used to separate objects horizontally."
	},
	"VScrollBar": {
		"brief_description": "Vertical scroll bar.",
		"description": "Vertical version of [ScrollBar](../ScrollBar), which goes from top (min) to bottom (max)."
	},
	"VoxelGIData": {
		"brief_description": "Contains baked voxel global illumination data for use in a [VoxelGI](../VoxelGI) node.",
		"description": "[VoxelGIData](../VoxelGIData) contains baked voxel global illumination for use in a [VoxelGI](../VoxelGI) node. [VoxelGIData](../VoxelGIData) also offers several properties to adjust the final appearance of the global illumination. These properties can be adjusted at run-time without having to bake the [VoxelGI](../VoxelGI) node again.\n<b>Note:</b> To prevent text-based scene files (<code>.tscn</code>) from growing too much and becoming slow to load and save, always save [VoxelGIData](../VoxelGIData) to an external binary resource file (<code>.res</code>) instead of embedding it within the scene. This can be done by clicking the dropdown arrow next to the [VoxelGIData](../VoxelGIData) resource, choosing <b>Edit</b>, clicking the floppy disk icon at the top of the Inspector then choosing <b>Save As...</b>."
	},
	"VoxelGI": {
		"brief_description": "Real-time global illumination (GI) probe.",
		"description": "[VoxelGI](../VoxelGI)s are used to provide high-quality real-time indirect light and reflections to scenes. They precompute the effect of objects that emit light and the effect of static geometry to simulate the behavior of complex light in real-time. [VoxelGI](../VoxelGI)s need to be baked before having a visible effect. However, once baked, dynamic objects will receive light from them. Furthermore, lights can be fully dynamic or baked.\n<b>Note:</b> [VoxelGI](../VoxelGI) is only supported in the Forward+ rendering method, not Mobile or Compatibility.\n<b>Procedural generation:</b> [VoxelGI](../VoxelGI) can be baked in an exported project, which makes it suitable for procedurally generated or user-built levels as long as all the geometry is generated in advance. For games where geometry is generated at any time during gameplay, SDFGI is more suitable (see <a href=\"../Environment#sdfgi_enabled\">Environment.sdfgi_enabled<a>).\n<b>Performance:</b> [VoxelGI](../VoxelGI) is relatively demanding on the GPU and is not suited to low-end hardware such as integrated graphics (consider [LightmapGI](../LightmapGI) instead). To improve performance, adjust [member ProjectSettings.rendering/global_illumination/voxel_gi/quality] and enable [member ProjectSettings.rendering/global_illumination/gi/use_half_resolution] in the Project Settings. To provide a fallback for low-end hardware, consider adding an option to disable [VoxelGI](../VoxelGI) in your project's options menus. A [VoxelGI](../VoxelGI) node can be disabled by hiding it.\n<b>Note:</b> Meshes should have sufficiently thick walls to avoid light leaks (avoid one-sided walls). For interior levels, enclose your level geometry in a sufficiently large box and bridge the loops to close the mesh. To further prevent light leaks, you can also strategically place temporary [MeshInstance3D](../MeshInstance3D) nodes with their <a href=\"../GeometryInstance3D#gi_mode\">GeometryInstance3D.gi_mode<a> set to <a href=\"../GeometryInstance3D#GI_MODE_STATIC\">GeometryInstance3D.GI_MODE_STATIC<a>. These temporary nodes can then be hidden after baking the [VoxelGI](../VoxelGI) node."
	},
	"VisualShaderNodeVectorRefract": {
		"brief_description": "Returns the vector that points in the direction of refraction. For use within the visual shader graph.",
		"description": "Translated to <code>refract(I, N, eta)</code> in the shader language, where <code>I</code> is the incident vector, <code>N</code> is the normal vector and <code>eta</code> is the ratio of the indices of the refraction."
	},
	"VisualShaderNodeVectorOp": {
		"brief_description": "A vector operator to be used within the visual shader graph.",
		"description": "A visual shader node for use of vector operators. Operates on vector <code>a</code> and vector <code>b</code>."
	},
	"VisualShaderNodeVectorLen": {
		"brief_description": "Returns the length of a [Vector3](../Vector3) within the visual shader graph.",
		"description": "Translated to <code>length(p0)</code> in the shader language."
	},
	"VisualShaderNodeVectorFunc": {
		"brief_description": "A vector function to be used within the visual shader graph.",
		"description": "A visual shader node able to perform different functions using vectors."
	},
	"VisualShaderNodeVectorDistance": {
		"brief_description": "Returns the distance between two points. To be used within the visual shader graph.",
		"description": "Calculates distance from point represented by vector <code>p0</code> to vector <code>p1</code>.\nTranslated to <code>distance(p0, p1)</code> in the shader language."
	},
	"VisualShaderNodeVectorDecompose": {
		"brief_description": "Decomposes a [Vector2](../Vector2), [Vector3](../Vector3) or 4D vector (represented as a [Quaternion](../Quaternion)) into scalars within the visual shader graph.",
		"description": "Takes a <code>vec2</code>, <code>vec3</code> or <code>vec4</code> and decomposes it into scalar values that can be used as separate outputs."
	},
	"VisualShaderNodeVectorCompose": {
		"brief_description": "Composes a [Vector2](../Vector2), [Vector3](../Vector3) or 4D vector (represented as a [Quaternion](../Quaternion)) from scalars within the visual shader graph.",
		"description": "Creates a <code>vec2</code>, <code>vec3</code> or <code>vec4</code> using scalar values that can be provided from separate inputs."
	},
	"VisualShaderNodeVectorBase": {
		"brief_description": "A base type for the nodes that perform vector operations within the visual shader graph.",
		"description": "This is an abstract class. See the derived types for descriptions of the possible operations."
	},
	"VisualShaderNodeVec4Parameter": {
		"brief_description": "A 4D vector parameter to be used within the visual shader graph.",
		"description": "Translated to <code>uniform vec4</code> in the shader language."
	},
	"VisualShaderNodeVec4Constant": {
		"brief_description": "A 4D vector constant to be used within the visual shader graph.",
		"description": "A constant 4D vector, which can be used as an input node."
	},
	"VisualShaderNodeVec3Parameter": {
		"brief_description": "A [Vector3](../Vector3) parameter to be used within the visual shader graph.",
		"description": "Translated to <code>uniform vec3</code> in the shader language."
	},
	"VisualShaderNodeVec3Constant": {
		"brief_description": "A [Vector3](../Vector3) constant to be used within the visual shader graph.",
		"description": "A constant [Vector3](../Vector3), which can be used as an input node."
	},
	"VisualShaderNodeVec2Parameter": {
		"brief_description": "A [Vector2](../Vector2) parameter to be used within the visual shader graph.",
		"description": "Translated to <code>uniform vec2</code> in the shader language."
	},
	"VisualShaderNodeVec2Constant": {
		"brief_description": "A [Vector2](../Vector2) constant to be used within the visual shader graph.",
		"description": "A constant [Vector2](../Vector2), which can be used as an input node."
	},
	"VisualShaderNodeVaryingSetter": {
		"brief_description": "A visual shader node that sets a value of a varying.",
		"description": "Inputs a value to a varying defined in the shader. You need to first create a varying that can be used in the given function, e.g. varying setter in Fragment shader requires a varying with mode set to <a href=\"../VisualShader#VARYING_MODE_FRAG_TO_LIGHT\">VisualShader.VARYING_MODE_FRAG_TO_LIGHT<a>."
	},
	"VisualShaderNodeVaryingGetter": {
		"brief_description": "A visual shader node that gets a value of a varying.",
		"description": "Outputs a value of a varying defined in the shader. You need to first create a varying that can be used in the given function, e.g. varying getter in Fragment shader requires a varying with mode set to <a href=\"../VisualShader#VARYING_MODE_VERTEX_TO_FRAG_LIGHT\">VisualShader.VARYING_MODE_VERTEX_TO_FRAG_LIGHT<a>."
	},
	"VisualShaderNodeVarying": {
		"brief_description": "A visual shader node that represents a \"varying\" shader value.",
		"description": "Varying values are shader variables that can be passed between shader functions, e.g. from Vertex shader to Fragment shader."
	},
	"VisualShaderNodeUVPolarCoord": {
		"brief_description": "A visual shader node that modifies the texture UV using polar coordinates.",
		"description": "UV polar coord node will transform UV values into polar coordinates, with specified scale, zoom strength and repeat parameters. It can be used to create various swirl distortions."
	},
	"VisualShaderNodeUVFunc": {
		"brief_description": "Contains functions to modify texture coordinates (<code>uv</code>) to be used within the visual shader graph.",
		"description": "UV functions are similar to [Vector2](../Vector2) functions, but the input port of this node uses the shader's UV value by default."
	},
	"VisualShaderNodeUIntParameter": {
		"brief_description": "A visual shader node for shader parameter (uniform) of type unsigned [int](../int).",
		"description": "A [VisualShaderNodeParameter](../VisualShaderNodeParameter) of type unsigned [int](../int). Offers additional customization for range of accepted values."
	},
	"VisualShaderNodeUIntOp": {
		"brief_description": "An unsigned integer scalar operator to be used within the visual shader graph.",
		"description": "Applies <a href=\"#operator\">operator</a> to two unsigned integer inputs: <code>a</code> and <code>b</code>."
	},
	"VisualShaderNodeUIntFunc": {
		"brief_description": "An unsigned scalar integer function to be used within the visual shader graph.",
		"description": "Accept an unsigned integer scalar (<code>x</code>) to the input port and transform it according to <a href=\"#function\">function</a>."
	},
	"VisualShaderNodeUIntConstant": {
		"brief_description": "An unsigned scalar integer constant to be used within the visual shader graph.",
		"description": "Translated to <code>uint</code> in the shader language."
	},
	"VisualShaderNodeTransformVecMult": {
		"brief_description": "Multiplies a [Transform3D](../Transform3D) and a [Vector3](../Vector3) within the visual shader graph.",
		"description": "A multiplication operation on a transform (4x4 matrix) and a vector, with support for different multiplication operators."
	},
	"VisualShaderNodeTransformParameter": {
		"brief_description": "A [Transform3D](../Transform3D) parameter for use within the visual shader graph.",
		"description": "Translated to <code>uniform mat4</code> in the shader language."
	},
	"VisualShaderNodeTransformOp": {
		"brief_description": "A [Transform3D](../Transform3D) operator to be used within the visual shader graph.",
		"description": "Applies <a href=\"#operator\">operator</a> to two transform (4x4 matrices) inputs."
	},
	"VisualShaderNodeTransformFunc": {
		"brief_description": "Computes a [Transform3D](../Transform3D) function within the visual shader graph.",
		"description": "Computes an inverse or transpose function on the provided [Transform3D](../Transform3D)."
	},
	"VisualShaderNodeTransformDecompose": {
		"brief_description": "Decomposes a [Transform3D](../Transform3D) into four [Vector3](../Vector3)s within the visual shader graph.",
		"description": "Takes a 4x4 transform matrix and decomposes it into four <code>vec3</code> values, one from each row of the matrix."
	},
	"VisualShaderNodeTransformConstant": {
		"brief_description": "A [Transform3D](../Transform3D) constant for use within the visual shader graph.",
		"description": "A constant [Transform3D](../Transform3D), which can be used as an input node."
	},
	"VisualShaderNodeTransformCompose": {
		"brief_description": "Composes a [Transform3D](../Transform3D) from four [Vector3](../Vector3)s within the visual shader graph.",
		"description": "Creates a 4x4 transform matrix using four vectors of type <code>vec3</code>. Each vector is one row in the matrix and the last column is a <code>vec4(0, 0, 0, 1)</code>."
	},
	"VisualShaderNodeTextureSDFNormal": {
		"brief_description": "Performs an SDF (signed-distance field) normal texture lookup within the visual shader graph.",
		"description": "Translates to <code>texture_sdf_normal(sdf_pos)</code> in the shader language."
	},
	"VisualShaderNodeTextureSDF": {
		"brief_description": "Performs an SDF (signed-distance field) texture lookup within the visual shader graph.",
		"description": "Translates to <code>texture_sdf(sdf_pos)</code> in the shader language."
	},
	"VisualShaderNodeTextureParameterTriplanar": {
		"brief_description": "Performs a uniform texture lookup with triplanar within the visual shader graph.",
		"description": "Performs a lookup operation on the texture provided as a uniform for the shader, with support for triplanar mapping."
	},
	"VisualShaderNodeTextureParameter": {
		"brief_description": "Performs a uniform texture lookup within the visual shader graph.",
		"description": "Performs a lookup operation on the texture provided as a uniform for the shader."
	},
	"VisualShaderNodeTexture3DParameter": {
		"brief_description": "Provides a 3D texture parameter within the visual shader graph.",
		"description": "Translated to <code>uniform sampler3D</code> in the shader language."
	},
	"VisualShaderNodeTexture3D": {
		"brief_description": "Performs a 3D texture lookup within the visual shader graph.",
		"description": "Performs a lookup operation on the provided texture, with support for multiple texture sources to choose from."
	},
	"VisualShaderNodeTexture2DParameter": {
		"brief_description": "Provides a 2D texture parameter within the visual shader graph.",
		"description": "Translated to <code>uniform sampler2D</code> in the shader language."
	},
	"VisualShaderNodeTexture2DArrayParameter": {
		"brief_description": "A visual shader node for shader parameter (uniform) of type [Texture2DArray](../Texture2DArray).",
		"description": "This parameter allows to provide a collection of textures for the shader. You can use [VisualShaderNodeTexture2DArray](../VisualShaderNodeTexture2DArray) to extract the textures from array."
	},
	"VisualShaderNodeTexture2DArray": {
		"brief_description": "A 2D texture uniform array to be used within the visual shader graph.",
		"description": "Translated to <code>uniform sampler2DArray</code> in the shader language."
	},
	"VisualShaderNodeTexture": {
		"brief_description": "Performs a 2D texture lookup within the visual shader graph.",
		"description": "Performs a lookup operation on the provided texture, with support for multiple texture sources to choose from."
	},
	"VisualShaderNodeSwitch": {
		"brief_description": "A selector function for use within the visual shader graph.",
		"description": "Returns an associated value of the <code>op_type</code> type if the provided boolean value is <code>true</code> or <code>false</code>."
	},
	"VisualShaderNodeStep": {
		"brief_description": "Calculates a Step function within the visual shader graph.",
		"description": "Translates to <code>step(edge, x)</code> in the shader language.\nReturns <code>0.0</code> if <code>x</code> is smaller than <code>edge</code> and <code>1.0</code> otherwise."
	},
	"VisualShaderNodeSmoothStep": {
		"brief_description": "Calculates a SmoothStep function within the visual shader graph.",
		"description": "Translates to <code>smoothstep(edge0, edge1, x)</code> in the shader language.\nReturns <code>0.0</code> if <code>x</code> is smaller than <code>edge0</code> and <code>1.0</code> if <code>x</code> is larger than <code>edge1</code>. Otherwise, the return value is interpolated between <code>0.0</code> and <code>1.0</code> using Hermite polynomials."
	},
	"VisualShaderNodeSDFToScreenUV": {
		"brief_description": "A function to convert an SDF (signed-distance field) to screen UV, to be used within the visual shader graph.",
		"description": "Translates to <code>sdf_to_screen_uv(sdf_pos)</code> in the shader language."
	},
	"VisualShaderNodeSDFRaymarch": {
		"brief_description": "SDF raymarching algorithm to be used within the visual shader graph.",
		"description": "Casts a ray against the screen SDF (signed-distance field) and returns the distance travelled."
	},
	"VisualShaderNodeScreenUVToSDF": {
		"brief_description": "A function to convert screen UV to an SDF (signed-distance field), to be used within the visual shader graph.",
		"description": "Translates to <code>screen_uv_to_sdf(uv)</code> in the shader language. If the UV port isn't connected, <code>SCREEN_UV</code> is used instead."
	},
	"VisualShaderNodeSample3D": {
		"brief_description": "A base node for nodes which samples 3D textures in the visual shader graph.",
		"description": "A virtual class, use the descendants instead."
	},
	"VisualShaderNodeResizableBase": {
		"brief_description": "Base class for resizable nodes in a visual shader graph.",
		"description": "Resizable nodes have a handle that allows the user to adjust their size as needed."
	},
	"VisualShaderNodeRemap": {
		"brief_description": "A visual shader node for remap function.",
		"description": "Remap will transform the input range into output range, e.g. you can change a <code>0..1</code> value to <code>-2..2</code> etc. See [method @GlobalScope.remap] for more details."
	},
	"VisualShaderNodeRandomRange": {
		"brief_description": "A visual shader node that generates a pseudo-random scalar.",
		"description": "Random range node will output a pseudo-random scalar value in the specified range, based on the seed. The value is always the same for the given seed and range, so you should provide a changing input, e.g. by using time."
	},
	"VisualShaderNodeProximityFade": {
		"brief_description": "A visual shader node representing proximity fade effect.",
		"description": "The proximity fade effect fades out each pixel based on its distance to another object."
	},
	"VisualShaderNodeParticleSphereEmitter": {
		"brief_description": "A visual shader node that makes particles emitted in a sphere shape.",
		"description": "[VisualShaderNodeParticleEmitter](../VisualShaderNodeParticleEmitter) that makes the particles emitted in sphere shape with the specified inner and outer radii."
	},
	"VisualShaderNodeParticleRingEmitter": {
		"brief_description": "A visual shader node that makes particles emitted in a ring shape.",
		"description": "[VisualShaderNodeParticleEmitter](../VisualShaderNodeParticleEmitter) that makes the particles emitted in ring shape with the specified inner and outer radii and height."
	},
	"VisualShaderNodeParticleRandomness": {
		"brief_description": "Visual shader node for randomizing particle values.",
		"description": "Randomness node will output pseudo-random values of the given type based on the specified minimum and maximum values."
	},
	"VisualShaderNodeParticleOutput": {
		"brief_description": "Visual shader node that defines output values for particle emitting.",
		"description": "This node defines how particles are emitted. It allows to customize e.g. position and velocity. Available ports are different depending on which function this node is inside (start, process, collision) and whether custom data is enabled."
	},
	"VisualShaderNodeParticleMultiplyByAxisAngle": {
		"brief_description": "A visual shader helper node for multiplying position and rotation of particles.",
		"description": "This node helps to multiply a position input vector by rotation using specific axis. Intended to work with emitters."
	},
	"VisualShaderNodeParticleMeshEmitter": {
		"brief_description": "A visual shader node that makes particles emitted in a shape defined by a [Mesh](../Mesh).",
		"description": "[VisualShaderNodeParticleEmitter](../VisualShaderNodeParticleEmitter) that makes the particles emitted in a shape of the assigned <a href=\"#mesh\">mesh</a>. It will emit from the mesh's surfaces, either all or only the specified one."
	},
	"VisualShaderNodeParticleEmitter": {
		"brief_description": "A base class for particle emitters.",
		"description": "Particle emitter nodes can be used in \"start\" step of particle shaders and they define the starting position of the particles. Connect them to the Position output port."
	},
	"VisualShaderNodeParticleEmit": {
		"brief_description": "A visual shader node that forces to emit a particle from a sub-emitter.",
		"description": "This node internally calls <code>emit_subparticle</code> shader method. It will emit a particle from the configured sub-emitter and also allows to customize how its emitted. Requires a sub-emitter assigned to the particles node with this shader."
	},
	"VisualShaderNodeParticleConeVelocity": {
		"brief_description": "A visual shader node that makes particles move in a cone shape.",
		"description": "This node can be used in \"start\" step of particle shader. It defines the initial velocity of the particles, making them move in cone shape starting from the center, with a given spread."
	},
	"VisualShaderNodeParticleBoxEmitter": {
		"brief_description": "A visual shader node that makes particles emitted in a box shape.",
		"description": "[VisualShaderNodeParticleEmitter](../VisualShaderNodeParticleEmitter) that makes the particles emitted in box shape with the specified extents."
	},
	"VisualShaderNodeParticleAccelerator": {
		"brief_description": "A visual shader node that accelerates particles.",
		"description": "Particle accelerator can be used in \"process\" step of particle shader. It will accelerate the particles. Connect it to the Velocity output port."
	},
	"VisualShaderNodeParameterRef": {
		"brief_description": "A reference to an existing [VisualShaderNodeParameter](../VisualShaderNodeParameter).",
		"description": "Creating a reference to a [VisualShaderNodeParameter](../VisualShaderNodeParameter) allows you to reuse this parameter in different shaders or shader stages easily."
	},
	"VisualShaderNodeParameter": {
		"brief_description": "A base type for the parameters within the visual shader graph.",
		"description": "A parameter represents a variable in the shader which is set externally, i.e. from the [ShaderMaterial](../ShaderMaterial). Parameters are exposed as properties in the [ShaderMaterial](../ShaderMaterial) and can be assigned from the Inspector or from a script."
	},
	"VisualShaderNodeOutput": {
		"brief_description": "Represents the output shader parameters within the visual shader graph.",
		"description": "This visual shader node is present in all shader graphs in form of \"Output\" block with multiple output value ports."
	},
	"VisualShaderNodeOuterProduct": {
		"brief_description": "Calculates an outer product of two vectors within the visual shader graph.",
		"description": "<code>OuterProduct</code> treats the first parameter <code>c</code> as a column vector (matrix with one column) and the second parameter <code>r</code> as a row vector (matrix with one row) and does a linear algebraic matrix multiply <code>c * r</code>, yielding a matrix whose number of rows is the number of components in <code>c</code> and whose number of columns is the number of components in <code>r</code>."
	},
	"VisualShaderNodeMultiplyAdd": {
		"brief_description": "Performs a fused multiply-add operation within the visual shader graph.",
		"description": "Uses three operands to compute <code>(a * b + c)</code> expression."
	},
	"VisualShaderNodeMix": {
		"brief_description": "Linearly interpolates between two values within the visual shader graph.",
		"description": "Translates to <code>mix(a, b, weight)</code> in the shader language."
	},
	"VisualShaderNodeLinearSceneDepth": {
		"brief_description": "A visual shader node that returns the depth value of the DEPTH_TEXTURE node in a linear space.",
		"description": "This node can be used in fragment shaders."
	},
	"VisualShaderNodeIs": {
		"brief_description": "A boolean comparison operator to be used within the visual shader graph.",
		"description": "Returns the boolean result of the comparison between <code>INF</code> or <code>NaN</code> and a scalar parameter."
	},
	"VisualShaderNodeIntParameter": {
		"brief_description": "A visual shader node for shader parameter (uniform) of type [int](../int).",
		"description": "A [VisualShaderNodeParameter](../VisualShaderNodeParameter) of type [int](../int). Offers additional customization for range of accepted values."
	},
	"VisualShaderNodeIntOp": {
		"brief_description": "An integer scalar operator to be used within the visual shader graph.",
		"description": "Applies <a href=\"#operator\">operator</a> to two integer inputs: <code>a</code> and <code>b</code>."
	},
	"VisualShaderNodeIntFunc": {
		"brief_description": "A scalar integer function to be used within the visual shader graph.",
		"description": "Accept an integer scalar (<code>x</code>) to the input port and transform it according to <a href=\"#function\">function</a>."
	},
	"VisualShaderNodeIntConstant": {
		"brief_description": "A scalar integer constant to be used within the visual shader graph.",
		"description": "Translated to <code>int</code> in the shader language."
	},
	"VisualShaderNodeInput": {
		"brief_description": "Represents the input shader parameter within the visual shader graph.",
		"description": "Gives access to input variables (built-ins) available for the shader. See the shading reference for the list of available built-ins for each shader type (check <code>Tutorials</code> section for link)."
	},
	"VisualShaderNodeIf": {
		"brief_description": "Compares two floating-point numbers in order to return a required vector within the visual shader graph.",
		"description": "First two ports are scalar floating-point numbers to compare, third is tolerance comparison amount and last three ports represents a vectors returned if <code>a == b</code>, <code>a > b</code> and <code>a < b</code> respectively."
	},
	"VisualShaderNodeGroupBase": {
		"brief_description": "Base class for a family of nodes with variable number of input and output ports within the visual shader graph.",
		"description": "Currently, has no direct usage, use the derived classes instead."
	},
	"VisualShaderNodeGlobalExpression": {
		"brief_description": "A custom global visual shader graph expression written in Godot Shading Language.",
		"description": "Custom Godot Shader Language expression, which is placed on top of the generated shader. You can place various function definitions inside to call later in [VisualShaderNodeExpression](../VisualShaderNodeExpression)s (which are injected in the main shader functions). You can also declare varyings, uniforms and global constants."
	},
	"VisualShaderNodeFresnel": {
		"brief_description": "A Fresnel effect to be used within the visual shader graph.",
		"description": "Returns falloff based on the dot product of surface normal and view direction of camera (pass associated inputs to it)."
	},
	"VisualShaderNodeFloatParameter": {
		"brief_description": "A scalar float parameter to be used within the visual shader graph.",
		"description": "Translated to <code>uniform float</code> in the shader language."
	},
	"VisualShaderNodeFloatOp": {
		"brief_description": "A floating-point scalar operator to be used within the visual shader graph.",
		"description": "Applies <a href=\"#operator\">operator</a> to two floating-point inputs: <code>a</code> and <code>b</code>."
	},
	"VisualShaderNodeFloatFunc": {
		"brief_description": "A scalar floating-point function to be used within the visual shader graph.",
		"description": "Accept a floating-point scalar (<code>x</code>) to the input port and transform it according to <a href=\"#function\">function</a>."
	},
	"VisualShaderNodeFloatConstant": {
		"brief_description": "A scalar floating-point constant to be used within the visual shader graph.",
		"description": "Translated to <code>float</code> in the shader language."
	},
	"VisualShaderNodeFaceForward": {
		"brief_description": "Returns the vector that points in the same direction as a reference vector within the visual shader graph.",
		"description": "Translates to <code>faceforward(N, I, Nref)</code> in the shader language. The function has three vector parameters: <code>N</code>, the vector to orient, <code>I</code>, the incident vector, and <code>Nref</code>, the reference vector. If the dot product of <code>I</code> and <code>Nref</code> is smaller than zero the return value is <code>N</code>. Otherwise, <code>-N</code> is returned."
	},
	"VisualShaderNodeExpression": {
		"brief_description": "A custom visual shader graph expression written in Godot Shading Language.",
		"description": "Custom Godot Shading Language expression, with a custom number of input and output ports.\nThe provided code is directly injected into the graph's matching shader function (<code>vertex</code>, <code>fragment</code>, or <code>light</code>), so it cannot be used to declare functions, varyings, uniforms, or global constants. See [VisualShaderNodeGlobalExpression](../VisualShaderNodeGlobalExpression) for such global definitions."
	},
	"VisualShaderNodeDotProduct": {
		"brief_description": "Calculates a dot product of two vectors within the visual shader graph.",
		"description": "Translates to <code>dot(a, b)</code> in the shader language."
	},
	"VisualShaderNodeDistanceFade": {
		"brief_description": "A visual shader node representing distance fade effect.",
		"description": "The distance fade effect fades out each pixel based on its distance to another object."
	},
	"VisualShaderNodeDeterminant": {
		"brief_description": "Calculates the determinant of a [Transform3D](../Transform3D) within the visual shader graph.",
		"description": "Translates to <code>determinant(x)</code> in the shader language."
	},
	"VisualShaderNodeDerivativeFunc": {
		"brief_description": "Calculates a derivative within the visual shader graph.",
		"description": "This node is only available in <code>Fragment</code> and <code>Light</code> visual shaders."
	},
	"VisualShaderNodeCustom": {
		"brief_description": "Virtual class to define custom [VisualShaderNode](../VisualShaderNode)s for use in the Visual Shader Editor.",
		"description": "By inheriting this class you can create a custom [VisualShader](../VisualShader) script addon which will be automatically added to the Visual Shader Editor. The [VisualShaderNode](../VisualShaderNode)'s behavior is defined by overriding the provided virtual methods.\nIn order for the node to be registered as an editor addon, you must use the <code>@tool</code> annotation and provide a <code>class_name</code> for your custom script. For example:\n<code>\n@tool\nextends VisualShaderNodeCustom\nclass_name VisualShaderNodeNoise\n</code>"
	},
	"VisualShaderNodeCurveXYZTexture": {
		"brief_description": "Performs a [CurveXYZTexture](../CurveXYZTexture) lookup within the visual shader graph.",
		"description": "Comes with a built-in editor for texture's curves."
	},
	"VisualShaderNodeCurveTexture": {
		"brief_description": "Performs a [CurveTexture](../CurveTexture) lookup within the visual shader graph.",
		"description": "Comes with a built-in editor for texture's curves."
	},
	"VisualShaderNodeCubemapParameter": {
		"brief_description": "A [Cubemap](../Cubemap) parameter node to be used within the visual shader graph.",
		"description": "Translated to <code>uniform samplerCube</code> in the shader language. The output value can be used as port for [VisualShaderNodeCubemap](../VisualShaderNodeCubemap)."
	},
	"VisualShaderNodeCubemap": {
		"brief_description": "A [Cubemap](../Cubemap) sampling node to be used within the visual shader graph.",
		"description": "Translated to <code>texture(cubemap, vec3)</code> in the shader language. Returns a color vector and alpha channel as scalar."
	},
	"VisualShaderNodeConstant": {
		"brief_description": "A base type for the constants within the visual shader graph.",
		"description": "This is an abstract class. See the derived types for descriptions of the possible values."
	},
	"VisualShaderNodeCompare": {
		"brief_description": "A comparison function for common types within the visual shader graph.",
		"description": "Compares <code>a</code> and <code>b</code> of <a href=\"#type\">type</a> by <a href=\"#function\">function</a>. Returns a boolean scalar. Translates to <code>if</code> instruction in shader code."
	},
	"VisualShaderNodeComment": {
		"brief_description": "A comment node to be placed on visual shader graph.",
		"description": "A resizable rectangular area with changeable <a href=\"#title\">title</a> and <a href=\"#description\">description</a> used for better organizing of other visual shader nodes."
	},
	"VisualShaderNodeColorParameter": {
		"brief_description": "A [Color](../Color) parameter to be used within the visual shader graph.",
		"description": "Translated to <code>uniform vec4</code> in the shader language."
	},
	"VisualShaderNodeColorOp": {
		"brief_description": "A [Color](../Color) operator to be used within the visual shader graph.",
		"description": "Applies <a href=\"#operator\">operator</a> to two color inputs."
	},
	"VisualShaderNodeColorFunc": {
		"brief_description": "A [Color](../Color) function to be used within the visual shader graph.",
		"description": "Accept a [Color](../Color) to the input port and transform it according to <a href=\"#function\">function</a>."
	},
	"VisualShaderNodeColorConstant": {
		"brief_description": "A [Color](../Color) constant to be used within the visual shader graph.",
		"description": "Has two output ports representing RGB and alpha channels of [Color](../Color).\nTranslated to <code>vec3 rgb</code> and <code>float alpha</code> in the shader language."
	},
	"VisualShaderNodeClamp": {
		"brief_description": "Clamps a value within the visual shader graph.",
		"description": "Constrains a value to lie between <code>min</code> and <code>max</code> values."
	},
	"VisualShaderNodeBooleanParameter": {
		"brief_description": "A boolean parameter to be used within the visual shader graph.",
		"description": "Translated to <code>uniform bool</code> in the shader language."
	},
	"VisualShaderNodeBooleanConstant": {
		"brief_description": "A boolean constant to be used within the visual shader graph.",
		"description": "Has only one output port and no inputs.\nTranslated to <code>bool</code> in the shader language."
	},
	"VisualShaderNodeBillboard": {
		"brief_description": "A node that controls how the object faces the camera to be used within the visual shader graph.",
		"description": "The output port of this node needs to be connected to <code>Model View Matrix</code> port of [VisualShaderNodeOutput](../VisualShaderNodeOutput)."
	},
	"VisualShaderNode": {
		"brief_description": "Base class for nodes in a visual shader graph.",
		"description": "Visual shader graphs consist of various nodes. Each node in the graph is a separate object and they are represented as a rectangular boxes with title and a set of properties. Each node has also connection ports that allow to connect it to another nodes and control the flow of the shader."
	},
	"VisualShader": {
		"brief_description": "A custom shader program with a visual editor.",
		"description": "This class allows you to define a custom shader program that can be used for various materials to render objects.\nThe visual shader editor creates the shader."
	},
	"VisualInstance3D": {
		"brief_description": "Parent of all visual 3D nodes.",
		"description": "The [VisualInstance3D](../VisualInstance3D) is used to connect a resource to a visual representation. All visual 3D nodes inherit from the [VisualInstance3D](../VisualInstance3D). In general, you should not access the [VisualInstance3D](../VisualInstance3D) properties directly as they are accessed and managed by the nodes that inherit from [VisualInstance3D](../VisualInstance3D). [VisualInstance3D](../VisualInstance3D) is the node representation of the [RenderingServer](../RenderingServer) instance."
	},
	"VisibleOnScreenNotifier3D": {
		"brief_description": "Detects approximately when the node is visible on screen.",
		"description": "The VisibleOnScreenNotifier3D detects when it is visible on the screen. It also notifies when its bounding rectangle enters or exits the screen or a [Camera3D](../Camera3D)'s view.\nIf you want nodes to be disabled automatically when they exit the screen, use [VisibleOnScreenEnabler3D](../VisibleOnScreenEnabler3D) instead.\n<b>Note:</b> VisibleOnScreenNotifier3D uses the render culling code to determine whether it's visible on screen, which also means that its <a href=\"../Node3D#visible\">Node3D.visible<a> must be <code>true</code> to work correctly."
	},
	"VisibleOnScreenNotifier2D": {
		"brief_description": "Detects when the node extents are visible on screen.",
		"description": "The VisibleOnScreenNotifier2D detects when it is visible on the screen. It also notifies when its bounding rectangle enters or exits the screen or a viewport.\nIf you want nodes to be disabled automatically when they exit the screen, use [VisibleOnScreenEnabler2D](../VisibleOnScreenEnabler2D) instead.\n<b>Note:</b> VisibleOnScreenNotifier2D uses the render culling code to determine whether it's visible on screen, which also means that its <a href=\"../CanvasItem#visible\">CanvasItem.visible<a> must be <code>true</code> to work correctly."
	},
	"VisibleOnScreenEnabler3D": {
		"brief_description": "Enables certain nodes only when approximately visible.",
		"description": "The VisibleOnScreenEnabler3D will disable [RigidBody3D](../RigidBody3D) and [AnimationPlayer](../AnimationPlayer) nodes when they are not visible. It will only affect other nodes within the same scene as the VisibleOnScreenEnabler3D itself.\nIf you just want to receive notifications, use [VisibleOnScreenNotifier3D](../VisibleOnScreenNotifier3D) instead.\n<b>Note:</b> VisibleOnScreenEnabler3D uses an approximate heuristic for performance reasons. It doesn't take walls and other occlusion into account. The heuristic is an implementation detail and may change in future versions. If you need precise visibility checking, use another method such as adding an [Area3D](../Area3D) node as a child of a [Camera3D](../Camera3D) node and/or <a href=\"../Vector3#dot\">Vector3.dot<a>.\n<b>Note:</b> VisibleOnScreenEnabler3D will not affect nodes added after scene initialization."
	},
	"VisibleOnScreenEnabler2D": {
		"brief_description": "Automatically disables another node if not visible on screen.",
		"description": "VisibleOnScreenEnabler2D detects when it is visible on screen (just like [VisibleOnScreenNotifier2D](../VisibleOnScreenNotifier2D)) and automatically enables or disables the target node. The target node is disabled when [VisibleOnScreenEnabler2D](../VisibleOnScreenEnabler2D) is not visible on screen (including when <a href=\"../CanvasItem#visible\">CanvasItem.visible<a> is <code>false</code>), and enabled when the enabler is visible. The disabling is achieved by changing <a href=\"../Node#process_mode\">Node.process_mode<a>."
	},
	"ViewportTexture": {
		"brief_description": "Texture which displays the content of a [Viewport](../Viewport).",
		"description": "Displays the content of a [Viewport](../Viewport) node as a dynamic [Texture2D](../Texture2D). This can be used to mix controls, 2D, and 3D elements in the same scene.\nTo create a ViewportTexture in code, use the <a href=\"../Viewport#get_texture\">Viewport.get_texture<a> method on the target viewport.\n<b>Note:</b> When local to scene, this texture uses <a href=\"../Resource#setup_local_to_scene\">Resource.setup_local_to_scene<a> to set the proxy texture and flags in the local viewport."
	},
	"Viewport": {
		"brief_description": "Base class for viewports.",
		"description": "A Viewport creates a different view into the screen, or a sub-view inside another viewport. Children 2D Nodes will display on it, and children Camera3D 3D nodes will render on it too.\nOptionally, a viewport can have its own 2D or 3D world, so they don't share what they draw with other viewports.\nViewports can also choose to be audio listeners, so they generate positional audio depending on a 2D or 3D camera child of it.\nAlso, viewports can be assigned to different screens in case the devices have multiple screens.\nFinally, viewports can also behave as render targets, in which case they will not be visible unless the associated texture is used to draw."
	},
	"VideoStreamPlayer": {
		"brief_description": "Control for playing video streams.",
		"description": "Control node for playing video streams using [VideoStream](../VideoStream) resources.\nSupported video formats are [Ogg Theora](https://www.theora.org/) (<code>.ogv</code>, [VideoStreamTheora](../VideoStreamTheora)) and any format exposed via a GDExtension plugin.\n<b>Note:</b> Due to a bug, VideoStreamPlayer does not support localization remapping yet.\n<b>Warning:</b> On Web, video playback <i>will</i> perform poorly due to missing architecture-specific assembly optimizations."
	},
	"VideoStreamPlayback": {
		"brief_description": "Internal class used by [VideoStream](../VideoStream) to manage playback state when played from a [VideoStreamPlayer](../VideoStreamPlayer).",
		"description": "This class is intended to be overridden by video decoder extensions with custom implementations of [VideoStream](../VideoStream)."
	},
	"VideoStream": {
		"brief_description": "Base resource for video streams.",
		"description": "Base resource type for all video streams. Classes that derive from [VideoStream](../VideoStream) can all be used as resource types to play back videos in [VideoStreamPlayer](../VideoStreamPlayer)."
	},
	"VFlowContainer": {
		"brief_description": "Vertical flow container.",
		"description": "Vertical version of [FlowContainer](../FlowContainer)."
	},
	"VehicleWheel3D": {
		"brief_description": "Physics object that simulates the behavior of a wheel.",
		"description": "This node needs to be used as a child node of [VehicleBody3D](../VehicleBody3D) and simulates the behavior of one of its wheels. This node also acts as a collider to detect if the wheel is touching a surface.\n<b>Note:</b> This class has known issues and isn't designed to provide realistic 3D vehicle physics. If you want advanced vehicle physics, you will probably have to write your own physics integration using another [PhysicsBody3D](../PhysicsBody3D) class."
	},
	"VehicleBody3D": {
		"brief_description": "Physics body that simulates the behavior of a car.",
		"description": "This node implements all the physics logic needed to simulate a car. It is based on the raycast vehicle system commonly found in physics engines. You will need to add a [CollisionShape3D](../CollisionShape3D) for the main body of your vehicle and add [VehicleWheel3D](../VehicleWheel3D) nodes for the wheels. You should also add a [MeshInstance3D](../MeshInstance3D) to this node for the 3D model of your car but this model should not include meshes for the wheels. You should control the vehicle by using the <a href=\"#brake\">brake</a>, <a href=\"#engine_force\">engine_force</a>, and <a href=\"#steering\">steering</a> properties and not change the position or orientation of this node directly.\n<b>Note:</b> The origin point of your VehicleBody3D will determine the center of gravity of your vehicle so it is better to keep this low and move the [CollisionShape3D](../CollisionShape3D) and [MeshInstance3D](../MeshInstance3D) upwards.\n<b>Note:</b> This class has known issues and isn't designed to provide realistic 3D vehicle physics. If you want advanced vehicle physics, you will probably have to write your own physics integration using another [PhysicsBody3D](../PhysicsBody3D) class.\n<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"Vector4i": {
		"brief_description": "Vector used for 4D math using integer coordinates.",
		"description": "4-element structure that can be used to represent 4D grid coordinates or sets of integers.\nIt uses integer coordinates and is therefore preferable to [Vector4](../Vector4) when exact precision is required. Note that the values are limited to 32 bits, and unlike [Vector4](../Vector4) this cannot be configured with an engine build option. Use [int](../int) or [PackedInt64Array](../PackedInt64Array) if 64-bit values are needed."
	},
	"Vector4": {
		"brief_description": "Vector used for 4D math using floating point coordinates.",
		"description": "4-element structure that can be used to represent any quadruplet of numeric values.\nIt uses floating-point coordinates. By default, these floating-point values use 32-bit precision, unlike [float](../float) which is always 64-bit. If double precision is needed, compile the engine with the option <code>precision=double</code>.\nSee [Vector4i](../Vector4i) for its integer counterpart.\n<b>Note:</b> In a boolean context, a Vector4 will evaluate to <code>false</code> if it's equal to <code>Vector4(0, 0, 0, 0)</code>. Otherwise, a Vector4 will always evaluate to <code>true</code>."
	},
	"Vector3i": {
		"brief_description": "Vector used for 3D math using integer coordinates.",
		"description": "3-element structure that can be used to represent positions in 3D space or any other triplet of numeric values.\nIt uses integer coordinates and is therefore preferable to [Vector3](../Vector3) when exact precision is required. Note that the values are limited to 32 bits, and unlike [Vector3](../Vector3) this cannot be configured with an engine build option. Use [int](../int) or [PackedInt64Array](../PackedInt64Array) if 64-bit values are needed.\n<b>Note:</b> In a boolean context, a Vector3i will evaluate to <code>false</code> if it's equal to <code>Vector3i(0, 0, 0)</code>. Otherwise, a Vector3i will always evaluate to <code>true</code>."
	},
	"Vector3": {
		"brief_description": "Vector used for 3D math using floating point coordinates.",
		"description": "3-element structure that can be used to represent positions in 3D space or any other triplet of numeric values.\nIt uses floating-point coordinates. By default, these floating-point values use 32-bit precision, unlike [float](../float) which is always 64-bit. If double precision is needed, compile the engine with the option <code>precision=double</code>.\nSee [Vector3i](../Vector3i) for its integer counterpart.\n<b>Note:</b> In a boolean context, a Vector3 will evaluate to <code>false</code> if it's equal to <code>Vector3(0, 0, 0)</code>. Otherwise, a Vector3 will always evaluate to <code>true</code>."
	},
	"Vector2i": {
		"brief_description": "Vector used for 2D math using integer coordinates.",
		"description": "2-element structure that can be used to represent positions in 2D space or any other pair of numeric values.\nIt uses integer coordinates and is therefore preferable to [Vector2](../Vector2) when exact precision is required. Note that the values are limited to 32 bits, and unlike [Vector2](../Vector2) this cannot be configured with an engine build option. Use [int](../int) or [PackedInt64Array](../PackedInt64Array) if 64-bit values are needed.\n<b>Note:</b> In a boolean context, a Vector2i will evaluate to <code>false</code> if it's equal to <code>Vector2i(0, 0)</code>. Otherwise, a Vector2i will always evaluate to <code>true</code>."
	},
	"Vector2": {
		"brief_description": "Vector used for 2D math using floating point coordinates.",
		"description": "2-element structure that can be used to represent positions in 2D space or any other pair of numeric values.\nIt uses floating-point coordinates. By default, these floating-point values use 32-bit precision, unlike [float](../float) which is always 64-bit. If double precision is needed, compile the engine with the option <code>precision=double</code>.\nSee [Vector2i](../Vector2i) for its integer counterpart.\n<b>Note:</b> In a boolean context, a Vector2 will evaluate to <code>false</code> if it's equal to <code>Vector2(0, 0)</code>. Otherwise, a Vector2 will always evaluate to <code>true</code>."
	},
	"VBoxContainer": {
		"brief_description": "Vertical box container.",
		"description": "Vertical box container. See [BoxContainer](../BoxContainer)."
	},
	"Variant": {
		"brief_description": "The most important data type in Godot.",
		"description": "In computer programming, a Variant class is a class that is designed to store a variety of other types. Dynamic programming languages like PHP, Lua, JavaScript and GDScript like to use them to store variables' data on the backend. With these Variants, properties are able to change value types freely.\n<!-- <codeblocks> -->\n<code>\nvar foo = 2 # foo is dynamically an integer\nfoo = \"Now foo is a string!\"\nfoo = RefCounted.new() # foo is an Object\nvar bar: int = 2 # bar is a statically typed integer.\n# bar = \"Uh oh! I can't make static variables become a different type!\"\n</code>\n```csharp\n// C# is statically typed. Once a variable has a type it cannot be changed. You can use the `var` keyword to let the compiler infer the type automatically.\nvar foo = 2; // Foo is a 32-bit integer (int). Be cautious, integers in GDScript are 64-bit and the direct C# equivalent is `long`.\n// foo = \"foo was and will always be an integer. It cannot be turned into a string!\";\nvar boo = \"Boo is a string!\";\nvar ref = new RefCounted(); // var is especially useful when used together with a constructor.\n\n// Godot also provides a Variant type that works like an union of all the Variant-compatible types.\nVariant fooVar = 2; // fooVar is dynamically an integer (stored as a `long` in the Variant type).\nfooVar = \"Now fooVar is a string!\";\nfooVar = new RefCounted(); // fooVar is a GodotObject.\n```\n<!-- </codeblocks> -->\nGodot tracks all scripting API variables within Variants. Without even realizing it, you use Variants all the time. When a particular language enforces its own rules for keeping data typed, then that language is applying its own custom logic over the base Variant scripting API.\n- GDScript automatically wrap values in them. It keeps all data in plain Variants by default and then optionally enforces custom static typing rules on variable types.\n- C# is statically typed, but uses its own implementation of the <code>Variant</code> type in place of Godot's Variant class when it needs to represent a dynamic value. A <code>Variant</code> can be assigned any compatible type implicitly but converting requires an explicit cast.\nThe global [method @GlobalScope.typeof] function returns the enumerated value of the Variant type stored in the current variable (see <a href=\"../Variant#Type\">Variant.Type<a>).\n<!-- <codeblocks> -->\n<code>\nvar foo = 2\nmatch typeof(foo):\n\tTYPE_NIL:\n\t\tprint(\"foo is null\")\n\tTYPE_INTEGER:\n\t\tprint(\"foo is an integer\")\n\tTYPE_OBJECT:\n\t\t# Note that Objects are their own special category.\n\t\t# To get the name of the underlying Object type, you need the `get_class()` method.\n\t\tprint(\"foo is a(n) %s\" % foo.get_class()) # inject the class name into a formatted string.\n\t\t# Note also that there is not yet any way to get a script's `class_name` string easily.\n\t\t# To fetch that value, you can use <a href=\"../ProjectSettings#get_global_class_list\">ProjectSettings.get_global_class_list<a>.\n\t\t# Open your project.godot file to see it up close.\n</code>\n```csharp\nVariant foo = 2;\nswitch (foo.VariantType)\n{\n\tcase Variant.Type.Nil:\n\t\tGD.Print(\"foo is null\");\n\t\tbreak;\n\tcase Variant.Type.Int:\n\t\tGD.Print(\"foo is an integer\");\n\t\tbreak;\n\tcase Variant.Type.Object:\n\t\t// Note that Objects are their own special category.\n\t\t// You can convert a Variant to a GodotObject and use reflection to get its name.\n\t\tGD.Print($\"foo is a(n) {foo.AsGodotObject().GetType().Name}\");\n\t\tbreak;\n}\n```\n<!-- </codeblocks> -->\nA Variant takes up only 20 bytes and can store almost any engine datatype inside of it. Variants are rarely used to hold information for long periods of time. Instead, they are used mainly for communication, editing, serialization and moving data around.\nGodot has specifically invested in making its Variant class as flexible as possible; so much so that it is used for a multitude of operations to facilitate communication between all of Godot's systems.\nA Variant:\n- Can store almost any datatype.\n- Can perform operations between many variants. GDScript uses Variant as its atomic/native datatype.\n- Can be hashed, so it can be compared quickly to other variants.\n- Can be used to convert safely between datatypes.\n- Can be used to abstract calling methods and their arguments. Godot exports all its functions through variants.\n- Can be used to defer calls or move data between threads.\n- Can be serialized as binary and stored to disk, or transferred via network.\n- Can be serialized to text and use it for printing values and editable settings.\n- Can work as an exported property, so the editor can edit it universally.\n- Can be used for dictionaries, arrays, parsers, etc.\n<b>Containers (Array and Dictionary):</b> Both are implemented using variants. A [Dictionary](../Dictionary) can match any datatype used as key to any other datatype. An [Array](../Array) just holds an array of Variants. Of course, a Variant can also hold a [Dictionary](../Dictionary) and an [Array](../Array) inside, making it even more flexible.\nModifications to a container will modify all references to it. A [Mutex](../Mutex) should be created to lock it if multi-threaded access is desired."
	},
	"UndoRedo": {
		"brief_description": "Helper to manage undo/redo operations in the editor or custom tools.",
		"description": "Helper to manage undo/redo operations in the editor or custom tools. It works by registering methods and property changes inside \"actions\".\nCommon behavior is to create an action, then add do/undo calls to functions or property changes, then committing the action.\nHere's an example on how to add an action to the Godot editor's own [UndoRedo](../UndoRedo), from a plugin:\n<!-- <codeblocks> -->\n<code>\nvar undo_redo = get_undo_redo() # Method of EditorPlugin.\n\nfunc do_something():\n\tpass # Put your code here.\n\nfunc undo_something():\n\tpass # Put here the code that reverts what's done by \"do_something()\".\n\nfunc _on_my_button_pressed():\n\tvar node = get_node(\"MyNode2D\")\n\tundo_redo.create_action(\"Move the node\")\n\tundo_redo.add_do_method(self, \"do_something\")\n\tundo_redo.add_undo_method(self, \"undo_something\")\n\tundo_redo.add_do_property(node, \"position\", Vector2(100,100))\n\tundo_redo.add_undo_property(node, \"position\", node.position)\n\tundo_redo.commit_action()\n</code>\n```csharp\nprivate UndoRedo _undoRedo;\n\npublic override void _Ready()\n{\n\t_undoRedo = GetUndoRedo(); // Method of EditorPlugin.\n}\n\npublic void DoSomething()\n{\n\t// Put your code here.\n}\n\npublic void UndoSomething()\n{\n\t// Put here the code that reverts what's done by \"DoSomething()\".\n}\n\nprivate void OnMyButtonPressed()\n{\n\tvar node = GetNode<Node2D>(\"MyNode2D\");\n\t_undoRedo.CreateAction(\"Move the node\");\n\t_undoRedo.AddDoMethod(new Callable(this, MethodName.DoSomething));\n\t_undoRedo.AddUndoMethod(new Callable(this, MethodName.UndoSomething));\n\t_undoRedo.AddDoProperty(node, \"position\", new Vector2(100, 100));\n\t_undoRedo.AddUndoProperty(node, \"position\", node.Position);\n\t_undoRedo.CommitAction();\n}\n```\n<!-- </codeblocks> -->\n<a href=\"#create_action\">create_action</a>, <a href=\"#add_do_method\">add_do_method</a>, <a href=\"#add_undo_method\">add_undo_method</a>, <a href=\"#add_do_property\">add_do_property</a>, <a href=\"#add_undo_property\">add_undo_property</a>, and <a href=\"#commit_action\">commit_action</a> should be called one after the other, like in the example. Not doing so could lead to crashes.\nIf you don't need to register a method, you can leave <a href=\"#add_do_method\">add_do_method</a> and <a href=\"#add_undo_method\">add_undo_method</a> out; the same goes for properties. You can also register more than one method/property."
	},
	"UDPServer": {
		"brief_description": "Helper class to implement a UDP server.",
		"description": "A simple server that opens a UDP socket and returns connected [PacketPeerUDP](../PacketPeerUDP) upon receiving new packets. See also <a href=\"../PacketPeerUDP#connect_to_host\">PacketPeerUDP.connect_to_host<a>.\nAfter starting the server (<a href=\"#listen\">listen</a>), you will need to <a href=\"#poll\">poll</a> it at regular intervals (e.g. inside <a href=\"../Node#_process\">Node._process<a>) for it to process new packets, delivering them to the appropriate [PacketPeerUDP](../PacketPeerUDP), and taking new connections.\nBelow a small example of how it can be used:\n<!-- <codeblocks> -->\n<code>\n# server_node.gd\nclass_name ServerNode\nextends Node\n\nvar server := UDPServer.new()\nvar peers = []\n\nfunc _ready():\n\tserver.listen(4242)\n\nfunc _process(delta):\n\tserver.poll() # Important!\n\tif server.is_connection_available():\n\t\tvar peer: PacketPeerUDP = server.take_connection()\n\t\tvar packet = peer.get_packet()\n\t\tprint(\"Accepted peer: %s:%s\" % [peer.get_packet_ip(), peer.get_packet_port()])\n\t\tprint(\"Received data: %s\" % [packet.get_string_from_utf8()])\n\t\t# Reply so it knows we received the message.\n\t\tpeer.put_packet(packet)\n\t\t# Keep a reference so we can keep contacting the remote peer.\n\t\tpeers.append(peer)\n\n\tfor i in range(0, peers.size()):\n\t\tpass # Do something with the connected peers.\n</code>\n```csharp\n// ServerNode.cs\nusing Godot;\nusing System.Collections.Generic;\n\npublic partial class ServerNode : Node\n{\n\tprivate UdpServer _server = new UdpServer();\n\tprivate List<PacketPeerUdp> _peers  = new List<PacketPeerUdp>();\n\n\tpublic override void _Ready()\n\t{\n\t\t_server.Listen(4242);\n\t}\n\n\tpublic override void _Process(double delta)\n\t{\n\t\t_server.Poll(); // Important!\n\t\tif (_server.IsConnectionAvailable())\n\t\t{\n\t\t\tPacketPeerUdp peer = _server.TakeConnection();\n\t\t\tbyte[] packet = peer.GetPacket();\n\t\t\tGD.Print($\"Accepted Peer: {peer.GetPacketIP()}:{peer.GetPacketPort()}\");\n\t\t\tGD.Print($\"Received Data: {packet.GetStringFromUtf8()}\");\n\t\t\t// Reply so it knows we received the message.\n\t\t\tpeer.PutPacket(packet);\n\t\t\t// Keep a reference so we can keep contacting the remote peer.\n\t\t\t_peers.Add(peer);\n\t\t}\n\t\tforeach (var peer in _peers)\n\t\t{\n\t\t\t// Do something with the peers.\n\t\t}\n\t}\n}\n```\n<!-- </codeblocks> -->\n<!-- <codeblocks> -->\n<code>\n# client_node.gd\nclass_name ClientNode\nextends Node\n\nvar udp := PacketPeerUDP.new()\nvar connected = false\n\nfunc _ready():\n\tudp.connect_to_host(\"127.0.0.1\", 4242)\n\nfunc _process(delta):\n\tif !connected:\n\t\t# Try to contact server\n\t\tudp.put_packet(\"The answer is... 42!\".to_utf8())\n\tif udp.get_available_packet_count() > 0:\n\t\tprint(\"Connected: %s\" % udp.get_packet().get_string_from_utf8())\n\t\tconnected = true\n</code>\n```csharp\n// ClientNode.cs\nusing Godot;\n\npublic partial class ClientNode : Node\n{\n\tprivate PacketPeerUdp _udp = new PacketPeerUdp();\n\tprivate bool _connected = false;\n\n\tpublic override void _Ready()\n\t{\n\t\t_udp.ConnectToHost(\"127.0.0.1\", 4242);\n\t}\n\n\tpublic override void _Process(double delta)\n\t{\n\t\tif (!_connected)\n\t\t{\n\t\t\t// Try to contact server\n\t\t\t_udp.PutPacket(\"The Answer Is..42!\".ToUtf8());\n\t\t}\n\t\tif (_udp.GetAvailablePacketCount() > 0)\n\t\t{\n\t\t\tGD.Print($\"Connected: {_udp.GetPacket().GetStringFromUtf8()}\");\n\t\t\t_connected = true;\n\t\t}\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"Tweener": {
		"brief_description": "Abstract class for all Tweeners used by [Tween](../Tween).",
		"description": "Tweeners are objects that perform a specific animating task, e.g. interpolating a property or calling a method at a given time. A [Tweener](../Tweener) can't be created manually, you need to use a dedicated method from [Tween](../Tween)."
	},
	"Tween": {
		"brief_description": "Lightweight object used for general-purpose animation via script, using [Tweener](../Tweener)s.",
		"description": "Tweens are mostly useful for animations requiring a numerical property to be interpolated over a range of values. The name <i>tween</i> comes from <i>in-betweening</i>, an animation technique where you specify <i>keyframes</i> and the computer interpolates the frames that appear between them. Animating something with a [Tween](../Tween) is called tweening.\n[Tween](../Tween) is more suited than [AnimationPlayer](../AnimationPlayer) for animations where you don't know the final values in advance. For example, interpolating a dynamically-chosen camera zoom value is best done with a [Tween](../Tween); it would be difficult to do the same thing with an [AnimationPlayer](../AnimationPlayer) node. Tweens are also more light-weight than [AnimationPlayer](../AnimationPlayer), so they are very much suited for simple animations or general tasks that don't require visual tweaking provided by the editor. They can be used in a fire-and-forget manner for some logic that normally would be done by code. You can e.g. make something shoot periodically by using a looped [CallbackTweener](../CallbackTweener) with a delay.\nA [Tween](../Tween) can be created by using either <a href=\"../SceneTree#create_tween\">SceneTree.create_tween<a> or <a href=\"../Node#create_tween\">Node.create_tween<a>. [Tween](../Tween)s created manually (i.e. by using <code>Tween.new()</code>) are invalid and can't be used for tweening values.\nA tween animation is created by adding [Tweener](../Tweener)s to the [Tween](../Tween) object, using <a href=\"#tween_property\">tween_property</a>, <a href=\"#tween_interval\">tween_interval</a>, <a href=\"#tween_callback\">tween_callback</a> or <a href=\"#tween_method\">tween_method</a>:\n<!-- <codeblocks> -->\n<code>\nvar tween = get_tree().create_tween()\ntween.tween_property($Sprite, \"modulate\", Color.RED, 1)\ntween.tween_property($Sprite, \"scale\", Vector2(), 1)\ntween.tween_callback($Sprite.queue_free)\n</code>\n```csharp\nTween tween = GetTree().CreateTween();\ntween.TweenProperty(GetNode(\"Sprite\"), \"modulate\", Colors.Red, 1.0f);\ntween.TweenProperty(GetNode(\"Sprite\"), \"scale\", Vector2.Zero, 1.0f);\ntween.TweenCallback(Callable.From(GetNode(\"Sprite\").QueueFree));\n```\n<!-- </codeblocks> -->\nThis sequence will make the <code>$Sprite</code> node turn red, then shrink, before finally calling <a href=\"../Node#queue_free\">Node.queue_free<a> to free the sprite. [Tweener](../Tweener)s are executed one after another by default. This behavior can be changed using <a href=\"#parallel\">parallel</a> and <a href=\"#set_parallel\">set_parallel</a>.\nWhen a [Tweener](../Tweener) is created with one of the <code>tween_*</code> methods, a chained method call can be used to tweak the properties of this [Tweener](../Tweener). For example, if you want to set a different transition type in the above example, you can use <a href=\"#set_trans\">set_trans</a>:\n<!-- <codeblocks> -->\n<code>\nvar tween = get_tree().create_tween()\ntween.tween_property($Sprite, \"modulate\", Color.RED, 1).set_trans(Tween.TRANS_SINE)\ntween.tween_property($Sprite, \"scale\", Vector2(), 1).set_trans(Tween.TRANS_BOUNCE)\ntween.tween_callback($Sprite.queue_free)\n</code>\n```csharp\nTween tween = GetTree().CreateTween();\ntween.TweenProperty(GetNode(\"Sprite\"), \"modulate\", Colors.Red, 1.0f).SetTrans(Tween.TransitionType.Sine);\ntween.TweenProperty(GetNode(\"Sprite\"), \"scale\", Vector2.Zero, 1.0f).SetTrans(Tween.TransitionType.Bounce);\ntween.TweenCallback(Callable.From(GetNode(\"Sprite\").QueueFree));\n```\n<!-- </codeblocks> -->\nMost of the [Tween](../Tween) methods can be chained this way too. In the following example the [Tween](../Tween) is bound to the running script's node and a default transition is set for its [Tweener](../Tweener)s:\n<!-- <codeblocks> -->\n<code>\nvar tween = get_tree().create_tween().bind_node(self).set_trans(Tween.TRANS_ELASTIC)\ntween.tween_property($Sprite, \"modulate\", Color.RED, 1)\ntween.tween_property($Sprite, \"scale\", Vector2(), 1)\ntween.tween_callback($Sprite.queue_free)\n</code>\n```csharp\nvar tween = GetTree().CreateTween().BindNode(this).SetTrans(Tween.TransitionType.Elastic);\ntween.TweenProperty(GetNode(\"Sprite\"), \"modulate\", Colors.Red, 1.0f);\ntween.TweenProperty(GetNode(\"Sprite\"), \"scale\", Vector2.Zero, 1.0f);\ntween.TweenCallback(Callable.From(GetNode(\"Sprite\").QueueFree));\n```\n<!-- </codeblocks> -->\nAnother interesting use for [Tween](../Tween)s is animating arbitrary sets of objects:\n<!-- <codeblocks> -->\n<code>\nvar tween = create_tween()\nfor sprite in get_children():\n\ttween.tween_property(sprite, \"position\", Vector2(0, 0), 1)\n</code>\n```csharp\nTween tween = CreateTween();\nforeach (Node sprite in GetChildren())\n\ttween.TweenProperty(sprite, \"position\", Vector2.Zero, 1.0f);\n```\n<!-- </codeblocks> -->\nIn the example above, all children of a node are moved one after another to position (0, 0).\nYou should avoid using more than one [Tween](../Tween) per object's property. If two or more tweens animate one property at the same time, the last one created will take priority and assign the final value. If you want to interrupt and restart an animation, consider assigning the [Tween](../Tween) to a variable:\n<!-- <codeblocks> -->\n<code>\nvar tween\nfunc animate():\n\tif tween:\n\t\ttween.kill() # Abort the previous animation.\n\ttween = create_tween()\n</code>\n```csharp\nprivate Tween _tween;\n\npublic void Animate()\n{\n\tif (_tween != null)\n\t\t_tween.Kill(); // Abort the previous animation\n\t_tween = CreateTween();\n}\n```\n<!-- </codeblocks> -->\nSome [Tweener](../Tweener)s use transitions and eases. The first accepts a <a href=\"#TransitionType\">TransitionType</a> constant, and refers to the way the timing of the animation is handled (see [easings.net](https://easings.net/) for some examples). The second accepts an <a href=\"#EaseType\">EaseType</a> constant, and controls where the <code>trans_type</code> is applied to the interpolation (in the beginning, the end, or both). If you don't know which transition and easing to pick, you can try different <a href=\"#TransitionType\">TransitionType</a> constants with <a href=\"#EASE_IN_OUT\">EASE_IN_OUT</a>, and use the one that looks best.\n[Tween easing and transition types cheatsheet](https://raw.githubusercontent.com/godotengine/godot-docs/master/img/tween_cheatsheet.png)\n<b>Note:</b> Tweens are not designed to be re-used and trying to do so results in an undefined behavior. Create a new Tween for each animation and every time you replay an animation from start. Keep in mind that Tweens start immediately, so only create a Tween when you want to start animating.\n<b>Note:</b> Tweens are processing after all of nodes in the current frame, i.e. after <a href=\"../Node#_process\">Node._process<a> or <a href=\"../Node#_physics_process\">Node._physics_process<a> (depending on <a href=\"#TweenProcessMode\">TweenProcessMode</a>)."
	},
	"TubeTrailMesh": {
		"brief_description": "",
		"description": ""
	},
	"TriangleMesh": {
		"brief_description": "Internal mesh type.",
		"description": "Mesh type used internally for collision calculations."
	},
	"TreeItem": {
		"brief_description": "Control for a single item inside a [Tree](../Tree).",
		"description": "Control for a single item inside a [Tree](../Tree). May have child [TreeItem](../TreeItem)s and be styled as well as contain buttons.\nYou can remove a [TreeItem](../TreeItem) by using <a href=\"../Object#free\">Object.free<a>."
	},
	"Tree": {
		"brief_description": "Control to show a tree of items.",
		"description": "This shows a tree of items that can be selected, expanded and collapsed. The tree can have multiple columns with custom controls like text editing, buttons and popups. It can be useful for structured displays and interactions.\nTrees are built via code, using [TreeItem](../TreeItem) objects to create the structure. They have a single root but multiple roots can be simulated if a dummy hidden root is added.\n<!-- <codeblocks> -->\n<code>\nfunc _ready():\n\tvar tree = Tree.new()\n\tvar root = tree.create_item()\n\ttree.hide_root = true\n\tvar child1 = tree.create_item(root)\n\tvar child2 = tree.create_item(root)\n\tvar subchild1 = tree.create_item(child1)\n\tsubchild1.set_text(0, \"Subchild1\")\n</code>\n```csharp\npublic override void _Ready()\n{\n\tvar tree = new Tree();\n\tTreeItem root = tree.CreateItem();\n\ttree.HideRoot = true;\n\tTreeItem child1 = tree.CreateItem(root);\n\tTreeItem child2 = tree.CreateItem(root);\n\tTreeItem subchild1 = tree.CreateItem(child1);\n\tsubchild1.SetText(0, \"Subchild1\");\n}\n```\n<!-- </codeblocks> -->\nTo iterate over all the [TreeItem](../TreeItem) objects in a [Tree](../Tree) object, use <a href=\"../TreeItem#get_next\">TreeItem.get_next<a> and <a href=\"../TreeItem#get_first_child\">TreeItem.get_first_child<a> after getting the root through <a href=\"#get_root\">get_root</a>. You can use <a href=\"../Object#free\">Object.free<a> on a [TreeItem](../TreeItem) to remove it from the [Tree](../Tree).\n<b>Incremental search:</b> Like [ItemList](../ItemList) and [PopupMenu](../PopupMenu), [Tree](../Tree) supports searching within the list while the control is focused. Press a key that matches the first letter of an item's name to select the first item starting with the given letter. After that point, there are two ways to perform incremental search: 1) Press the same key again before the timeout duration to select the next item starting with the same letter. 2) Press letter keys that match the rest of the word before the timeout duration to match to select the item in question directly. Both of these actions will be reset to the beginning of the list if the timeout duration has passed since the last keystroke was registered. You can adjust the timeout duration by changing [member ProjectSettings.gui/timers/incremental_search_max_interval_msec]."
	},
	"TranslationServer": {
		"brief_description": "Server that manages all translations.",
		"description": "Server that manages all translations. Translations can be set to it and removed from it."
	},
	"Translation": {
		"brief_description": "Language Translation.",
		"description": "Translations are resources that can be loaded and unloaded on demand. They map a string to another string."
	},
	"Transform3D": {
		"brief_description": "3D transformation (34 matrix).",
		"description": "34 matrix (3 rows, 4 columns) used for 3D linear transformations. It can represent transformations such as translation, rotation, or scaling. It consists of a <a href=\"#basis\">basis</a> (first 3 columns) and a [Vector3](../Vector3) for the <a href=\"#origin\">origin</a> (last column).\nFor more information, read the \"Matrices and transforms\" documentation article."
	},
	"Transform2D": {
		"brief_description": "2D transformation (23 matrix).",
		"description": "23 matrix (2 rows, 3 columns) used for 2D linear transformations. It can represent transformations such as translation, rotation, or scaling. It consists of three [Vector2](../Vector2) values: <a href=\"#x\">x</a>, <a href=\"#y\">y</a>, and the <a href=\"#origin\">origin</a>.\nFor more information, read the \"Matrices and transforms\" documentation article."
	},
	"TouchScreenButton": {
		"brief_description": "Button for touch screen devices for gameplay use.",
		"description": "TouchScreenButton allows you to create on-screen buttons for touch devices. It's intended for gameplay use, such as a unit you have to touch to move. Unlike [Button](../Button), TouchScreenButton supports multitouch out of the box. Several TouchScreenButtons can be pressed at the same time with touch input.\nThis node inherits from [Node2D](../Node2D). Unlike with [Control](../Control) nodes, you cannot set anchors on it. If you want to create menus or user interfaces, you may want to use [Button](../Button) nodes instead. To make button nodes react to touch events, you can enable the Emulate Mouse option in the Project Settings.\nYou can configure TouchScreenButton to be visible only on touch devices, helping you develop your game both for desktop and mobile devices."
	},
	"TorusMesh": {
		"brief_description": "Class representing a torus [PrimitiveMesh](../PrimitiveMesh).",
		"description": "Class representing a torus [PrimitiveMesh](../PrimitiveMesh)."
	},
	"TLSOptions": {
		"brief_description": "TLS configuration for clients and servers.",
		"description": "TLSOptions abstracts the configuration options for the [StreamPeerTLS](../StreamPeerTLS) and [PacketPeerDTLS](../PacketPeerDTLS) classes.\nObjects of this class cannot be instantiated directly, and one of the static methods <a href=\"#client\">client</a>, <a href=\"#client_unsafe\">client_unsafe</a>, or <a href=\"#server\">server</a> should be used instead.\n<!-- <codeblocks> -->\n<code>\n# Create a TLS client configuration which uses our custom trusted CA chain.\nvar client_trusted_cas = load(\"res://my_trusted_cas.crt\")\nvar client_tls_options = TLSOptions.client(client_trusted_cas)\n\n# Create a TLS server configuration.\nvar server_certs = load(\"res://my_server_cas.crt\")\nvar server_key = load(\"res://my_server_key.key\")\nvar server_tls_options = TLSOptions.server(server_certs, server_key)\n</code>\n<!-- </codeblocks> -->"
	},
	"Timer": {
		"brief_description": "A countdown timer.",
		"description": "Counts down a specified interval and emits a signal on reaching 0. Can be set to repeat or \"one-shot\" mode.\n<b>Note:</b> To create a one-shot timer without instantiating a node, use <a href=\"../SceneTree#create_timer\">SceneTree.create_timer<a>."
	},
	"Time": {
		"brief_description": "Time singleton for working with time.",
		"description": "The Time singleton allows converting time between various formats and also getting time information from the system.\nThis class conforms with as many of the ISO 8601 standards as possible. All dates follow the Proleptic Gregorian calendar. As such, the day before <code>1582-10-15</code> is <code>1582-10-14</code>, not <code>1582-10-04</code>. The year before 1 AD (aka 1 BC) is number <code>0</code>, with the year before that (2 BC) being <code>-1</code>, etc.\nConversion methods assume \"the same timezone\", and do not handle timezone conversions or DST automatically. Leap seconds are also not handled, they must be done manually if desired. Suffixes such as \"Z\" are not handled, you need to strip them away manually.\nWhen getting time information from the system, the time can either be in the local timezone or UTC depending on the <code>utc</code> parameter. However, the <a href=\"#get_unix_time_from_system\">get_unix_time_from_system</a> method always returns the time in UTC.\n<b>Important:</b> The <code>_from_system</code> methods use the system clock that the user can manually set. <b>Never use</b> this method for precise time calculation since its results are subject to automatic adjustments by the user or the operating system. <b>Always use</b> <a href=\"#get_ticks_usec\">get_ticks_usec</a> or <a href=\"#get_ticks_msec\">get_ticks_msec</a> for precise time calculation instead, since they are guaranteed to be monotonic (i.e. never decrease)."
	},
	"TileSetSource": {
		"brief_description": "Exposes a set of tiles for a [TileSet](../TileSet) resource.",
		"description": "Exposes a set of tiles for a [TileSet](../TileSet) resource.\nTiles in a source are indexed with two IDs, coordinates ID (of type Vector2i) and an alternative ID (of type int), named according to their use in the [TileSetAtlasSource](../TileSetAtlasSource) class.\nDepending on the TileSet source type, those IDs might have restrictions on their values, this is why the base [TileSetSource](../TileSetSource) class only exposes getters for them.\nYou can iterate over all tiles exposed by a TileSetSource by first iterating over coordinates IDs using <a href=\"#get_tiles_count\">get_tiles_count</a> and <a href=\"#get_tile_id\">get_tile_id</a>, then over alternative IDs using <a href=\"#get_alternative_tiles_count\">get_alternative_tiles_count</a> and <a href=\"#get_alternative_tile_id\">get_alternative_tile_id</a>."
	},
	"TileSetScenesCollectionSource": {
		"brief_description": "Exposes a set of scenes as tiles for a [TileSet](../TileSet) resource.",
		"description": "When placed on a [TileMap](../TileMap), tiles from [TileSetScenesCollectionSource](../TileSetScenesCollectionSource) will automatically instantiate an associated scene at the cell's position in the TileMap.\nScenes are instantiated as children of the [TileMap](../TileMap) when it enters the tree. If you add/remove a scene tile in the [TileMap](../TileMap) that is already inside the tree, the [TileMap](../TileMap) will automatically instantiate/free the scene accordingly."
	},
	"TileSetAtlasSource": {
		"brief_description": "Exposes a 2D atlas texture as a set of tiles for a [TileSet](../TileSet) resource.",
		"description": "An atlas is a grid of tiles laid out on a texture. Each tile in the grid must be exposed using <a href=\"#create_tile\">create_tile</a>. Those tiles are then indexed using their coordinates in the grid.\nEach tile can also have a size in the grid coordinates, making it more or less cells in the atlas.\nAlternatives version of a tile can be created using <a href=\"#create_alternative_tile\">create_alternative_tile</a>, which are then indexed using an alternative ID. The main tile (the one in the grid), is accessed with an alternative ID equal to 0.\nEach tile alternate has a set of properties that is defined by the source's [TileSet](../TileSet) layers. Those properties are stored in a TileData object that can be accessed and modified using <a href=\"#get_tile_data\">get_tile_data</a>.\nAs TileData properties are stored directly in the TileSetAtlasSource resource, their properties might also be set using <code>TileSetAtlasSource.set(\"<coords_x>:<coords_y>/<alternative_id>/<tile_data_property>\")</code>."
	},
	"TileSet": {
		"brief_description": "Tile library for tilemaps.",
		"description": "A TileSet is a library of tiles for a [TileMap](../TileMap). A TileSet handles a list of [TileSetSource](../TileSetSource), each of them storing a set of tiles.\nTiles can either be from a [TileSetAtlasSource](../TileSetAtlasSource), that render tiles out of a texture with support for physics, navigation, etc... or from a [TileSetScenesCollectionSource](../TileSetScenesCollectionSource) which exposes scene-based tiles.\nTiles are referenced by using three IDs: their source ID, their atlas coordinates ID and their alternative tile ID.\nA TileSet can be configured so that its tiles expose more or less properties. To do so, the TileSet resources uses property layers, that you can add or remove depending on your needs.\nFor example, adding a physics layer allows giving collision shapes to your tiles. Each layer having dedicated properties (physics layer an mask), you may add several TileSet physics layers for each type of collision you need.\nSee the functions to add new layers for more information."
	},
	"TileMapPattern": {
		"brief_description": "Holds a pattern to be copied from or pasted into [TileMap](../TileMap)s.",
		"description": "This resource holds a set of cells to help bulk manipulations of [TileMap](../TileMap).\nA pattern always start at the <code>(0,0)</code> coordinates and cannot have cells with negative coordinates."
	},
	"TileMap": {
		"brief_description": "Node for 2D tile-based maps.",
		"description": "Node for 2D tile-based maps. Tilemaps use a [TileSet](../TileSet) which contain a list of tiles which are used to create grid-based maps. A TileMap may have several layers, layouting tiles on top of each other."
	},
	"TileData": {
		"brief_description": "Settings for a single tile in a [TileSet](../TileSet).",
		"description": "[TileData](../TileData) object represents a single tile in a [TileSet](../TileSet). It is usually edited using the tileset editor, but it can be modified at runtime using <a href=\"../TileMap#_tile_data_runtime_update\">TileMap._tile_data_runtime_update<a>."
	},
	"Thread": {
		"brief_description": "A unit of execution in a process.",
		"description": "A unit of execution in a process. Can run methods on [Object](../Object)s simultaneously. The use of synchronization via [Mutex](../Mutex) or [Semaphore](../Semaphore) is advised if working with shared objects.\n<b>Note:</b> Breakpoints won't break on code if it's running in a thread. This is a current limitation of the GDScript debugger."
	},
	"ThemeDB": {
		"brief_description": "An engine singleton providing access to static [Theme](../Theme) information, such as default and project theme, and fallback values.",
		"description": "This engine singleton provides access to static information about [Theme](../Theme) resources used by the engine and by your projects. You can fetch the default engine theme, as well as your project configured theme.\n[ThemeDB](../ThemeDB) also contains fallback values for theme properties."
	},
	"Theme": {
		"brief_description": "Theme resource for styling/skinning [Control](../Control)s and [Window](../Window)s.",
		"description": "A theme resource is used for styling/skinning [Control](../Control) and [Window](../Window) nodes. While individual controls can be styled using their local theme overrides (see <a href=\"../Control#add_theme_color_override\">Control.add_theme_color_override<a>), theme resources allow you to store and apply the same settings between all controls sharing the same type (e.g. style all [Button](../Button)s the same). One theme resource can be used for the entire project, but you can also set a separate theme resource to a branch of control nodes. A theme resources assigned to a control node applies to the control itself, as well as all of its direct and indirect children (as long as a chain of controls is uninterrupted).\nUse [member ProjectSettings.gui/theme/custom] to set up a project-scope theme that will be available to every control in your project.\nUse <a href=\"../Control#theme\">Control.theme<a> of any control node to set up a theme that will be available to that control and all of its direct and indirect children."
	},
	"TextureRect": {
		"brief_description": "Control for drawing textures.",
		"description": "Used to draw icons and sprites in a user interface. The texture's placement can be controlled with the <a href=\"#stretch_mode\">stretch_mode</a> property. It can scale, tile, or stay centered inside its bounding rectangle."
	},
	"TextureProgressBar": {
		"brief_description": "Texture-based progress bar. Useful for loading screens and life or stamina bars.",
		"description": "TextureProgressBar works like [ProgressBar](../ProgressBar), but uses up to 3 textures instead of Godot's [Theme](../Theme) resource. It can be used to create horizontal, vertical and radial progress bars."
	},
	"TextureLayered": {
		"brief_description": "Base class for texture types which contain the data of multiple [Image](../Image)s. Each image is of the same size and format.",
		"description": "Base class for [ImageTextureLayered](../ImageTextureLayered). Cannot be used directly, but contains all the functions necessary for accessing the derived resource types. See also [Texture3D](../Texture3D).\nData is set on a per-layer basis. For [Texture2DArray](../Texture2DArray)s, the layer specifies the array layer.\nAll images need to have the same width, height and number of mipmap levels.\nA [TextureLayered](../TextureLayered) can be loaded with <a href=\"../ResourceLoader#load\">ResourceLoader.load<a>.\nInternally, Godot maps these files to their respective counterparts in the target rendering driver (Vulkan, OpenGL3)."
	},
	"TextureButton": {
		"brief_description": "Texture-based button. Supports Pressed, Hover, Disabled and Focused states.",
		"description": "[TextureButton](../TextureButton) has the same functionality as [Button](../Button), except it uses sprites instead of Godot's [Theme](../Theme) resource. It is faster to create, but it doesn't support localization like more complex [Control](../Control)s.\nThe \"normal\" state must contain a texture (<a href=\"#texture_normal\">texture_normal</a>); other textures are optional.\nSee also [BaseButton](../BaseButton) which contains common properties and methods associated with this node."
	},
	"Texture3D": {
		"brief_description": "Base class for 3-dimensionnal textures.",
		"description": "Base class for [ImageTexture3D](../ImageTexture3D) and [CompressedTexture3D](../CompressedTexture3D). Cannot be used directly, but contains all the functions necessary for accessing the derived resource types. [Texture3D](../Texture3D) is the base class for all 3-dimensional texture types. See also [TextureLayered](../TextureLayered).\nAll images need to have the same width, height and number of mipmap levels.\nTo create such a texture file yourself, reimport your image files using the Godot Editor import presets."
	},
	"Texture2DArray": {
		"brief_description": "A single texture resource which consists of multiple, separate images. Each image has the same dimensions and number of mipmap levels.",
		"description": "A Texture2DArray is different from a Texture3D: The Texture2DArray does not support trilinear interpolation between the [Image](../Image)s, i.e. no blending. See also [Cubemap](../Cubemap) and [CubemapArray](../CubemapArray), which are texture arrays with specialized cubemap functions.\nA Texture2DArray is also different from an [AtlasTexture](../AtlasTexture): In a Texture2DArray, all images are treated separately. In an atlas, the regions (i.e. the single images) can be of different sizes. Furthermore, you usually need to add a padding around the regions, to prevent accidental UV mapping to more than one region. The same goes for mipmapping: Mipmap chains are handled separately for each layer. In an atlas, the slicing has to be done manually in the fragment shader.\nTo create such a texture file yourself, reimport your image files using the Godot Editor import presets."
	},
	"Texture2D": {
		"brief_description": "Texture for 2D and 3D.",
		"description": "A texture works by registering an image in the video hardware, which then can be used in 3D models or 2D [Sprite2D](../Sprite2D) or GUI [Control](../Control).\nTextures are often created by loading them from a file. See [method @GDScript.load].\n[Texture2D](../Texture2D) is a base for other resources. It cannot be used directly.\n<b>Note:</b> The maximum texture size is 1638416384 pixels due to graphics hardware limitations. Larger textures may fail to import."
	},
	"Texture": {
		"brief_description": "Base class for all texture types.",
		"description": "[Texture](../Texture) is the base class for all texture types. Common texture types are [Texture2D](../Texture2D) and [ImageTexture](../ImageTexture). See also [Image](../Image)."
	},
	"TextServerManager": {
		"brief_description": "Manager for the font and complex text layout servers.",
		"description": "[TextServerManager](../TextServerManager) is the API backend for loading, enumeration and switching [TextServer](../TextServer)s.\n<b>Note:</b> Switching text server at runtime is possible, but will invalidate all fonts and text buffers. Make sure to unload all controls, fonts, and themes before doing so."
	},
	"TextServerExtension": {
		"brief_description": "Base class for TextServer custom implementations (plugins).",
		"description": "External TextServer implementations should inherit from this class."
	},
	"TextServerDummy": {
		"brief_description": "",
		"description": ""
	},
	"TextServer": {
		"brief_description": "Interface for the fonts and complex text layouts.",
		"description": "[TextServer](../TextServer) is the API backend for managing fonts, and rendering complex text."
	},
	"TextParagraph": {
		"brief_description": "Holds a paragraph of text.",
		"description": "Abstraction over [TextServer](../TextServer) for handling paragraph of text."
	},
	"TextMesh": {
		"brief_description": "Generate an [PrimitiveMesh](../PrimitiveMesh) from the text.",
		"description": "Generate an [PrimitiveMesh](../PrimitiveMesh) from the text.\nTextMesh can be generated only when using dynamic fonts with vector glyph contours. Bitmap fonts (including bitmap data in the TrueType/OpenType containers, like color emoji fonts) are not supported.\nThe UV layout is arranged in 4 horizontal strips, top to bottom: 40% of the height for the front face, 40% for the back face, 10% for the outer edges and 10% for the inner edges."
	},
	"TextLine": {
		"brief_description": "Holds a line of text.",
		"description": "Abstraction over [TextServer](../TextServer) for handling single line of text."
	},
	"TextEdit": {
		"brief_description": "Multiline text editing control.",
		"description": "TextEdit is meant for editing large, multiline text. It also has facilities for editing code, such as syntax highlighting support and multiple levels of undo/redo.\n<b>Note:</b> Most viewport, caret and edit methods contain a <code>caret_index</code> argument for <a href=\"#caret_multiple\">caret_multiple</a> support. The argument should be one of the following: <code>-1</code> for all carets, <code>0</code> for the main caret, or greater than <code>0</code> for secondary carets.\n<b>Note:</b> When holding down <kbd>Alt</kbd>, the vertical scroll wheel will scroll 5 times as fast as it would normally do. This also works in the Godot script editor."
	},
	"TCPServer": {
		"brief_description": "A TCP server.",
		"description": "A TCP server. Listens to connections on a port and returns a [StreamPeerTCP](../StreamPeerTCP) when it gets an incoming connection.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"TabContainer": {
		"brief_description": "Tabbed container.",
		"description": "Arranges [Control](../Control) children into a tabbed view, creating a tab for each one. The active tab's corresponding [Control](../Control) has its <code>visible</code> property set to <code>true</code>, and all other children's to <code>false</code>.\nIgnores non-[Control](../Control) children.\n<b>Note:</b> The drawing of the clickable tabs themselves is handled by this node. Adding [TabBar](../TabBar)s as children is not needed."
	},
	"TabBar": {
		"brief_description": "Tab bar control.",
		"description": "Simple tabs control, similar to [TabContainer](../TabContainer) but is only in charge of drawing tabs, not interacting with children."
	},
	"SystemFont": {
		"brief_description": "Font loaded from a system font.\n<b>Note:</b> This class is implemented on iOS, Linux, macOS and Windows, on other platforms it will fallback to default theme font.",
		"description": "[SystemFont](../SystemFont) loads a font from a system font with the first matching name from <a href=\"#font_names\">font_names</a>.\nIt will attempt to match font style, but it's not guaranteed.\nThe returned font might be part of a font collection or be a variable font with OpenType \"weight\", \"width\" and/or \"italic\" features set.\nYou can create [FontVariation](../FontVariation) of the system font for fine control over its features."
	},
	"SyntaxHighlighter": {
		"brief_description": "Base Syntax highlighter resource for [TextEdit](../TextEdit).",
		"description": "Base syntax highlighter resource all syntax highlighters extend from, provides syntax highlighting data to [TextEdit](../TextEdit).\nThe associated [TextEdit](../TextEdit) node will call into the [SyntaxHighlighter](../SyntaxHighlighter) on a as needed basis.\n<b>Note:</b> Each Syntax highlighter instance should not be shared across multiple [TextEdit](../TextEdit) nodes."
	},
	"SurfaceTool": {
		"brief_description": "Helper tool to create geometry.",
		"description": "The [SurfaceTool](../SurfaceTool) is used to construct a [Mesh](../Mesh) by specifying vertex attributes individually. It can be used to construct a [Mesh](../Mesh) from a script. All properties except indices need to be added before calling <a href=\"#add_vertex\">add_vertex</a>. For example, to add vertex colors and UVs:\n<!-- <codeblocks> -->\n<code>\nvar st = SurfaceTool.new()\nst.begin(Mesh.PRIMITIVE_TRIANGLES)\nst.set_color(Color(1, 0, 0))\nst.set_uv(Vector2(0, 0))\nst.add_vertex(Vector3(0, 0, 0))\n</code>\n```csharp\nvar st = new SurfaceTool();\nst.Begin(Mesh.PrimitiveType.Triangles);\nst.SetColor(new Color(1, 0, 0));\nst.SetUv(new Vector2(0, 0));\nst.AddVertex(new Vector3(0, 0, 0));\n```\n<!-- </codeblocks> -->\nThe above [SurfaceTool](../SurfaceTool) now contains one vertex of a triangle which has a UV coordinate and a specified [Color](../Color). If another vertex were added without calling <a href=\"#set_uv\">set_uv</a> or <a href=\"#set_color\">set_color</a>, then the last values would be used.\nVertex attributes must be passed <b>before</b> calling <a href=\"#add_vertex\">add_vertex</a>. Failure to do so will result in an error when committing the vertex information to a mesh.\nAdditionally, the attributes used before the first vertex is added determine the format of the mesh. For example, if you only add UVs to the first vertex, you cannot add color to any of the subsequent vertices.\nSee also [ArrayMesh](../ArrayMesh), [ImmediateMesh](../ImmediateMesh) and [MeshDataTool](../MeshDataTool) for procedural geometry generation.\n<b>Note:</b> Godot uses clockwise [winding order](https://learnopengl.com/Advanced-OpenGL/Face-culling) for front faces of triangle primitive modes."
	},
	"SubViewportContainer": {
		"brief_description": "Control for holding [SubViewport](../SubViewport)s.",
		"description": "A [Container](../Container) node that holds a [SubViewport](../SubViewport). It uses the [SubViewport](../SubViewport)'s size as minimum size, unless <a href=\"#stretch\">stretch</a> is enabled.\n<b>Note:</b> Changing a SubViewportContainer's <a href=\"../Control#scale\">Control.scale<a> will cause its contents to appear distorted. To change its visual size without causing distortion, adjust the node's margins instead (if it's not already in a container).\n<b>Note:</b> The SubViewportContainer forwards mouse-enter and mouse-exit notifications to its sub-viewports."
	},
	"SubViewport": {
		"brief_description": "Creates a sub-view into the screen.",
		"description": "[SubViewport](../SubViewport) is a [Viewport](../Viewport) that isn't a [Window](../Window), i.e. it doesn't draw anything by itself. To display something, [SubViewport](../SubViewport)'s <a href=\"#size\">size</a> must be non-zero and it should be either put inside a [SubViewportContainer](../SubViewportContainer) or assigned to a [ViewportTexture](../ViewportTexture)."
	},
	"StyleBoxTexture": {
		"brief_description": "Texture-based nine-patch [StyleBox](../StyleBox).",
		"description": "Texture-based nine-patch [StyleBox](../StyleBox), in a way similar to [NinePatchRect](../NinePatchRect). This stylebox performs a 33 scaling of a texture, where only the center cell is fully stretched. This makes it possible to design bordered styles regardless of the stylebox's size."
	},
	"StyleBoxLine": {
		"brief_description": "[StyleBox](../StyleBox) that displays a single line.",
		"description": "[StyleBox](../StyleBox) that displays a single line of a given color and thickness. It can be used to draw things like separators."
	},
	"StyleBoxFlat": {
		"brief_description": "Customizable [StyleBox](../StyleBox) with a given set of parameters (no texture required).",
		"description": "This [StyleBox](../StyleBox) can be used to achieve all kinds of looks without the need of a texture. The following properties are customizable:\n- Color\n- Border width (individual width for each border)\n- Rounded corners (individual radius for each corner)\n- Shadow (with blur and offset)\nSetting corner radius to high values is allowed. As soon as corners overlap, the stylebox will switch to a relative system.\n<b>Example:</b>\n<code>\nheight = 30\ncorner_radius_top_left = 50\ncorner_radius_bottom_left = 100\n</code>\nThe relative system now would take the 1:2 ratio of the two left corners to calculate the actual corner width. Both corners added will <b>never</b> be more than the height. Result:\n<code>\ncorner_radius_top_left: 10\ncorner_radius_bottom_left: 20\n</code>"
	},
	"StyleBoxEmpty": {
		"brief_description": "Empty stylebox (does not display anything).",
		"description": "Empty stylebox (really does not display anything)."
	},
	"StyleBox": {
		"brief_description": "Base class for drawing stylized boxes for the UI.",
		"description": "StyleBox is [Resource](../Resource) that provides an abstract base class for drawing stylized boxes for the UI. StyleBoxes are used for drawing the styles of buttons, line edit backgrounds, tree backgrounds, etc. and also for testing a transparency mask for pointer signals. If mask test fails on a StyleBox assigned as mask to a control, clicks and motion signals will go through it to the one below.\n<b>Note:</b> For children of [Control](../Control) that have <i>Theme Properties</i>, the <code>focus</code> [StyleBox](../StyleBox) is displayed over the <code>normal</code>, <code>hover</code> or <code>pressed</code> [StyleBox](../StyleBox). This makes the <code>focus</code> [StyleBox](../StyleBox) more reusable across different nodes."
	},
	"StringName": {
		"brief_description": "An optimized string type for unique names.",
		"description": "[StringName](../StringName)s are immutable strings designed for general-purpose representation of unique names (also called \"string interning\"). [StringName](../StringName) ensures that only one instance of a given name exists (so two [StringName](../StringName)s with the same value are the same object). Comparing them is much faster than with regular [String](../String)s, because only the pointers are compared, not the whole strings.\nYou will usually just pass a [String](../String) to methods expecting a [StringName](../StringName) and it will be automatically converted, but you may occasionally want to construct a [StringName](../StringName) ahead of time with the [StringName](../StringName) constructor or, in GDScript, the literal syntax <code>&\"example\"</code>.\nSee also [NodePath](../NodePath), which is a similar concept specifically designed to store pre-parsed node paths.\nSome string methods have corresponding variations. Variations suffixed with <code>n</code> (<a href=\"#countn\">countn</a>, <a href=\"#findn\">findn</a>, <a href=\"#replacen\">replacen</a>, etc.) are <b>case-insensitive</b> (they make no distinction between uppercase and lowercase letters). Method variations prefixed with <code>r</code> (<a href=\"#rfind\">rfind</a>, <a href=\"#rsplit\">rsplit</a>, etc.) are reversed, and start from the end of the string, instead of the beginning.\n<b>Note:</b> In a boolean context, a [StringName](../StringName) will evaluate to <code>false</code> if it is empty (<code>StringName(\"\")</code>). Otherwise, a [StringName](../StringName) will always evaluate to <code>true</code>."
	},
	"String": {
		"brief_description": "Built-in string Variant type.",
		"description": "This is the built-in string Variant type (and the one used by GDScript). Strings may contain any number of Unicode characters, and expose methods useful for manipulating and generating strings. Strings are reference-counted and use a copy-on-write approach (every modification to a string returns a new [String](../String)), so passing them around is cheap in resources.\nSome string methods have corresponding variations. Variations suffixed with <code>n</code> (<a href=\"#countn\">countn</a>, <a href=\"#findn\">findn</a>, <a href=\"#replacen\">replacen</a>, etc.) are <b>case-insensitive</b> (they make no distinction between uppercase and lowercase letters). Method variations prefixed with <code>r</code> (<a href=\"#rfind\">rfind</a>, <a href=\"#rsplit\">rsplit</a>, etc.) are reversed, and start from the end of the string, instead of the beginning.\n<b>Note:</b> In a boolean context, a string will evaluate to <code>false</code> if it is empty (<code>\"\"</code>). Otherwise, a string will always evaluate to <code>true</code>."
	},
	"StreamPeerTLS": {
		"brief_description": "TLS stream peer.",
		"description": "TLS stream peer. This object can be used to connect to an TLS server or accept a single TLS client connection.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"StreamPeerTCP": {
		"brief_description": "TCP stream peer.",
		"description": "TCP stream peer. This object can be used to connect to TCP servers, or also is returned by a TCP server.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"StreamPeerGZIP": {
		"brief_description": "Stream peer handling GZIP and deflate compression/decompresison.",
		"description": "This class allows to compress or decompress data using GZIP/deflate in a streaming fashion. This is particularly useful when compressing or decompressing files that has to be sent through the network without having to allocate them all in memory.\nAfter starting the stream via <a href=\"#start_compression\">start_compression</a> (or <a href=\"#start_decompression\">start_decompression</a>), calling <a href=\"../StreamPeer#put_partial_data\">StreamPeer.put_partial_data<a> on this stream will compress (or decompress) the data, writing it to the internal buffer. Calling <a href=\"../StreamPeer#get_available_bytes\">StreamPeer.get_available_bytes<a> will return the pending bytes in the internal buffer, and <a href=\"../StreamPeer#get_partial_data\">StreamPeer.get_partial_data<a> will retrieve the compressed (or decompressed) bytes from it. When the stream is over, you must call <a href=\"#finish\">finish</a> to ensure the internal buffer is properly flushed (make sure to call <a href=\"../StreamPeer#get_available_bytes\">StreamPeer.get_available_bytes<a> on last time to check if more data needs to be read after that)."
	},
	"StreamPeerExtension": {
		"brief_description": "",
		"description": ""
	},
	"StreamPeerBuffer": {
		"brief_description": "Data buffer stream peer.",
		"description": "Data buffer stream peer that uses a byte array as the stream. This object can be used to handle binary data from network sessions. To handle binary data stored in files, [FileAccess](../FileAccess) can be used directly.\nA [StreamPeerBuffer](../StreamPeerBuffer) object keeps an internal cursor which is the offset in bytes to the start of the buffer. Get and put operations are performed at the cursor position and will move the cursor accordingly."
	},
	"StreamPeer": {
		"brief_description": "Abstraction and base class for stream-based protocols.",
		"description": "StreamPeer is an abstraction and base class for stream-based protocols (such as TCP). It provides an API for sending and receiving data through streams as raw data or strings.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"StaticBody3D": {
		"brief_description": "Physics body for 3D physics which is static or moves only by script. Useful for floor and walls.",
		"description": "Static body for 3D physics.\nA static body is a simple body that doesn't move under physics simulation, i.e. it can't be moved by external forces or contacts but its transformation can still be updated manually by the user. It is ideal for implementing objects in the environment, such as walls or platforms. In contrast to [RigidBody3D](../RigidBody3D), it doesn't consume any CPU resources as long as they don't move.\nThey have extra functionalities to move and affect other bodies:\n<i>Static transform change:</i> Static bodies can be moved by animation or script. In this case, they are just teleported and don't affect other bodies on their path.\n<i>Constant velocity:</i> When <a href=\"#constant_linear_velocity\">constant_linear_velocity</a> or <a href=\"#constant_angular_velocity\">constant_angular_velocity</a> is set, static bodies don't move themselves but affect touching bodies as if they were moving. This is useful for simulating conveyor belts or conveyor wheels.\n<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"StaticBody2D": {
		"brief_description": "Physics body for 2D physics which is static or moves only by script. Useful for floor and walls.",
		"description": "Static body for 2D physics.\nA static body is a simple body that doesn't move under physics simulation, i.e. it can't be moved by external forces or contacts but its transformation can still be updated manually by the user. It is ideal for implementing objects in the environment, such as walls or platforms. In contrast to [RigidBody2D](../RigidBody2D), it doesn't consume any CPU resources as long as they don't move.\nThey have extra functionalities to move and affect other bodies:\n<b>Static transform change:</b> Static bodies can be moved by animation or script. In this case, they are just teleported and don't affect other bodies on their path.\n<b>Constant velocity:</b> When <a href=\"#constant_linear_velocity\">constant_linear_velocity</a> or <a href=\"#constant_angular_velocity\">constant_angular_velocity</a> is set, static bodies don't move themselves but affect touching bodies as if they were moving. This is useful for simulating conveyor belts or conveyor wheels."
	},
	"StandardMaterial3D": {
		"brief_description": "Physically based rendering (PBR) material that can be applied to 3D objects.",
		"description": "[StandardMaterial3D](../StandardMaterial3D)'s properties are inherited from [BaseMaterial3D](../BaseMaterial3D). [StandardMaterial3D](../StandardMaterial3D) uses separate textures for ambient occlusion, roughness and metallic maps. To use a single ORM map for all 3 textures, use an [ORMMaterial3D](../ORMMaterial3D) instead."
	},
	"SpriteFrames": {
		"brief_description": "Sprite frame library for AnimatedSprite2D and AnimatedSprite3D.",
		"description": "Sprite frame library for an [AnimatedSprite2D](../AnimatedSprite2D) or [AnimatedSprite3D](../AnimatedSprite3D) node. Contains frames and animation data for playback."
	},
	"SpriteBase3D": {
		"brief_description": "2D sprite node in 3D environment.",
		"description": "A node that displays 2D texture information in a 3D environment. See also [Sprite3D](../Sprite3D) where many other properties are defined."
	},
	"Sprite3D": {
		"brief_description": "2D sprite node in a 3D world.",
		"description": "A node that displays a 2D texture in a 3D environment. The texture displayed can be a region from a larger atlas texture, or a frame from a sprite sheet animation. See also [SpriteBase3D](../SpriteBase3D) where properties such as the billboard mode are defined."
	},
	"Sprite2D": {
		"brief_description": "General-purpose sprite node.",
		"description": "A node that displays a 2D texture. The texture displayed can be a region from a larger atlas texture, or a frame from a sprite sheet animation."
	},
	"SpringArm3D": {
		"brief_description": "A helper node, mostly used in 3rd person cameras.",
		"description": "The SpringArm3D node is a node that casts a ray (or collision shape) along its z axis and moves all its direct children to the collision point, minus a margin.\nThe most common use case for this is to make a 3rd person camera that reacts to collisions in the environment.\nThe SpringArm3D will either cast a ray, or if a shape is given, it will cast the shape in the direction of its z axis.\nIf you use the SpringArm3D as a camera controller for your player, you might need to exclude the player's collider from the SpringArm3D's collision check."
	},
	"SpotLight3D": {
		"brief_description": "A spotlight, such as a reflector spotlight or a lantern.",
		"description": "A Spotlight is a type of [Light3D](../Light3D) node that emits lights in a specific direction, in the shape of a cone. The light is attenuated through the distance. This attenuation can be configured by changing the energy, radius and attenuation parameters of [Light3D](../Light3D).\n<b>Note:</b> When using the Mobile rendering method, only 8 spot lights can be displayed on each mesh resource. Attempting to display more than 8 spot lights on a single mesh resource will result in spot lights flickering in and out as the camera moves. When using the Compatibility rendering method, only 8 spot lights can be displayed on each mesh resource by default, but this can be increased by adjusting [member ProjectSettings.rendering/limits/opengl/max_lights_per_object].\n<b>Note:</b> When using the Mobile or Compatibility rendering methods, spot lights will only correctly affect meshes whose visibility AABB intersects with the light's AABB. If using a shader to deform the mesh in a way that makes it go outside its AABB, <a href=\"../GeometryInstance3D#extra_cull_margin\">GeometryInstance3D.extra_cull_margin<a> must be increased on the mesh. Otherwise, the light may not be visible on the mesh."
	},
	"SplitContainer": {
		"brief_description": "Container for splitting and adjusting.",
		"description": "Container for splitting two [Control](../Control)s vertically or horizontally, with a grabber that allows adjusting the split offset or ratio."
	},
	"SpinBox": {
		"brief_description": "Numerical input text field.",
		"description": "SpinBox is a numerical input text field. It allows entering integers and floats.\n<b>Example:</b>\n<!-- <codeblocks> -->\n<code>\nvar spin_box = SpinBox.new()\nadd_child(spin_box)\nvar line_edit = spin_box.get_line_edit()\nline_edit.context_menu_enabled = false\nspin_box.horizontal_alignment = LineEdit.HORIZONTAL_ALIGNMENT_RIGHT\n</code>\n```csharp\nvar spinBox = new SpinBox();\nAddChild(spinBox);\nvar lineEdit = spinBox.GetLineEdit();\nlineEdit.ContextMenuEnabled = false;\nspinBox.AlignHorizontal = LineEdit.HorizontalAlignEnum.Right;\n```\n<!-- </codeblocks> -->\nThe above code will create a [SpinBox](../SpinBox), disable context menu on it and set the text alignment to right.\nSee [Range](../Range) class for more options over the [SpinBox](../SpinBox).\n<b>Note:</b> [SpinBox](../SpinBox) relies on an underlying [LineEdit](../LineEdit) node. To theme a [SpinBox](../SpinBox)'s background, add theme items for [LineEdit](../LineEdit) and customize them.\n<b>Note:</b> If you want to implement drag and drop for the underlying [LineEdit](../LineEdit), you can use <a href=\"../Control#set_drag_forwarding\">Control.set_drag_forwarding<a> on the node returned by <a href=\"#get_line_edit\">get_line_edit</a>."
	},
	"SphereShape3D": {
		"brief_description": "Sphere shape resource for 3D collisions.",
		"description": "3D sphere shape to be added as a <i>direct</i> child of a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D) using a [CollisionShape3D](../CollisionShape3D) node. This shape is useful for modeling sphere-like 3D objects.\n<b>Performance:</b> Being a primitive collision shape, [SphereShape3D](../SphereShape3D) is the fastest collision shape to check collisions against, as it only requires a distance check with the shape's origin."
	},
	"SphereOccluder3D": {
		"brief_description": "Spherical shape for use with occlusion culling in [OccluderInstance3D](../OccluderInstance3D).",
		"description": "[SphereOccluder3D](../SphereOccluder3D) stores a sphere shape that can be used by the engine's occlusion culling system.\nSee [OccluderInstance3D](../OccluderInstance3D)'s documentation for instructions on setting up occlusion culling."
	},
	"SphereMesh": {
		"brief_description": "Class representing a spherical [PrimitiveMesh](../PrimitiveMesh).",
		"description": "Class representing a spherical [PrimitiveMesh](../PrimitiveMesh)."
	},
	"SoftBody3D": {
		"brief_description": "A soft mesh physics body.",
		"description": "A deformable physics body. Used to create elastic or deformable objects such as cloth, rubber, or other flexible materials.\n<b>Note:</b> There are many known bugs in [SoftBody3D](../SoftBody3D). Therefore, it's not recommended to use them for things that can affect gameplay (such as a player character made entirely out of soft bodies)."
	},
	"SliderJoint3D": {
		"brief_description": "Slider between two PhysicsBodies in 3D.",
		"description": "Slides across the X axis of the pivot object. See also [Generic6DOFJoint3D](../Generic6DOFJoint3D)."
	},
	"Slider": {
		"brief_description": "Base class for GUI sliders.",
		"description": "Base class for GUI sliders.\n<b>Note:</b> The <a href=\"../Range#changed\">Range.changed<a> and <a href=\"../Range#value_changed\">Range.value_changed<a> signals are part of the [Range](../Range) class which this class inherits from."
	},
	"Sky": {
		"brief_description": "Background that uses a [Material](../Material) to draw a sky.",
		"description": "The [Sky](../Sky) class uses a [Material](../Material) to draw the background and update the reflection/radiance cubemaps."
	},
	"SkinReference": {
		"brief_description": "",
		"description": ""
	},
	"Skin": {
		"brief_description": "",
		"description": ""
	},
	"SkeletonProfileHumanoid": {
		"brief_description": "A humanoid [SkeletonProfile](../SkeletonProfile) preset.",
		"description": "A [SkeletonProfile](../SkeletonProfile) as a preset that is optimized for the human form. This exists for standardization, so all parameters are read-only."
	},
	"SkeletonProfile": {
		"brief_description": "Profile of a virtual skeleton used as a target for retargeting.",
		"description": "This resource is used in [EditorScenePostImport](../EditorScenePostImport). Some parameters are referring to bones in [Skeleton3D](../Skeleton3D), [Skin](../Skin), [Animation](../Animation), and some other nodes are rewritten based on the parameters of [SkeletonProfile](../SkeletonProfile).\n<b>Note:</b> These parameters need to be set only when creating a custom profile. In [SkeletonProfileHumanoid](../SkeletonProfileHumanoid), they are defined internally as read-only values."
	},
	"SkeletonModificationStack2D": {
		"brief_description": "A resource that holds a stack of [SkeletonModification2D](../SkeletonModification2D)s.",
		"description": "This resource is used by the Skeleton and holds a stack of [SkeletonModification2D](../SkeletonModification2D)s.\nThis controls the order of the modifications and how they are applied. Modification order is especially important for full-body IK setups, as you need to execute the modifications in the correct order to get the desired results. For example, you want to execute a modification on the spine <i>before</i> the arms on a humanoid skeleton.\nThis resource also controls how strongly all of the modifications are applied to the [Skeleton2D](../Skeleton2D)."
	},
	"SkeletonModification2DTwoBoneIK": {
		"brief_description": "A modification that rotates two bones using the law of cosigns to reach the target.",
		"description": "This [SkeletonModification2D](../SkeletonModification2D) uses an algorithm typically called TwoBoneIK. This algorithm works by leveraging the law of cosigns and the lengths of the bones to figure out what rotation the bones currently have, and what rotation they need to make a complete triangle, where the first bone, the second bone, and the target form the three vertices of the triangle. Because the algorithm works by making a triangle, it can only operate on two bones.\nTwoBoneIK is great for arms, legs, and really any joints that can be represented by just two bones that bend to reach a target. This solver is more lightweight than [SkeletonModification2DFABRIK](../SkeletonModification2DFABRIK), but gives similar, natural looking results."
	},
	"SkeletonModification2DStackHolder": {
		"brief_description": "A modification that holds and executes a [SkeletonModificationStack2D](../SkeletonModificationStack2D).",
		"description": "This [SkeletonModification2D](../SkeletonModification2D) holds a reference to a [SkeletonModificationStack2D](../SkeletonModificationStack2D), allowing you to use multiple modification stacks on a single [Skeleton2D](../Skeleton2D).\n<b>Note:</b> The modifications in the held [SkeletonModificationStack2D](../SkeletonModificationStack2D) will only be executed if their execution mode matches the execution mode of the SkeletonModification2DStackHolder."
	},
	"SkeletonModification2DPhysicalBones": {
		"brief_description": "A modification that applies the transforms of [PhysicalBone2D](../PhysicalBone2D) nodes to [Bone2D](../Bone2D) nodes.",
		"description": "This modification takes the transforms of [PhysicalBone2D](../PhysicalBone2D) nodes and applies them to [Bone2D](../Bone2D) nodes. This allows the [Bone2D](../Bone2D) nodes to react to physics thanks to the linked [PhysicalBone2D](../PhysicalBone2D) nodes.\nExperimental. Physical bones may be changed in the future to perform the position update of [Bone2D](../Bone2D) on their own."
	},
	"SkeletonModification2DLookAt": {
		"brief_description": "A modification that rotates a [Bone2D](../Bone2D) node to look at a target.",
		"description": "This [SkeletonModification2D](../SkeletonModification2D) rotates a bone to look a target. This is extremely helpful for moving character's head to look at the player, rotating a turret to look at a target, or any other case where you want to make a bone rotate towards something quickly and easily."
	},
	"SkeletonModification2DJiggle": {
		"brief_description": "A modification that jiggles [Bone2D](../Bone2D) nodes as they move towards a target.",
		"description": "This modification moves a series of bones, typically called a bone chain, towards a target. What makes this modification special is that it calculates the velocity and acceleration for each bone in the bone chain, and runs a very light physics-like calculation using the inputted values. This allows the bones to overshoot the target and \"jiggle\" around. It can be configured to act more like a spring, or sway around like cloth might.\nThis modification is useful for adding additional motion to things like hair, the edges of clothing, and more. It has several settings to that allow control over how the joint moves when the target moves.\n<b>Note:</b> The Jiggle modifier has <code>jiggle_joints</code>, which are the data objects that hold the data for each joint in the Jiggle chain. This is different from than [Bone2D](../Bone2D) nodes! Jiggle joints hold the data needed for each [Bone2D](../Bone2D) in the bone chain used by the Jiggle modification."
	},
	"SkeletonModification2DFABRIK": {
		"brief_description": "A modification that uses FABRIK to manipulate a series of [Bone2D](../Bone2D) nodes to reach a target.",
		"description": "This [SkeletonModification2D](../SkeletonModification2D) uses an algorithm called Forward And Backward Reaching Inverse Kinematics, or FABRIK, to rotate a bone chain so that it reaches a target.\nFABRIK works by knowing the positions and lengths of a series of bones, typically called a \"bone chain\". It first starts by running a forward pass, which places the final bone at the target's position. Then all other bones are moved towards the tip bone, so they stay at the defined bone length away. Then a backwards pass is performed, where the root/first bone in the FABRIK chain is placed back at the origin. then all other bones are moved so they stay at the defined bone length away. This positions the bone chain so that it reaches the target when possible, but all of the bones stay the correct length away from each other.\nBecause of how FABRIK works, it often gives more natural results than those seen in [SkeletonModification2DCCDIK](../SkeletonModification2DCCDIK). FABRIK also supports angle constraints, which are fully taken into account when solving.\n<b>Note:</b> The FABRIK modifier has <code>fabrik_joints</code>, which are the data objects that hold the data for each joint in the FABRIK chain. This is different from [Bone2D](../Bone2D) nodes! FABRIK joints hold the data needed for each [Bone2D](../Bone2D) in the bone chain used by FABRIK.\nTo help control how the FABRIK joints move, a magnet vector can be passed, which can nudge the bones in a certain direction prior to solving, giving a level of control over the final result."
	},
	"SkeletonModification2DCCDIK": {
		"brief_description": "A modification that uses CCDIK to manipulate a series of bones to reach a target in 2D.",
		"description": "This [SkeletonModification2D](../SkeletonModification2D) uses an algorithm called Cyclic Coordinate Descent Inverse Kinematics, or CCDIK, to manipulate a chain of bones in a [Skeleton2D](../Skeleton2D) so it reaches a defined target.\nCCDIK works by rotating a set of bones, typically called a \"bone chain\", on a single axis. Each bone is rotated to face the target from the tip (by default), which over a chain of bones allow it to rotate properly to reach the target. Because the bones only rotate on a single axis, CCDIK <i>can</i> look more robotic than other IK solvers.\n<b>Note:</b> The CCDIK modifier has <code>ccdik_joints</code>, which are the data objects that hold the data for each joint in the CCDIK chain. This is different from a bone! CCDIK joints hold the data needed for each bone in the bone chain used by CCDIK.\nCCDIK also fully supports angle constraints, allowing for more control over how a solution is met."
	},
	"SkeletonModification2D": {
		"brief_description": "A resource that operates on [Bone2D](../Bone2D) nodes in a [Skeleton2D](../Skeleton2D).",
		"description": "This resource provides an interface that can be expanded so code that operates on [Bone2D](../Bone2D) nodes in a [Skeleton2D](../Skeleton2D) can be mixed and matched together to create complex interactions.\nThis is used to provide Godot with a flexible and powerful Inverse Kinematics solution that can be adapted for many different uses."
	},
	"SkeletonIK3D": {
		"brief_description": "SkeletonIK3D is used to place the end bone of a [Skeleton3D](../Skeleton3D) bone chain at a certain point in 3D by rotating all bones in the chain accordingly.",
		"description": "SkeletonIK3D is used to place the end bone of a [Skeleton3D](../Skeleton3D) bone chain at a certain point in 3D by rotating all bones in the chain accordingly. A typical scenario for IK in games is to place a characters feet on the ground or a characters hands on a currently hold object. SkeletonIK uses FabrikInverseKinematic internally to solve the bone chain and applies the results to the [Skeleton3D](../Skeleton3D) <code>bones_global_pose_override</code> property for all affected bones in the chain. If fully applied this overwrites any bone transform from [Animation](../Animation)s or bone custom poses set by users. The applied amount can be controlled with the <code>interpolation</code> property.\n<code>\n# Apply IK effect automatically on every new frame (not the current)\nskeleton_ik_node.start()\n\n# Apply IK effect only on the current frame\nskeleton_ik_node.start(true)\n\n# Stop IK effect and reset bones_global_pose_override on Skeleton\nskeleton_ik_node.stop()\n\n# Apply full IK effect\nskeleton_ik_node.set_interpolation(1.0)\n\n# Apply half IK effect\nskeleton_ik_node.set_interpolation(0.5)\n\n# Apply zero IK effect (a value at or below 0.01 also removes bones_global_pose_override on Skeleton)\nskeleton_ik_node.set_interpolation(0.0)\n</code>"
	},
	"Skeleton3D": {
		"brief_description": "Skeleton for characters and animated objects.",
		"description": "Skeleton3D provides a hierarchical interface for managing bones, including pose, rest and animation (see [Animation](../Animation)). It can also use ragdoll physics.\nThe overall transform of a bone with respect to the skeleton is determined by the following hierarchical order: rest pose, custom pose and pose.\nNote that \"global pose\" below refers to the overall transform of the bone with respect to skeleton, so it not the actual global/world transform of the bone.\nTo setup different types of inverse kinematics, consider using [SkeletonIK3D](../SkeletonIK3D), or add a custom IK implementation in <a href=\"../Node#_process\">Node._process<a> as a child node."
	},
	"Skeleton2D": {
		"brief_description": "Skeleton for 2D characters and animated objects.",
		"description": "Skeleton2D parents a hierarchy of [Bone2D](../Bone2D) objects. It is a requirement of [Bone2D](../Bone2D). Skeleton2D holds a reference to the rest pose of its children and acts as a single point of access to its bones.\nTo setup different types of inverse kinematics for the given Skeleton2D, a [SkeletonModificationStack2D](../SkeletonModificationStack2D) should be created. They can be applied by creating the desired number of modifications, which can be done by increasing <a href=\"../SkeletonModificationStack2D#modification_count\">SkeletonModificationStack2D.modification_count<a>."
	},
	"Signal": {
		"brief_description": "Built-in type representing a signal defined in an object.",
		"description": "[Signal](../Signal) is a built-in [Variant](../Variant) type that represents a signal of an [Object](../Object) instance. Like all [Variant](../Variant) types, it can be stored in variables and passed to functions. Signals allow all connected [Callable](../Callable)s (and by extension their respective objects) to listen and react to events, without directly referencing one another. This keeps the code flexible and easier to manage.\nIn GDScript, signals can be declared with the <code>signal</code> keyword. In C#, you may use the <code>[Signal](../Signal)</code> attribute on a delegate.\n<!-- <codeblocks> -->\n<code>\nsignal attacked\n\n# Additional arguments may be declared.\n# These arguments must be passed when the signal is emitted.\nsignal item_dropped(item_name, amount)\n</code>\n```csharp\n[Signal](../Signal)\ndelegate void AttackedEventHandler();\n\n// Additional arguments may be declared.\n// These arguments must be passed when the signal is emitted.\n[Signal](../Signal)\ndelegate void ItemDroppedEventHandler(string itemName, int amount);\n```\n<!-- </codeblocks> -->"
	},
	"Shortcut": {
		"brief_description": "A shortcut for binding input.",
		"description": "Shortcuts are commonly used for interacting with a [Control](../Control) element from an [InputEvent](../InputEvent) (also known as hotkeys).\nOne shortcut can contain multiple [InputEvent](../InputEvent)'s, allowing the possibility of triggering one action with multiple different inputs."
	},
	"ShapeCast3D": {
		"brief_description": "Node for physics collision sweep and immediate overlap queries. Similar to the [RayCast3D](../RayCast3D) node.",
		"description": "Shape casting allows to detect collision objects by sweeping the <a href=\"#shape\">shape</a> along the cast direction determined by <a href=\"#target_position\">target_position</a> (useful for things like beam weapons).\nImmediate collision overlaps can be done with the <a href=\"#target_position\">target_position</a> set to <code>Vector3(0, 0, 0)</code> and by calling <a href=\"#force_shapecast_update\">force_shapecast_update</a> within the same <b>physics_frame</b>. This also helps to overcome some limitations of [Area3D](../Area3D) when used as a continuous detection area, often requiring waiting a couple of frames before collision information is available to [Area3D](../Area3D) nodes, and when using the signals creates unnecessary complexity.\nThe node can detect multiple collision objects, but it's usually used to detect the first collision.\n<b>Note:</b> Shape casting is more computationally expensive compared to ray casting."
	},
	"ShapeCast2D": {
		"brief_description": "Node for physics collision sweep and immediate overlap queries. Similar to the [RayCast2D](../RayCast2D) node.",
		"description": "Shape casting allows to detect collision objects by sweeping the <a href=\"#shape\">shape</a> along the cast direction determined by <a href=\"#target_position\">target_position</a> (useful for things like beam weapons).\nImmediate collision overlaps can be done with the <a href=\"#target_position\">target_position</a> set to <code>Vector2(0, 0)</code> and by calling <a href=\"#force_shapecast_update\">force_shapecast_update</a> within the same <b>physics_frame</b>. This also helps to overcome some limitations of [Area2D](../Area2D) when used as a continuous detection area, often requiring waiting a couple of frames before collision information is available to [Area2D](../Area2D) nodes, and when using the signals creates unnecessary complexity.\nThe node can detect multiple collision objects, but it's usually used to detect the first collision.\n<b>Note:</b> shape casting is more computationally expensive compared to ray casting."
	},
	"Shape3D": {
		"brief_description": "Base class for all 3D shape resources.",
		"description": "Base class for all 3D shape resources. Nodes that inherit from this can be used as shapes for a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D) objects."
	},
	"Shape2D": {
		"brief_description": "Base class for all 2D shapes.",
		"description": "Base class for all 2D shapes. All 2D shape types inherit from this."
	},
	"ShaderMaterial": {
		"brief_description": "A material that uses a custom [Shader](../Shader) program.",
		"description": "A material that uses a custom [Shader](../Shader) program to render either items to screen or process particles. You can create multiple materials for the same shader but configure different values for the uniforms defined in the shader."
	},
	"ShaderInclude": {
		"brief_description": "",
		"description": ""
	},
	"ShaderGlobalsOverride": {
		"brief_description": "",
		"description": ""
	},
	"Shader": {
		"brief_description": "A custom shader program.",
		"description": "This class allows you to define a custom shader program that can be used by a [ShaderMaterial](../ShaderMaterial). Shaders allow you to write your own custom behavior for rendering objects or updating particle information. For a detailed explanation and usage, please see the tutorials linked below."
	},
	"Separator": {
		"brief_description": "Base class for separators.",
		"description": "Separator is a [Control](../Control) used for separating other controls. It's purely a visual decoration. Horizontal ([HSeparator](../HSeparator)) and Vertical ([VSeparator](../VSeparator)) versions are available."
	},
	"SeparationRayShape3D": {
		"brief_description": "Separation ray shape resource for 3D physics.",
		"description": "3D separation ray shape to be added as a <i>direct</i> child of a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D) using a [CollisionShape3D](../CollisionShape3D) node. A ray is not really a collision body; instead, it tries to separate itself from whatever is touching its far endpoint. It's often useful for characters.\n<b>Performance:</b> Being a primitive collision shape, [SeparationRayShape3D](../SeparationRayShape3D) is fast to check collisions against."
	},
	"SeparationRayShape2D": {
		"brief_description": "Separation ray shape resource for 2D physics.",
		"description": "2D separation ray shape to be added as a <i>direct</i> child of a [PhysicsBody2D](../PhysicsBody2D) or [Area2D](../Area2D) using a [CollisionShape2D](../CollisionShape2D) node. A ray is not really a collision body; instead, it tries to separate itself from whatever is touching its far endpoint. It's often useful for characters.\n<b>Performance:</b> Being a primitive collision shape, [SeparationRayShape2D](../SeparationRayShape2D) is fast to check collisions against."
	},
	"Semaphore": {
		"brief_description": "A synchronization semaphore.",
		"description": "A synchronization semaphore which can be used to synchronize multiple [Thread](../Thread)s. Initialized to zero on creation. Be careful to avoid deadlocks. For a binary version, see [Mutex](../Mutex)."
	},
	"SegmentShape2D": {
		"brief_description": "Segment shape resource for 2D physics.",
		"description": "2D segment shape to be added as a <i>direct</i> child of a [PhysicsBody2D](../PhysicsBody2D) or [Area2D](../Area2D) using a [CollisionShape2D](../CollisionShape2D) node. Consists of two points, <code>a</code> and <code>b</code>.\n<b>Performance:</b> Being a primitive collision shape, [SegmentShape2D](../SegmentShape2D) is fast to check collisions against (though not as fast as [CircleShape2D](../CircleShape2D))."
	},
	"ScrollContainer": {
		"brief_description": "A helper node for displaying scrollable elements such as lists.",
		"description": "A ScrollContainer node meant to contain a [Control](../Control) child.\nScrollContainers will automatically create a scrollbar child ([HScrollBar](../HScrollBar), [VScrollBar](../VScrollBar), or both) when needed and will only draw the Control within the ScrollContainer area. Scrollbars will automatically be drawn at the right (for vertical) or bottom (for horizontal) and will enable dragging to move the viewable Control (and its children) within the ScrollContainer. Scrollbars will also automatically resize the grabber based on the <a href=\"../Control#custom_minimum_size\">Control.custom_minimum_size<a> of the Control relative to the ScrollContainer.\nWorks great with a [Panel](../Panel) control. You can set <a href=\"../Control#SIZE_EXPAND\">Control.SIZE_EXPAND<a> on the children's size flags, so they will upscale to the ScrollContainer's size if it's larger (scroll is invisible for the chosen dimension)."
	},
	"ScrollBar": {
		"brief_description": "Base class for scroll bars.",
		"description": "Scrollbars are a [Range](../Range)-based [Control](../Control), that display a draggable area (the size of the page). Horizontal ([HScrollBar](../HScrollBar)) and Vertical ([VScrollBar](../VScrollBar)) versions are available."
	},
	"ScriptLanguageExtension": {
		"brief_description": "",
		"description": ""
	},
	"ScriptLanguage": {
		"brief_description": "",
		"description": ""
	},
	"ScriptExtension": {
		"brief_description": "",
		"description": ""
	},
	"ScriptEditorBase": {
		"brief_description": "Base editor for editing scripts in the [ScriptEditor](../ScriptEditor).",
		"description": "Base editor for editing scripts in the [ScriptEditor](../ScriptEditor), this does not include documentation items."
	},
	"ScriptEditor": {
		"brief_description": "Godot editor's script editor.",
		"description": "<b>Note:</b> This class shouldn't be instantiated directly. Instead, access the singleton using <a href=\"../EditorInterface#get_script_editor\">EditorInterface.get_script_editor<a>."
	},
	"ScriptCreateDialog": {
		"brief_description": "The Editor's popup dialog for creating new [Script](../Script) files.",
		"description": "The [ScriptCreateDialog](../ScriptCreateDialog) creates script files according to a given template for a given scripting language. The standard use is to configure its fields prior to calling one of the <a href=\"../Window#popup\">Window.popup<a> methods.\n<!-- <codeblocks> -->\n<code>\nfunc _ready():\n\tvar dialog = ScriptCreateDialog.new();\n\tdialog.config(\"Node\", \"res://new_node.gd\") # For in-engine types.\n\tdialog.config(\"\\\"res://base_node.gd\\\"\", \"res://derived_node.gd\") # For script types.\n\tdialog.popup_centered()\n</code>\n```csharp\npublic override void _Ready()\n{\n\tvar dialog = new ScriptCreateDialog();\n\tdialog.Config(\"Node\", \"res://NewNode.cs\"); // For in-engine types.\n\tdialog.Config(\"\\\"res://BaseNode.cs\\\"\", \"res://DerivedNode.cs\"); // For script types.\n\tdialog.PopupCentered();\n}\n```\n<!-- </codeblocks> -->"
	},
	"Script": {
		"brief_description": "A class stored as a resource.",
		"description": "A class stored as a resource. A script extends the functionality of all objects that instantiate it.\nThis is the base class for all scripts and should not be used directly. Trying to create a new script with this class will result in an error.\nThe <code>new</code> method of a script subclass creates a new instance. <a href=\"../Object#set_script\">Object.set_script<a> extends an existing object, if that object's class matches one of the script's base classes."
	},
	"SceneTreeTimer": {
		"brief_description": "One-shot timer.",
		"description": "A one-shot timer managed by the scene tree, which emits <a href=\"#timeout\">timeout</a> on completion. See also <a href=\"../SceneTree#create_timer\">SceneTree.create_timer<a>.\nAs opposed to [Timer](../Timer), it does not require the instantiation of a node. Commonly used to create a one-shot delay timer as in the following example:\n<!-- <codeblocks> -->\n<code>\nfunc some_function():\n\tprint(\"Timer started.\")\n\tawait get_tree().create_timer(1.0).timeout\n\tprint(\"Timer ended.\")\n</code>\n```csharp\npublic async Task SomeFunction()\n{\n\tGD.Print(\"Timer started.\");\n\tawait ToSignal(GetTree().CreateTimer(1.0f), SceneTreeTimer.SignalName.Timeout);\n\tGD.Print(\"Timer ended.\");\n}\n```\n<!-- </codeblocks> -->\nThe timer will be dereferenced after its time elapses. To preserve the timer, you can keep a reference to it. See [RefCounted](../RefCounted)."
	},
	"SceneTree": {
		"brief_description": "Manages the game loop via a hierarchy of nodes.",
		"description": "As one of the most important classes, the [SceneTree](../SceneTree) manages the hierarchy of nodes in a scene as well as scenes themselves. Nodes can be added, retrieved and removed. The whole scene tree (and thus the current scene) can be paused. Scenes can be loaded, switched and reloaded.\nYou can also use the [SceneTree](../SceneTree) to organize your nodes into groups: every node can be assigned as many groups as you want to create, e.g. an \"enemy\" group. You can then iterate these groups or even call methods and set properties on all the group's members at once.\n[SceneTree](../SceneTree) is the default [MainLoop](../MainLoop) implementation used by scenes, and is thus in charge of the game loop."
	},
	"SceneState": {
		"brief_description": "A script interface to a scene file's data.",
		"description": "Maintains a list of resources, nodes, exported, and overridden properties, and built-in scripts associated with a scene.\nThis class cannot be instantiated directly, it is retrieved for a given scene as the result of <a href=\"../PackedScene#get_state\">PackedScene.get_state<a>."
	},
	"RootMotionView": {
		"brief_description": "Editor-only helper for setting up root motion in [AnimationTree](../AnimationTree).",
		"description": "<i>Root motion</i> refers to an animation technique where a mesh's skeleton is used to give impulse to a character. When working with 3D animations, a popular technique is for animators to use the root skeleton bone to give motion to the rest of the skeleton. This allows animating characters in a way where steps actually match the floor below. It also allows precise interaction with objects during cinematics. See also [AnimationTree](../AnimationTree).\n<b>Note:</b> [RootMotionView](../RootMotionView) is only visible in the editor. It will be hidden automatically in the running project."
	},
	"RigidBody3D": {
		"brief_description": "Physics Body which is moved by 3D physics simulation. Useful for objects that have gravity and can be pushed by other objects.",
		"description": "This is the node that implements full 3D physics. This means that you do not control a RigidBody3D directly. Instead, you can apply forces to it (gravity, impulses, etc.), and the physics simulation will calculate the resulting movement, collision, bouncing, rotating, etc.\nYou can switch the body's behavior using <a href=\"#lock_rotation\">lock_rotation</a>, <a href=\"#freeze\">freeze</a>, and <a href=\"#freeze_mode\">freeze_mode</a>.\n<b>Note:</b> Don't change a RigidBody3D's position every frame or very often. Sporadic changes work fine, but physics runs at a different granularity (fixed Hz) than usual rendering (process callback) and maybe even in a separate thread, so changing this from a process loop may result in strange behavior. If you need to directly affect the body's state, use <a href=\"#_integrate_forces\">_integrate_forces</a>, which allows you to directly access the physics state.\nIf you need to override the default physics behavior, you can write a custom force integration function. See <a href=\"#custom_integrator\">custom_integrator</a>.\n<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"RigidBody2D": {
		"brief_description": "Physics Body which is moved by 2D physics simulation. Useful for objects that have gravity and can be pushed by other objects.",
		"description": "This node implements simulated 2D physics. You do not control a RigidBody2D directly. Instead, you apply forces to it (gravity, impulses, etc.) and the physics simulation calculates the resulting movement based on its mass, friction, and other physical properties.\nYou can switch the body's behavior using <a href=\"#lock_rotation\">lock_rotation</a>, <a href=\"#freeze\">freeze</a>, and <a href=\"#freeze_mode\">freeze_mode</a>.\n<b>Note:</b> You should not change a RigidBody2D's <code>position</code> or <code>linear_velocity</code> every frame or even very often. If you need to directly affect the body's state, use <a href=\"#_integrate_forces\">_integrate_forces</a>, which allows you to directly access the physics state.\nPlease also keep in mind that physics bodies manage their own transform which overwrites the ones you set. So any direct or indirect transformation (including scaling of the node or its parent) will be visible in the editor only, and immediately reset at runtime.\nIf you need to override the default physics behavior or add a transformation at runtime, you can write a custom force integration. See <a href=\"#custom_integrator\">custom_integrator</a>."
	},
	"RID": {
		"brief_description": "Handle for a [Resource](../Resource)'s unique ID.",
		"description": "The RID [Variant](../Variant) type is used to access a low-level resource by its unique ID. RIDs are opaque, which means they do not grant access to the resource by themselves. They are used by the low-level server classes, such as [DisplayServer](../DisplayServer), [RenderingServer](../RenderingServer), [TextServer](../TextServer), etc.\nA low-level resource may correspond to a high-level [Resource](../Resource), such as [Texture](../Texture) or [Mesh](../Mesh)."
	},
	"RichTextLabel": {
		"brief_description": "Label that displays rich text.",
		"description": "Rich text can contain custom text, fonts, images and some basic formatting. The label manages these as an internal tag stack. It also adapts itself to given width/heights.\n<b>Note:</b> Assignments to <a href=\"#text\">text</a> clear the tag stack and reconstruct it from the property's contents. Any edits made to <a href=\"#text\">text</a> will erase previous edits made from other manual sources such as <a href=\"#append_text\">append_text</a> and the <code>push_*</code> / <a href=\"#pop\">pop</a> methods.\n<b>Note:</b> RichTextLabel doesn't support entangled BBCode tags. For example, instead of using <code><b>bold<i>bold italic</b>italic</i></code>, use <code><b>bold<i>bold italic</i></b><i>italic</i></code>.\n<b>Note:</b> <code>push_*/pop</code> functions won't affect BBCode.\n<b>Note:</b> Unlike [Label](../Label), RichTextLabel doesn't have a <i>property</i> to horizontally align text to the center. Instead, enable <a href=\"#bbcode_enabled\">bbcode_enabled</a> and surround the text in a <code>[center](../center)</code> tag as follows: <code>[center](../center)Example[/center]</code>. There is currently no built-in way to vertically align text either, but this can be emulated by relying on anchors/containers and the <a href=\"#fit_content\">fit_content</a> property."
	},
	"RichTextEffect": {
		"brief_description": "A custom effect for use with [RichTextLabel](../RichTextLabel).",
		"description": "A custom effect for use with [RichTextLabel](../RichTextLabel).\n<b>Note:</b> For a [RichTextEffect](../RichTextEffect) to be usable, a BBCode tag must be defined as a member variable called <code>bbcode</code> in the script.\n<!-- <codeblocks> -->\n<code>\n# The RichTextEffect will be usable like this: `[example](../example)Some text[/example]`\nvar bbcode = \"example\"\n</code>\n```csharp\n// The RichTextEffect will be usable like this: `[example](../example)Some text[/example]`\nstring bbcode = \"example\";\n```\n<!-- </codeblocks> -->\n<b>Note:</b> As soon as a [RichTextLabel](../RichTextLabel) contains at least one [RichTextEffect](../RichTextEffect), it will continuously process the effect unless the project is paused. This may impact battery life negatively."
	},
	"RibbonTrailMesh": {
		"brief_description": "",
		"description": ""
	},
	"ResourceUID": {
		"brief_description": "Singleton for managing a cache of resource UIDs within a project.",
		"description": "Resources can not only be referenced using their resource paths <code>res://</code>, but alternatively through a unique identifier specified via <code>uid://</code>.\nUsing UIDs allows for the engine to keep references between resources intact, even if the files get renamed or moved.\nThis singleton is responsible for keeping track of all registered resource UIDs of a project, generating new UIDs and converting between the string and integer representation."
	},
	"ResourceSaver": {
		"brief_description": "Singleton for saving Godot-specific resource types.",
		"description": "Singleton for saving Godot-specific resource types to the filesystem.\nIt uses the many [ResourceFormatSaver](../ResourceFormatSaver) classes registered in the engine (either built-in or from a plugin) to save engine-specific resource data to text-based (e.g. <code>.tres</code> or <code>.tscn</code>) or binary files (e.g. <code>.res</code> or <code>.scn</code>)."
	},
	"ResourcePreloader": {
		"brief_description": "Preloads a list of resources inside a scene.",
		"description": "This node is used to preload sub-resources inside a scene, so when the scene is loaded, all the resources are ready to use and can be retrieved from the preloader. You can add the resources using the ResourcePreloader tab when the node is selected.\nGDScript has a simplified [method @GDScript.preload] built-in method which can be used in most situations, leaving the use of [ResourcePreloader](../ResourcePreloader) for more advanced scenarios."
	},
	"ResourceLoader": {
		"brief_description": "Singleton used to load resource files.",
		"description": "Singleton used to load resource files from the filesystem.\nIt uses the many [ResourceFormatLoader](../ResourceFormatLoader) classes registered in the engine (either built-in or from a plugin) to load files into memory and convert them to a format that can be used by the engine.\n<b>Note:</b> You have to import the files into the engine first to load them using <a href=\"#load\">load</a>. If you want to load [Image](../Image)s at run-time, you may use <a href=\"../Image#load\">Image.load<a>. If you want to import audio files, you can use the snippet described in <a href=\"../AudioStreamMP3#data\">AudioStreamMP3.data<a>."
	},
	"ResourceImporter": {
		"brief_description": "Base class for the implementation of core resource importers.",
		"description": "This is the base class for the resource importers implemented in core. To implement your own resource importers using editor plugins, see [EditorImportPlugin](../EditorImportPlugin)."
	},
	"ResourceFormatSaver": {
		"brief_description": "Saves a specific resource type to a file.",
		"description": "The engine can save resources when you do it from the editor, or when you use the [ResourceSaver](../ResourceSaver) singleton. This is accomplished thanks to multiple [ResourceFormatSaver](../ResourceFormatSaver)s, each handling its own format and called automatically by the engine.\nBy default, Godot saves resources as <code>.tres</code> (text-based), <code>.res</code> (binary) or another built-in format, but you can choose to create your own format by extending this class. Be sure to respect the documented return types and values. You should give it a global class name with <code>class_name</code> for it to be registered. Like built-in ResourceFormatSavers, it will be called automatically when saving resources of its recognized type(s). You may also implement a [ResourceFormatLoader](../ResourceFormatLoader)."
	},
	"ResourceFormatLoader": {
		"brief_description": "Loads a specific resource type from a file.",
		"description": "Godot loads resources in the editor or in exported games using ResourceFormatLoaders. They are queried automatically via the [ResourceLoader](../ResourceLoader) singleton, or when a resource with internal dependencies is loaded. Each file type may load as a different resource type, so multiple ResourceFormatLoaders are registered in the engine.\nExtending this class allows you to define your own loader. Be sure to respect the documented return types and values. You should give it a global class name with <code>class_name</code> for it to be registered. Like built-in ResourceFormatLoaders, it will be called automatically when loading resources of its handled type(s). You may also implement a [ResourceFormatSaver](../ResourceFormatSaver).\n<b>Note:</b> You can also extend [EditorImportPlugin](../EditorImportPlugin) if the resource type you need exists but Godot is unable to load its format. Choosing one way over another depends on if the format is suitable or not for the final exported game. For example, it's better to import <code>.png</code> textures as <code>.ctex</code> ([CompressedTexture2D](../CompressedTexture2D)) first, so they can be loaded with better efficiency on the graphics card."
	},
	"Resource": {
		"brief_description": "Base class for all resources.",
		"description": "Resource is the base class for all Godot-specific resource types, serving primarily as data containers. Since they inherit from [RefCounted](../RefCounted), resources are reference-counted and freed when no longer in use. They can also be nested within other resources, and saved on disk. Once loaded from disk, further attempts to load a resource by <a href=\"#resource_path\">resource_path</a> returns the same reference. [PackedScene](../PackedScene), one of the most common [Object](../Object)s in a Godot project, is also a resource, uniquely capable of storing and instantiating the [Node](../Node)s it contains as many times as desired.\nIn GDScript, resources can loaded from disk by their <a href=\"#resource_path\">resource_path</a> using [method @GDScript.load] or [method @GDScript.preload].\n<b>Note:</b> In C#, resources will not be freed instantly after they are no longer in use. Instead, garbage collection will run periodically and will free resources that are no longer in use. This means that unused resources will linger on for a while before being removed."
	},
	"RenderingServer": {
		"brief_description": "Server for anything visible.",
		"description": "The rendering server is the API backend for everything visible. The whole scene system mounts on it to display.\nThe rendering server is completely opaque, the internals are entirely implementation specific and cannot be accessed.\nThe rendering server can be used to bypass the scene/[Node](../Node) system entirely.\nResources are created using the <code>*_create</code> functions. These functions return [RID](../RID)s which are not references to the objects themselves, but opaque <i>pointers</i> towards these objects.\nAll objects are drawn to a viewport. You can use the [Viewport](../Viewport) attached to the [SceneTree](../SceneTree) or you can create one yourself with <a href=\"#viewport_create\">viewport_create</a>. When using a custom scenario or canvas, the scenario or canvas needs to be attached to the viewport using <a href=\"#viewport_set_scenario\">viewport_set_scenario</a> or <a href=\"#viewport_attach_canvas\">viewport_attach_canvas</a>.\nIn 3D, all visual objects must be associated with a scenario. The scenario is a visual representation of the world. If accessing the rendering server from a running game, the scenario can be accessed from the scene tree from any [Node3D](../Node3D) node with <a href=\"../Node3D#get_world_3d\">Node3D.get_world_3d<a>. Otherwise, a scenario can be created with <a href=\"#scenario_create\">scenario_create</a>.\nSimilarly, in 2D, a canvas is needed to draw all canvas items.\nIn 3D, all visible objects are comprised of a resource and an instance. A resource can be a mesh, a particle system, a light, or any other 3D object. In order to be visible resources must be attached to an instance using <a href=\"#instance_set_base\">instance_set_base</a>. The instance must also be attached to the scenario using <a href=\"#instance_set_scenario\">instance_set_scenario</a> in order to be visible.\nIn 2D, all visible objects are some form of canvas item. In order to be visible, a canvas item needs to be the child of a canvas attached to a viewport, or it needs to be the child of another canvas item that is eventually attached to the canvas.\n<b>Headless mode:</b> Starting the engine with the <code>--headless</code> [command line argument]($DOCS_URL/tutorials/editor/command_line_tutorial.html) disables all rendering and window management functions. Most functions from [RenderingServer](../RenderingServer) will return dummy values in this case."
	},
	"RenderingDevice": {
		"brief_description": "Abstraction for working with modern low-level graphics APIs.",
		"description": "[RenderingDevice](../RenderingDevice) is an abstraction for working with modern low-level graphics APIs such as Vulkan.\nOn startup, Godot creates a global [RenderingDevice](../RenderingDevice) which can be retrieved using <a href=\"../RenderingServer#get_rendering_device\">RenderingServer.get_rendering_device<a>. This global RenderingDevice performs drawing to the screen.\nInternally, [RenderingDevice](../RenderingDevice) is used in Godot to provide support for several modern low-level graphics APIs while reducing the amount of code duplication required.\n<b>Local RenderingDevices:</b> Using <a href=\"../RenderingServer#create_local_rendering_device\">RenderingServer.create_local_rendering_device<a>, you can create \"secondary\" rendering devices to perform drawing and GPU compute operations on separate threads.\n<b>Note:</b> [RenderingDevice](../RenderingDevice) is not available when running in headless mode or when using the Compatibility rendering method."
	},
	"RemoteTransform3D": {
		"brief_description": "RemoteTransform3D pushes its own [Transform3D](../Transform3D) to another [Node3D](../Node3D) derived Node in the scene.",
		"description": "RemoteTransform3D pushes its own [Transform3D](../Transform3D) to another [Node3D](../Node3D) derived Node (called the remote node) in the scene.\nIt can be set to update another Node's position, rotation and/or scale. It can use either global or local coordinates."
	},
	"RemoteTransform2D": {
		"brief_description": "RemoteTransform2D pushes its own [Transform2D](../Transform2D) to another [Node2D](../Node2D) derived node in the scene.",
		"description": "RemoteTransform2D pushes its own [Transform2D](../Transform2D) to another [Node2D](../Node2D) derived node (called the remote node) in the scene.\nIt can be set to update another node's position, rotation and/or scale. It can use either global or local coordinates."
	},
	"ReflectionProbe": {
		"brief_description": "Captures its surroundings to create fast, accurate reflections from a given point.",
		"description": "Captures its surroundings as a cubemap, and stores versions of it with increasing levels of blur to simulate different material roughnesses.\nThe [ReflectionProbe](../ReflectionProbe) is used to create high-quality reflections at a low performance cost (when <a href=\"#update_mode\">update_mode</a> is <a href=\"#UPDATE_ONCE\">UPDATE_ONCE</a>). [ReflectionProbe](../ReflectionProbe)s can be blended together and with the rest of the scene smoothly. [ReflectionProbe](../ReflectionProbe)s can also be combined with [VoxelGI](../VoxelGI), SDFGI (<a href=\"../Environment#sdfgi_enabled\">Environment.sdfgi_enabled<a>) and screen-space reflections (<a href=\"../Environment#ssr_enabled\">Environment.ssr_enabled<a>) to get more accurate reflections in specific areas. [ReflectionProbe](../ReflectionProbe)s render all objects within their <a href=\"#cull_mask\">cull_mask</a>, so updating them can be quite expensive. It is best to update them once with the important static objects and then leave them as-is.\n<b>Note:</b> Unlike [VoxelGI](../VoxelGI) and SDFGI, [ReflectionProbe](../ReflectionProbe)s only source their environment from a [WorldEnvironment](../WorldEnvironment) node. If you specify an [Environment](../Environment) resource within a [Camera3D](../Camera3D) node, it will be ignored by the [ReflectionProbe](../ReflectionProbe). This can lead to incorrect lighting within the [ReflectionProbe](../ReflectionProbe).\n<b>Note:</b> Reflection probes are only supported in the Forward+ and Mobile rendering methods, not Compatibility. When using the Mobile rendering method, only 8 reflection probes can be displayed on each mesh resource. Attempting to display more than 8 reflection probes on a single mesh resource will result in reflection probes flickering in and out as the camera moves.\n<b>Note:</b> When using the Mobile rendering method, reflection probes will only correctly affect meshes whose visibility AABB intersects with the reflection probe's AABB. If using a shader to deform the mesh in a way that makes it go outside its AABB, <a href=\"../GeometryInstance3D#extra_cull_margin\">GeometryInstance3D.extra_cull_margin<a> must be increased on the mesh. Otherwise, the reflection probe may not be visible on the mesh."
	},
	"ReferenceRect": {
		"brief_description": "Reference frame for GUI.",
		"description": "A rectangle box that displays only a <a href=\"#border_color\">border_color</a> border color around its rectangle. [ReferenceRect](../ReferenceRect) has no fill [Color](../Color). If you need to display a rectangle filled with a solid color, consider using [ColorRect](../ColorRect) instead."
	},
	"RefCounted": {
		"brief_description": "Base class for reference-counted objects.",
		"description": "Base class for any object that keeps a reference count. [Resource](../Resource) and many other helper objects inherit this class.\nUnlike other [Object](../Object) types, [RefCounted](../RefCounted)s keep an internal reference counter so that they are automatically released when no longer in use, and only then. [RefCounted](../RefCounted)s therefore do not need to be freed manually with <a href=\"../Object#free\">Object.free<a>.\nIn the vast majority of use cases, instantiating and using [RefCounted](../RefCounted)-derived types is all you need to do. The methods provided in this class are only for advanced users, and can cause issues if misused.\n<b>Note:</b> In C#, reference-counted objects will not be freed instantly after they are no longer in use. Instead, garbage collection will run periodically and will free reference-counted objects that are no longer in use. This means that unused ones will linger on for a while before being removed."
	},
	"RectangleShape2D": {
		"brief_description": "Rectangle shape resource for 2D physics.",
		"description": "2D rectangle shape to be added as a <i>direct</i> child of a [PhysicsBody2D](../PhysicsBody2D) or [Area2D](../Area2D) using a [CollisionShape2D](../CollisionShape2D) node. This shape is useful for modeling box-like 2D objects.\n<b>Performance:</b> Being a primitive collision shape, [RectangleShape2D](../RectangleShape2D) is fast to check collisions against (though not as fast as [CircleShape2D](../CircleShape2D))."
	},
	"Rect2i": {
		"brief_description": "2D axis-aligned bounding box using integer coordinates.",
		"description": "[Rect2i](../Rect2i) consists of a position, a size, and several utility functions. It is typically used for fast overlap tests.\nIt uses integer coordinates. If you need floating-point coordinates, use [Rect2](../Rect2) instead.\nNegative values for <a href=\"#size\">size</a> are not supported and will not work for most methods. Use <a href=\"#abs\">abs</a> to get a Rect2i with a positive size."
	},
	"Rect2": {
		"brief_description": "2D axis-aligned bounding box using floating point coordinates.",
		"description": "[Rect2](../Rect2) consists of a position, a size, and several utility functions. It is typically used for fast overlap tests.\nIt uses floating-point coordinates. If you need integer coordinates, use [Rect2i](../Rect2i) instead.\nThe 3D counterpart to [Rect2](../Rect2) is [AABB](../AABB).\nNegative values for <a href=\"#size\">size</a> are not supported and will not work for most methods. Use <a href=\"#abs\">abs</a> to get a Rect2 with a positive size."
	},
	"RDVertexAttribute": {
		"brief_description": "",
		"description": ""
	},
	"RDUniform": {
		"brief_description": "",
		"description": ""
	},
	"RDTextureView": {
		"brief_description": "",
		"description": ""
	},
	"RDTextureFormat": {
		"brief_description": "",
		"description": ""
	},
	"RDShaderSPIRV": {
		"brief_description": "",
		"description": ""
	},
	"RDShaderSource": {
		"brief_description": "",
		"description": ""
	},
	"RDShaderFile": {
		"brief_description": "",
		"description": ""
	},
	"RDSamplerState": {
		"brief_description": "",
		"description": ""
	},
	"RDPipelineSpecializationConstant": {
		"brief_description": "",
		"description": ""
	},
	"RDPipelineRasterizationState": {
		"brief_description": "",
		"description": ""
	},
	"RDPipelineMultisampleState": {
		"brief_description": "",
		"description": ""
	},
	"RDPipelineDepthStencilState": {
		"brief_description": "",
		"description": ""
	},
	"RDPipelineColorBlendStateAttachment": {
		"brief_description": "",
		"description": ""
	},
	"RDPipelineColorBlendState": {
		"brief_description": "",
		"description": ""
	},
	"RDFramebufferPass": {
		"brief_description": "Framebuffer pass attachment description.",
		"description": "This class contains the list of attachment descriptions for a framebuffer pass. Each points with an index to a previously supplied list of texture attachments.\nMultipass framebuffers can optimize some configurations in mobile, on desktop they provide little to no advantage."
	},
	"RDAttachmentFormat": {
		"brief_description": "",
		"description": ""
	},
	"RayCast3D": {
		"brief_description": "Query the closest object intersecting a ray.",
		"description": "A RayCast represents a line from its origin to its destination position, <a href=\"#target_position\">target_position</a>. It is used to query the 3D space in order to find the closest object along the path of the ray.\nRayCast3D can ignore some objects by adding them to the exception list via <a href=\"#add_exception\">add_exception</a> or by setting proper filtering with collision layers and masks.\nRayCast3D can be configured to report collisions with [Area3D](../Area3D)s (<a href=\"#collide_with_areas\">collide_with_areas</a>) and/or [PhysicsBody3D](../PhysicsBody3D)s (<a href=\"#collide_with_bodies\">collide_with_bodies</a>).\nOnly enabled raycasts will be able to query the space and report collisions.\nRayCast3D calculates intersection every physics frame (see [Node](../Node)), and the result is cached so it can be used later until the next frame. If multiple queries are required between physics frames (or during the same frame), use <a href=\"#force_raycast_update\">force_raycast_update</a> after adjusting the raycast."
	},
	"RayCast2D": {
		"brief_description": "Query the closest object intersecting a ray.",
		"description": "A RayCast represents a line from its origin to its destination position, <a href=\"#target_position\">target_position</a>. It is used to query the 2D space in order to find the closest object along the path of the ray.\nRayCast2D can ignore some objects by adding them to the exception list via <a href=\"#add_exception\">add_exception</a>, by setting proper filtering with collision layers, or by filtering object types with type masks.\nRayCast2D can be configured to report collisions with [Area2D](../Area2D)s (<a href=\"#collide_with_areas\">collide_with_areas</a>) and/or [PhysicsBody2D](../PhysicsBody2D)s (<a href=\"#collide_with_bodies\">collide_with_bodies</a>).\nOnly enabled raycasts will be able to query the space and report collisions.\nRayCast2D calculates intersection every physics frame (see [Node](../Node)), and the result is cached so it can be used later until the next frame. If multiple queries are required between physics frames (or during the same frame) use <a href=\"#force_raycast_update\">force_raycast_update</a> after adjusting the raycast."
	},
	"Range": {
		"brief_description": "Abstract base class for range-based controls.",
		"description": "Range is a base class for [Control](../Control) nodes that change a floating-point <a href=\"#value\">value</a> between a <a href=\"#min_value\">min_value</a> and <a href=\"#max_value\">max_value</a>, using a configured <a href=\"#step\">step</a> and <a href=\"#page\">page</a> size. See e.g. [ScrollBar](../ScrollBar) and [Slider](../Slider) for examples of higher level nodes using Range."
	},
	"RandomNumberGenerator": {
		"brief_description": "A class for generating pseudo-random numbers.",
		"description": "RandomNumberGenerator is a class for generating pseudo-random numbers. It currently uses [PCG32](https://www.pcg-random.org/).\n<b>Note:</b> The underlying algorithm is an implementation detail. As a result, it should not be depended upon for reproducible random streams across Godot versions.\nTo generate a random float number (within a given range) based on a time-dependant seed:\n<code>\nvar rng = RandomNumberGenerator.new()\nfunc _ready():\n\tvar my_random_number = rng.randf_range(-10.0, 10.0)\n</code>\n<b>Note:</b> The default values of <a href=\"#seed\">seed</a> and <a href=\"#state\">state</a> properties are pseudo-random, and change when calling <a href=\"#randomize\">randomize</a>. The <code>0</code> value documented here is a placeholder, and not the actual default seed."
	},
	"Quaternion": {
		"brief_description": "Quaternion.",
		"description": "A unit quaternion used for representing 3D rotations. Quaternions need to be normalized to be used for rotation.\nIt is similar to Basis, which implements matrix representation of rotations, and can be parametrized using both an axis-angle pair or Euler angles. Basis stores rotation, scale, and shearing, while Quaternion only stores rotation.\nDue to its compactness and the way it is stored in memory, certain operations (obtaining axis-angle and performing SLERP, in particular) are more efficient and robust against floating-point errors."
	},
	"QuadOccluder3D": {
		"brief_description": "Flat plane shape for use with occlusion culling in [OccluderInstance3D](../OccluderInstance3D).",
		"description": "[QuadOccluder3D](../QuadOccluder3D) stores a flat plane shape that can be used by the engine's occlusion culling system. See also [PolygonOccluder3D](../PolygonOccluder3D) if you need to customize the quad's shape.\nSee [OccluderInstance3D](../OccluderInstance3D)'s documentation for instructions on setting up occlusion culling."
	},
	"QuadMesh": {
		"brief_description": "Class representing a square mesh facing the camera.",
		"description": "Class representing a square [PrimitiveMesh](../PrimitiveMesh). This flat mesh does not have a thickness. By default, this mesh is aligned on the X and Y axes; this rotation is more suited for use with billboarded materials. A [QuadMesh](../QuadMesh) is equivalent to a [PlaneMesh](../PlaneMesh) except its default <a href=\"../PlaneMesh#orientation\">PlaneMesh.orientation<a> is <a href=\"../PlaneMesh#FACE_Z\">PlaneMesh.FACE_Z<a>."
	},
	"PropertyTweener": {
		"brief_description": "Interpolates an [Object](../Object)'s property over time.",
		"description": "[PropertyTweener](../PropertyTweener) is used to interpolate a property in an object. See <a href=\"../Tween#tween_property\">Tween.tween_property<a> for more usage information.\n<b>Note:</b> <a href=\"../Tween#tween_property\">Tween.tween_property<a> is the only correct way to create [PropertyTweener](../PropertyTweener). Any [PropertyTweener](../PropertyTweener) created manually will not function correctly."
	},
	"ProjectSettings": {
		"brief_description": "Contains global variables accessible from everywhere.",
		"description": "Contains global variables accessible from everywhere. Use <a href=\"#get_setting\">get_setting</a>, <a href=\"#set_setting\">set_setting</a> or <a href=\"#has_setting\">has_setting</a> to access them. Variables stored in <code>project.godot</code> are also loaded into ProjectSettings, making this object very useful for reading custom game configuration options.\nWhen naming a Project Settings property, use the full path to the setting including the category. For example, <code>\"application/config/name\"</code> for the project name. Category and property names can be viewed in the Project Settings dialog.\n<b>Feature tags:</b> Project settings can be overridden for specific platforms and configurations (debug, release, ...) using [feature tags]($DOCS_URL/tutorials/export/feature_tags.html).\n<b>Overriding:</b> Any project setting can be overridden by creating a file named <code>override.cfg</code> in the project's root directory. This can also be used in exported projects by placing this file in the same directory as the project binary. Overriding will still take the base project settings' [feature tags]($DOCS_URL/tutorials/export/feature_tags.html) in account. Therefore, make sure to <i>also</i> override the setting with the desired feature tags if you want them to override base project settings on all platforms and configurations."
	},
	"Projection": {
		"brief_description": "3D projection (4x4 matrix).",
		"description": "A 4x4 matrix used for 3D projective transformations. It can represent transformations such as translation, rotation, scaling, shearing, and perspective division. It consists of four [Vector4](../Vector4) columns.\nFor purely linear transformations (translation, rotation, and scale), it is recommended to use [Transform3D](../Transform3D), as it is more performant and has a lower memory footprint.\nUsed internally as [Camera3D](../Camera3D)'s projection matrix."
	},
	"ProgressBar": {
		"brief_description": "General-purpose progress bar.",
		"description": "General-purpose progress bar. Shows fill percentage from right to left."
	},
	"ProceduralSkyMaterial": {
		"brief_description": "A [Material](../Material) used with [Sky](../Sky) to generate a background based on user input parameters.",
		"description": "ProceduralSkyMaterial provides a way to create an effective background quickly by defining procedural parameters for the sun, the sky and the ground. The sky and ground are very similar, they are defined by a color at the horizon, another color, and finally an easing curve to interpolate between these two colors. Similarly, the sun is described by a position in the sky, a color, and an easing curve. However, the sun also defines a minimum and maximum angle, these two values define at what distance the easing curve begins and ends from the sun, and thus end up defining the size of the sun in the sky.\nThe [ProceduralSkyMaterial](../ProceduralSkyMaterial) uses a lightweight shader to draw the sky and is thus suited for real time updates. When you do not need a quick sky that is not realistic, this is a good option. If you need a more realistic option, try using [PhysicalSkyMaterial](../PhysicalSkyMaterial) instead.\nThe [ProceduralSkyMaterial](../ProceduralSkyMaterial) supports up to 4 suns. Each sun takes its color, energy, and direction from the corresponding [DirectionalLight3D](../DirectionalLight3D) in the scene."
	},
	"PrismMesh": {
		"brief_description": "Class representing a prism-shaped [PrimitiveMesh](../PrimitiveMesh).",
		"description": "Class representing a prism-shaped [PrimitiveMesh](../PrimitiveMesh)."
	},
	"PrimitiveMesh": {
		"brief_description": "Base class for all primitive meshes. Handles applying a [Material](../Material) to a primitive mesh.",
		"description": "Base class for all primitive meshes. Handles applying a [Material](../Material) to a primitive mesh. Examples include [BoxMesh](../BoxMesh), [CapsuleMesh](../CapsuleMesh), [CylinderMesh](../CylinderMesh), [PlaneMesh](../PlaneMesh), [PrismMesh](../PrismMesh), and [SphereMesh](../SphereMesh)."
	},
	"PortableCompressedTexture2D": {
		"brief_description": "Provides a compressed texture for disk and/or VRAM in a way that is portable.",
		"description": "This class allows storing compressed textures as self contained (not imported) resources.\nFor 2D usage (compressed on disk, uncompressed on VRAM), the lossy and lossless modes are recommended. For 3D usage (compressed on VRAM) it depends on the target platform.\nIf you intend to only use desktop, S3TC or BPTC are recommended. For only mobile, ETC2 is recommended.\nFor portable, self contained 3D textures that work on both desktop and mobile, Basis Universal is recommended (although it has a small quality cost and longer compression time as a tradeoff).\nThis resource is intended to be created from code."
	},
	"PopupPanel": {
		"brief_description": "Class for displaying popups with a panel background.",
		"description": "Class for displaying popups with a panel background. In some cases it might be simpler to use than [Popup](../Popup), since it provides a configurable background. If you are making windows, better check [Window](../Window).\nIf any [Control](../Control) node is added as a child of this [PopupPanel](../PopupPanel), it will be stretched to fit the panel's size (similar to how [PanelContainer](../PanelContainer) works)."
	},
	"PopupMenu": {
		"brief_description": "PopupMenu displays a list of options.",
		"description": "[PopupMenu](../PopupMenu) is a modal window used to display a list of options. They are popular in toolbars or context menus.\nThe size of a [PopupMenu](../PopupMenu) can be limited by using <a href=\"../Window#max_size\">Window.max_size<a>. If the height of the list of items is larger than the maximum height of the [PopupMenu](../PopupMenu), a [ScrollContainer](../ScrollContainer) within the popup will allow the user to scroll the contents.\nIf no maximum size is set, or if it is set to 0, the [PopupMenu](../PopupMenu) height will be limited by its parent rect.\nAll <code>set_*</code> methods allow negative item index, which makes the item accessed from the last one.\n<b>Incremental search:</b> Like [ItemList](../ItemList) and [Tree](../Tree), [PopupMenu](../PopupMenu) supports searching within the list while the control is focused. Press a key that matches the first letter of an item's name to select the first item starting with the given letter. After that point, there are two ways to perform incremental search: 1) Press the same key again before the timeout duration to select the next item starting with the same letter. 2) Press letter keys that match the rest of the word before the timeout duration to match to select the item in question directly. Both of these actions will be reset to the beginning of the list if the timeout duration has passed since the last keystroke was registered. You can adjust the timeout duration by changing [member ProjectSettings.gui/timers/incremental_search_max_interval_msec]."
	},
	"Popup": {
		"brief_description": "Popup is a base window container for popup-like subwindows.",
		"description": "Popup is a base window container for popup-like subwindows. It's a modal by default (see <a href=\"../Window#popup_window\">Window.popup_window<a>) and has helpers for custom popup behavior."
	},
	"PolygonPathFinder": {
		"brief_description": "",
		"description": ""
	},
	"PolygonOccluder3D": {
		"brief_description": "Flat 2D polygon shape for use with occlusion culling in [OccluderInstance3D](../OccluderInstance3D).",
		"description": "[PolygonOccluder3D](../PolygonOccluder3D) stores a polygon shape that can be used by the engine's occlusion culling system. When an [OccluderInstance3D](../OccluderInstance3D) with a [PolygonOccluder3D](../PolygonOccluder3D) is selected in the editor, an editor will appear at the top of the 3D viewport so you can add/remove points. All points must be placed on the same 2D plane, which means it is not possible to create arbitrary 3D shapes with a single [PolygonOccluder3D](../PolygonOccluder3D). To use arbitrary 3D shapes as occluders, use [ArrayOccluder3D](../ArrayOccluder3D) or [OccluderInstance3D](../OccluderInstance3D)'s baking feature instead.\nSee [OccluderInstance3D](../OccluderInstance3D)'s documentation for instructions on setting up occlusion culling."
	},
	"Polygon2D": {
		"brief_description": "A 2D polygon.",
		"description": "A Polygon2D is defined by a set of points. Each point is connected to the next, with the final point being connected to the first, resulting in a closed polygon. Polygon2Ds can be filled with color (solid or gradient) or filled with a given texture."
	},
	"PointMesh": {
		"brief_description": "Mesh with a single Point primitive.",
		"description": "The PointMesh is made from a single point. Instead of relying on triangles, points are rendered as a single rectangle on the screen with a constant size. They are intended to be used with Particle systems, but can be used as a cheap way to render constant size billboarded sprites (for example in a point cloud).\nPointMeshes, must be used with a material that has a point size. Point size can be accessed in a shader with <code>POINT_SIZE</code>, or in a [BaseMaterial3D](../BaseMaterial3D) by setting <a href=\"../BaseMaterial3D#use_point_size\">BaseMaterial3D.use_point_size<a> and the variable <a href=\"../BaseMaterial3D#point_size\">BaseMaterial3D.point_size<a>.\nWhen using PointMeshes, properties that normally alter vertices will be ignored, including billboard mode, grow, and cull face."
	},
	"PointLight2D": {
		"brief_description": "Positional 2D light source.",
		"description": "Casts light in a 2D environment. This light's shape is defined by a (usually grayscale) texture."
	},
	"PlaneMesh": {
		"brief_description": "Class representing a planar [PrimitiveMesh](../PrimitiveMesh).",
		"description": "Class representing a planar [PrimitiveMesh](../PrimitiveMesh). This flat mesh does not have a thickness. By default, this mesh is aligned on the X and Z axes; this default rotation isn't suited for use with billboarded materials. For billboarded materials, change <a href=\"#orientation\">orientation</a> to <a href=\"#FACE_Z\">FACE_Z</a>.\n<b>Note:</b> When using a large textured [PlaneMesh](../PlaneMesh) (e.g. as a floor), you may stumble upon UV jittering issues depending on the camera angle. To solve this, increase <a href=\"#subdivide_depth\">subdivide_depth</a> and <a href=\"#subdivide_width\">subdivide_width</a> until you no longer notice UV jittering."
	},
	"Plane": {
		"brief_description": "Plane in hessian form.",
		"description": "Plane represents a normalized plane equation. Basically, \"normal\" is the normal of the plane (a,b,c normalized), and \"d\" is the distance from the origin to the plane (in the direction of \"normal\"). \"Over\" or \"Above\" the plane is considered the side of the plane towards where the normal is pointing."
	},
	"PlaceholderTextureLayered": {
		"brief_description": "Placeholder class for a 2-dimensional texture array.",
		"description": "This class is used when loading a project that uses a [TextureLayered](../TextureLayered) subclass in 2 conditions:\n- When running the project exported in dedicated server mode, only the texture's dimensions are kept (as they may be relied upon for gameplay purposes or positioning of other elements). This allows reducing the exported PCK's size significantly.\n- When this subclass is missing due to using a different engine version or build (e.g. modules disabled)."
	},
	"PlaceholderTexture3D": {
		"brief_description": "Placeholder class for a 3-dimensional texture.",
		"description": "This class is used when loading a project that uses a [Texture3D](../Texture3D) subclass in 2 conditions:\n- When running the project exported in dedicated server mode, only the texture's dimensions are kept (as they may be relied upon for gameplay purposes or positioning of other elements). This allows reducing the exported PCK's size significantly.\n- When this subclass is missing due to using a different engine version or build (e.g. modules disabled)."
	},
	"PlaceholderTexture2DArray": {
		"brief_description": "Placeholder class for a 2-dimensional texture array.",
		"description": "This class is used when loading a project that uses a [Texture2D](../Texture2D) subclass in 2 conditions:\n- When running the project exported in dedicated server mode, only the texture's dimensions are kept (as they may be relied upon for gameplay purposes or positioning of other elements). This allows reducing the exported PCK's size significantly.\n- When this subclass is missing due to using a different engine version or build (e.g. modules disabled)."
	},
	"PlaceholderTexture2D": {
		"brief_description": "Placeholder class for a 2-dimensional texture.",
		"description": "This class is used when loading a project that uses a [Texture2D](../Texture2D) subclass in 2 conditions:\n- When running the project exported in dedicated server mode, only the texture's dimensions are kept (as they may be relied upon for gameplay purposes or positioning of other elements). This allows reducing the exported PCK's size significantly.\n- When this subclass is missing due to using a different engine version or build (e.g. modules disabled)."
	},
	"PlaceholderMesh": {
		"brief_description": "Placeholder class for a mesh.",
		"description": "This class is used when loading a project that uses a [Mesh](../Mesh) subclass in 2 conditions:\n- When running the project exported in dedicated server mode, only the texture's dimensions are kept (as they may be relied upon for gameplay purposes or positioning of other elements). This allows reducing the exported PCK's size significantly.\n- When this subclass is missing due to using a different engine version or build (e.g. modules disabled)."
	},
	"PlaceholderMaterial": {
		"brief_description": "Placeholder class for a material.",
		"description": "This class is used when loading a project that uses a [Material](../Material) subclass in 2 conditions:\n- When running the project exported in dedicated server mode, only the texture's dimensions are kept (as they may be relied upon for gameplay purposes or positioning of other elements). This allows reducing the exported PCK's size significantly.\n- When this subclass is missing due to using a different engine version or build (e.g. modules disabled)."
	},
	"PlaceholderCubemapArray": {
		"brief_description": "Placeholder class for a cubemap texture array.",
		"description": "This class is used when loading a project that uses a [CubemapArray](../CubemapArray) subclass in 2 conditions:\n- When running the project exported in dedicated server mode, only the texture's dimensions are kept (as they may be relied upon for gameplay purposes or positioning of other elements). This allows reducing the exported PCK's size significantly.\n- When this subclass is missing due to using a different engine version or build (e.g. modules disabled)."
	},
	"PlaceholderCubemap": {
		"brief_description": "Placeholder class for a cubemap texture.",
		"description": "This class is used when loading a project that uses a [Cubemap](../Cubemap) subclass in 2 conditions:\n- When running the project exported in dedicated server mode, only the texture's dimensions are kept (as they may be relied upon for gameplay purposes or positioning of other elements). This allows reducing the exported PCK's size significantly.\n- When this subclass is missing due to using a different engine version or build (e.g. modules disabled)."
	},
	"PinJoint3D": {
		"brief_description": "Pin joint for 3D PhysicsBodies.",
		"description": "Pin joint for 3D rigid bodies. It pins 2 bodies (dynamic or static) together. See also [Generic6DOFJoint3D](../Generic6DOFJoint3D)."
	},
	"PinJoint2D": {
		"brief_description": "Pin joint for 2D shapes.",
		"description": "Pin joint for 2D rigid bodies. It pins two bodies (dynamic or static) together."
	},
	"PhysicsTestMotionResult3D": {
		"brief_description": "Result from a 3D body motion test.",
		"description": "This class contains the motion and collision result from <a href=\"../PhysicsServer3D#body_test_motion\">PhysicsServer3D.body_test_motion<a>."
	},
	"PhysicsTestMotionResult2D": {
		"brief_description": "Result from a 2D body motion test.",
		"description": "This class contains the motion and collision result from <a href=\"../PhysicsServer2D#body_test_motion\">PhysicsServer2D.body_test_motion<a>."
	},
	"PhysicsTestMotionParameters3D": {
		"brief_description": "Parameters to be sent to a 3D body motion test.",
		"description": "This class contains parameters used in <a href=\"../PhysicsServer3D#body_test_motion\">PhysicsServer3D.body_test_motion<a>."
	},
	"PhysicsTestMotionParameters2D": {
		"brief_description": "Parameters to be sent to a 2D body motion test.",
		"description": "This class contains parameters used in <a href=\"../PhysicsServer2D#body_test_motion\">PhysicsServer2D.body_test_motion<a>."
	},
	"PhysicsShapeQueryParameters3D": {
		"brief_description": "Parameters to be sent to a 3D shape physics query.",
		"description": "This class contains the shape and other parameters for [PhysicsDirectSpaceState3D](../PhysicsDirectSpaceState3D) intersection/collision queries."
	},
	"PhysicsShapeQueryParameters2D": {
		"brief_description": "Parameters to be sent to a 2D shape physics query.",
		"description": "This class contains the shape and other parameters for [PhysicsDirectSpaceState2D](../PhysicsDirectSpaceState2D) intersection/collision queries."
	},
	"PhysicsServer3DRenderingServerHandler": {
		"brief_description": "",
		"description": ""
	},
	"PhysicsServer3DManager": {
		"brief_description": "Manager for 3D physics server implementations.",
		"description": "[PhysicsServer3DManager](../PhysicsServer3DManager) is the API for registering [PhysicsServer3D](../PhysicsServer3D) implementations, and for setting the default implementation.\n<b>Note:</b> It is not possible to switch physics servers at runtime. This class is only used on startup at the server initialization level, by Godot itself and possibly by GDExtensions."
	},
	"PhysicsServer3DExtension": {
		"brief_description": "",
		"description": ""
	},
	"PhysicsServer3D": {
		"brief_description": "Server interface for low-level physics access.",
		"description": "PhysicsServer3D is the server responsible for all 3D physics. It can create many kinds of physics objects, but does not insert them on the node tree."
	},
	"PhysicsServer2DManager": {
		"brief_description": "Manager for 2D physics server implementations.",
		"description": "[PhysicsServer2DManager](../PhysicsServer2DManager) is the API for registering [PhysicsServer2D](../PhysicsServer2D) implementations, and for setting the default implementation.\n<b>Note:</b> It is not possible to switch physics servers at runtime. This class is only used on startup at the server initialization level, by Godot itself and possibly by GDExtensions."
	},
	"PhysicsServer2DExtension": {
		"brief_description": "",
		"description": ""
	},
	"PhysicsServer2D": {
		"brief_description": "Server interface for low-level 2D physics access.",
		"description": "PhysicsServer2D is the server responsible for all 2D physics. It can directly create and manipulate all physics objects:\n- A <i>space</i> is a self-contained world for a physics simulation. It contains bodies, areas, and joints. Its state can be queried for collision and intersection information, and several parameters of the simulation can be modified.\n- A <i>shape</i> is a geometric figure such as a circle, a rectangle, a capsule, or a polygon. It can be used for collision detection by adding it to a body/area, possibly with an extra transformation relative to the body/area's origin. Bodies/areas can have multiple (transformed) shapes added to them, and a single shape can be added to bodies/areas multiple times with different local transformations.\n- A <i>body</i> is a physical object which can be in static, kinematic, or rigid mode. Its state (such as position and velocity) can be queried and updated. A force integration callback can be set to customize the body's physics.\n- An <i>area</i> is a region in space which can be used to detect bodies and areas entering and exiting it. A body monitoring callback can be set to report entering/exiting body shapes, and similarly an area monitoring callback can be set. Gravity and damping can be overridden within the area by setting area parameters.\n- A <i>joint</i> is a constraint, either between two bodies or on one body relative to a point. Parameters such as the joint bias and the rest length of a spring joint can be adjusted.\nPhysics objects in the physics server may be created and manipulated independently; they do not have to be tied to nodes in the scene tree.\n<b>Note:</b> All the physics nodes use the physics server internally. Adding a physics node to the scene tree will cause a corresponding physics object to be created in the physics server. A rigid body node registers a callback that updates the node's transform with the transform of the respective body object in the physics server (every physics update). An area node registers a callback to inform the area node about overlaps with the respective area object in the physics server. The raycast node queries the direct state of the relevant space in the physics server."
	},
	"PhysicsRayQueryParameters3D": {
		"brief_description": "Parameters to be sent to a 3D ray physics query.",
		"description": "This class contains the ray position and other parameters to be used for <a href=\"../PhysicsDirectSpaceState3D#intersect_ray\">PhysicsDirectSpaceState3D.intersect_ray<a>."
	},
	"PhysicsRayQueryParameters2D": {
		"brief_description": "Parameters to be sent to a 2D ray physics query.",
		"description": "This class contains the ray position and other parameters to be used for <a href=\"../PhysicsDirectSpaceState2D#intersect_ray\">PhysicsDirectSpaceState2D.intersect_ray<a>."
	},
	"PhysicsPointQueryParameters3D": {
		"brief_description": "Parameters to be sent to a 3D point physics query.",
		"description": "This class contains the position and other parameters to be used for <a href=\"../PhysicsDirectSpaceState3D#intersect_point\">PhysicsDirectSpaceState3D.intersect_point<a>."
	},
	"PhysicsPointQueryParameters2D": {
		"brief_description": "Parameters to be sent to a 2D point physics query.",
		"description": "This class contains the position and other parameters to be used for <a href=\"../PhysicsDirectSpaceState2D#intersect_point\">PhysicsDirectSpaceState2D.intersect_point<a>."
	},
	"PhysicsMaterial": {
		"brief_description": "A material for physics properties.",
		"description": "Provides a means of modifying the collision properties of a [PhysicsBody3D](../PhysicsBody3D)."
	},
	"PhysicsDirectSpaceState3DExtension": {
		"brief_description": "",
		"description": ""
	},
	"PhysicsDirectSpaceState3D": {
		"brief_description": "Direct access object to a space in the [PhysicsServer3D](../PhysicsServer3D).",
		"description": "Direct access object to a space in the [PhysicsServer3D](../PhysicsServer3D). It's used mainly to do queries against objects and areas residing in a given space."
	},
	"PhysicsDirectSpaceState2DExtension": {
		"brief_description": "",
		"description": ""
	},
	"PhysicsDirectSpaceState2D": {
		"brief_description": "Direct access object to a space in the [PhysicsServer2D](../PhysicsServer2D).",
		"description": "Direct access object to a space in the [PhysicsServer2D](../PhysicsServer2D). It's used mainly to do queries against objects and areas residing in a given space."
	},
	"PhysicsDirectBodyState3DExtension": {
		"brief_description": "",
		"description": ""
	},
	"PhysicsDirectBodyState3D": {
		"brief_description": "Direct access object to a physics body in the [PhysicsServer3D](../PhysicsServer3D).",
		"description": "Provides direct access to a physics body in the [PhysicsServer3D](../PhysicsServer3D), allowing safe changes to physics properties. This object is passed via the direct state callback of rigid bodies, and is intended for changing the direct state of that body. See <a href=\"../RigidBody3D#_integrate_forces\">RigidBody3D._integrate_forces<a>."
	},
	"PhysicsDirectBodyState2DExtension": {
		"brief_description": "",
		"description": ""
	},
	"PhysicsDirectBodyState2D": {
		"brief_description": "Direct access object to a physics body in the [PhysicsServer2D](../PhysicsServer2D).",
		"description": "Provides direct access to a physics body in the [PhysicsServer2D](../PhysicsServer2D), allowing safe changes to physics properties. This object is passed via the direct state callback of rigid bodies, and is intended for changing the direct state of that body. See <a href=\"../RigidBody2D#_integrate_forces\">RigidBody2D._integrate_forces<a>."
	},
	"PhysicsBody3D": {
		"brief_description": "Base class for all objects affected by physics in 3D space.",
		"description": "PhysicsBody3D is an abstract base class for implementing a physics body. All *Body3D types inherit from it.\n<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"PhysicsBody2D": {
		"brief_description": "Base class for all objects affected by physics in 2D space.",
		"description": "PhysicsBody2D is an abstract base class for implementing a physics body. All *Body2D types inherit from it."
	},
	"PhysicalSkyMaterial": {
		"brief_description": "[Sky](../Sky) [Material](../Material) used for a physically based sky.",
		"description": "The [PhysicalSkyMaterial](../PhysicalSkyMaterial) uses the Preetham analytic daylight model to draw a sky based on physical properties. This results in a substantially more realistic sky than the [ProceduralSkyMaterial](../ProceduralSkyMaterial), but it is slightly slower and less flexible.\nThe [PhysicalSkyMaterial](../PhysicalSkyMaterial) only supports one sun. The color, energy, and direction of the sun are taken from the first [DirectionalLight3D](../DirectionalLight3D) in the scene tree.\nAs it is based on a daylight model, the sky fades to black as the sunset ends. If you want a full day/night cycle, you will have to add a night sky by converting this to a [ShaderMaterial](../ShaderMaterial) and adding a night sky directly into the resulting shader."
	},
	"PhysicalBone3D": {
		"brief_description": "",
		"description": "<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"PhysicalBone2D": {
		"brief_description": "A 2D node that can be used for physically aware bones in 2D.",
		"description": "The <code>PhysicalBone2D</code> node is a [RigidBody2D](../RigidBody2D)-based node that can be used to make [Bone2D](../Bone2D) nodes in a [Skeleton2D](../Skeleton2D) react to physics. This node is very similar to the [PhysicalBone3D](../PhysicalBone3D) node, just for 2D instead of 3D.\n<b>Note:</b> To have the Bone2D nodes visually follow the <code>PhysicalBone2D</code> node, use a [SkeletonModification2DPhysicalBones](../SkeletonModification2DPhysicalBones) modification on the [Skeleton2D](../Skeleton2D) node with the [Bone2D](../Bone2D) nodes.\n<b>Note:</b> The PhysicalBone2D node does not automatically create a [Joint2D](../Joint2D) node to keep <code>PhysicalBone2D</code> nodes together. You will need to create these manually. For most cases, you want to use a [PinJoint2D](../PinJoint2D) node. The <code>PhysicalBone2D</code> node can automatically configure the [Joint2D](../Joint2D) node once it's been created as a child node."
	},
	"Performance": {
		"brief_description": "Exposes performance-related data.",
		"description": "This class provides access to a number of different monitors related to performance, such as memory usage, draw calls, and FPS. These are the same as the values displayed in the <b>Monitor</b> tab in the editor's <b>Debugger</b> panel. By using the <a href=\"#get_monitor\">get_monitor</a> method of this class, you can access this data from your code.\nYou can add custom monitors using the <a href=\"#add_custom_monitor\">add_custom_monitor</a> method. Custom monitors are available in <b>Monitor</b> tab in the editor's <b>Debugger</b> panel together with built-in monitors.\n<b>Note:</b> Some of the built-in monitors are only available in debug mode and will always return <code>0</code> when used in a project exported in release mode.\n<b>Note:</b> Some of the built-in monitors are not updated in real-time for performance reasons, so there may be a delay of up to 1 second between changes.\n<b>Note:</b> Custom monitors do not support negative values. Negative values are clamped to 0."
	},
	"PCKPacker": {
		"brief_description": "Creates packages that can be loaded into a running project.",
		"description": "The [PCKPacker](../PCKPacker) is used to create packages that can be loaded into a running project using <a href=\"../ProjectSettings#load_resource_pack\">ProjectSettings.load_resource_pack<a>.\n<!-- <codeblocks> -->\n<code>\nvar packer = PCKPacker.new()\npacker.pck_start(\"test.pck\")\npacker.add_file(\"res://text.txt\", \"text.txt\")\npacker.flush()\n</code>\n```csharp\nvar packer = new PCKPacker();\npacker.PckStart(\"test.pck\");\npacker.AddFile(\"res://text.txt\", \"text.txt\");\npacker.Flush();\n```\n<!-- </codeblocks> -->\nThe above [PCKPacker](../PCKPacker) creates package <code>test.pck</code>, then adds a file named <code>text.txt</code> at the root of the package."
	},
	"PathFollow3D": {
		"brief_description": "Point sampler for a [Path3D](../Path3D).",
		"description": "This node takes its parent [Path3D](../Path3D), and returns the coordinates of a point within it, given a distance from the first vertex.\nIt is useful for making other nodes follow a path, without coding the movement pattern. For that, the nodes must be children of this node. The descendant nodes will then move accordingly when setting the <a href=\"#progress\">progress</a> in this node."
	},
	"PathFollow2D": {
		"brief_description": "Point sampler for a [Path2D](../Path2D).",
		"description": "This node takes its parent [Path2D](../Path2D), and returns the coordinates of a point within it, given a distance from the first vertex.\nIt is useful for making other nodes follow a path, without coding the movement pattern. For that, the nodes must be children of this node. The descendant nodes will then move accordingly when setting the <a href=\"#progress\">progress</a> in this node."
	},
	"Path3D": {
		"brief_description": "Contains a [Curve3D](../Curve3D) path for [PathFollow3D](../PathFollow3D) nodes to follow.",
		"description": "Can have [PathFollow3D](../PathFollow3D) child nodes moving along the [Curve3D](../Curve3D). See [PathFollow3D](../PathFollow3D) for more information on the usage.\nNote that the path is considered as relative to the moved nodes (children of [PathFollow3D](../PathFollow3D)). As such, the curve should usually start with a zero vector <code>(0, 0, 0)</code>."
	},
	"Path2D": {
		"brief_description": "Contains a [Curve2D](../Curve2D) path for [PathFollow2D](../PathFollow2D) nodes to follow.",
		"description": "Can have [PathFollow2D](../PathFollow2D) child nodes moving along the [Curve2D](../Curve2D). See [PathFollow2D](../PathFollow2D) for more information on usage.\n<b>Note:</b> The path is considered as relative to the moved nodes (children of [PathFollow2D](../PathFollow2D)). As such, the curve should usually start with a zero vector (<code>(0, 0)</code>)."
	},
	"ParticleProcessMaterial": {
		"brief_description": "Particle properties for [GPUParticles3D](../GPUParticles3D) and [GPUParticles2D](../GPUParticles2D) nodes.",
		"description": "ParticleProcessMaterial defines particle properties and behavior. It is used in the <code>process_material</code> of [GPUParticles3D](../GPUParticles3D) and [GPUParticles2D](../GPUParticles2D) emitter nodes.\nSome of this material's properties are applied to each particle when emitted, while others can have a [CurveTexture](../CurveTexture) applied to vary values over the lifetime of the particle.\nParticle animation is available only in [GPUParticles2D](../GPUParticles2D). To use it, attach a [CanvasItemMaterial](../CanvasItemMaterial), with <a href=\"../CanvasItemMaterial#particles_animation\">CanvasItemMaterial.particles_animation<a> enabled, to the particles node."
	},
	"ParallaxLayer": {
		"brief_description": "A parallax scrolling layer to be used with [ParallaxBackground](../ParallaxBackground).",
		"description": "A ParallaxLayer must be the child of a [ParallaxBackground](../ParallaxBackground) node. Each ParallaxLayer can be set to move at different speeds relative to the camera movement or the <a href=\"../ParallaxBackground#scroll_offset\">ParallaxBackground.scroll_offset<a> value.\nThis node's children will be affected by its scroll offset.\n<b>Note:</b> Any changes to this node's position and scale made after it enters the scene will be ignored."
	},
	"ParallaxBackground": {
		"brief_description": "A node used to create a parallax scrolling background.",
		"description": "A ParallaxBackground uses one or more [ParallaxLayer](../ParallaxLayer) child nodes to create a parallax effect. Each [ParallaxLayer](../ParallaxLayer) can move at a different speed using <a href=\"../ParallaxLayer#motion_offset\">ParallaxLayer.motion_offset<a>. This creates an illusion of depth in a 2D game. If not used with a [Camera2D](../Camera2D), you must manually calculate the <a href=\"#scroll_offset\">scroll_offset</a>."
	},
	"PanoramaSkyMaterial": {
		"brief_description": "A [Material](../Material) used with [Sky](../Sky) to draw a background texture.",
		"description": "A resource referenced in a [Sky](../Sky) that is used to draw a background. The Panorama sky material functions similar to skyboxes in other engines, except it uses an equirectangular sky map instead of a cubemap.\nUsing an HDR panorama is strongly recommended for accurate, high-quality reflections. Godot supports the Radiance HDR (<code>.hdr</code>) and OpenEXR (<code>.exr</code>) image formats for this purpose.\nYou can use [this tool](https://danilw.github.io/GLSL-howto/cubemap_to_panorama_js/cubemap_to_panorama.html) to convert a cubemap to an equirectangular sky map."
	},
	"PanelContainer": {
		"brief_description": "Panel container type.",
		"description": "Panel container type. This container fits controls inside of the delimited area of a stylebox. It's useful for giving controls an outline."
	},
	"Panel": {
		"brief_description": "Provides an opaque background for [Control](../Control) children.",
		"description": "Panel is a [Control](../Control) that displays an opaque background. It's commonly used as a parent and container for other types of [Control](../Control) nodes."
	},
	"PacketPeerUDP": {
		"brief_description": "UDP packet peer.",
		"description": "UDP packet peer. Can be used to send raw UDP packets as well as [Variant](../Variant)s.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"PacketPeerStream": {
		"brief_description": "Wrapper to use a PacketPeer over a StreamPeer.",
		"description": "PacketStreamPeer provides a wrapper for working using packets over a stream. This allows for using packet based code with StreamPeers. PacketPeerStream implements a custom protocol over the StreamPeer, so the user should not read or write to the wrapped StreamPeer directly.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"PacketPeerExtension": {
		"brief_description": "",
		"description": ""
	},
	"PacketPeerDTLS": {
		"brief_description": "DTLS packet peer.",
		"description": "This class represents a DTLS peer connection. It can be used to connect to a DTLS server, and is returned by <a href=\"../DTLSServer#take_connection\">DTLSServer.take_connection<a>.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android.\n<b>Warning:</b> TLS certificate revocation and certificate pinning are currently not supported. Revoked certificates are accepted as long as they are otherwise valid. If this is a concern, you may want to use automatically managed certificates with a short validity period."
	},
	"PacketPeer": {
		"brief_description": "Abstraction and base class for packet-based protocols.",
		"description": "PacketPeer is an abstraction and base class for packet-based protocols (such as UDP). It provides an API for sending and receiving packets both as raw data or variables. This makes it easy to transfer data over a protocol, without having to encode data as low-level bytes or having to worry about network ordering.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"PackedVector3Array": {
		"brief_description": "A packed array of [Vector3](../Vector3)s.",
		"description": "An array specifically designed to hold [Vector3](../Vector3). Packs data tightly, so it saves memory for large array sizes."
	},
	"PackedVector2Array": {
		"brief_description": "A packed array of [Vector2](../Vector2)s.",
		"description": "An array specifically designed to hold [Vector2](../Vector2). Packs data tightly, so it saves memory for large array sizes."
	},
	"PackedStringArray": {
		"brief_description": "A packed array of [String](../String)s.",
		"description": "An array specifically designed to hold [String](../String)s. Packs data tightly, so it saves memory for large array sizes.\nIf you want to join the strings in the array, use <a href=\"../String#join\">String.join<a>.\n<code>\nvar string_array = PackedStringArray([\"hello\", \"world\"])\nvar string = \" \".join(string_array)\nprint(string) # \"hello world\"\n</code>"
	},
	"PackedScene": {
		"brief_description": "An abstraction of a serialized scene.",
		"description": "A simplified interface to a scene file. Provides access to operations and checks that can be performed on the scene resource itself.\nCan be used to save a node to a file. When saving, the node as well as all the nodes it owns get saved (see <a href=\"../Node#owner\">Node.owner<a> property).\n<b>Note:</b> The node doesn't need to own itself.\n<b>Example of loading a saved scene:</b>\n<!-- <codeblocks> -->\n<code>\n# Use load() instead of preload() if the path isn't known at compile-time.\nvar scene = preload(\"res://scene.tscn\").instantiate()\n# Add the node as a child of the node the script is attached to.\nadd_child(scene)\n</code>\n```csharp\n// C# has no preload, so you have to always use ResourceLoader.Load<PackedScene>().\nvar scene = ResourceLoader.Load<PackedScene>(\"res://scene.tscn\").Instantiate();\n// Add the node as a child of the node the script is attached to.\nAddChild(scene);\n```\n<!-- </codeblocks> -->\n<b>Example of saving a node with different owners:</b> The following example creates 3 objects: [Node2D](../Node2D) (<code>node</code>), [RigidBody2D](../RigidBody2D) (<code>body</code>) and [CollisionObject2D](../CollisionObject2D) (<code>collision</code>). <code>collision</code> is a child of <code>body</code> which is a child of <code>node</code>. Only <code>body</code> is owned by <code>node</code> and <code>pack</code> will therefore only save those two nodes, but not <code>collision</code>.\n<!-- <codeblocks> -->\n<code>\n# Create the objects.\nvar node = Node2D.new()\nvar body = RigidBody2D.new()\nvar collision = CollisionShape2D.new()\n\n# Create the object hierarchy.\nbody.add_child(collision)\nnode.add_child(body)\n\n# Change owner of `body`, but not of `collision`.\nbody.owner = node\nvar scene = PackedScene.new()\n\n# Only `node` and `body` are now packed.\nvar result = scene.pack(node)\nif result == OK:\n\tvar error = ResourceSaver.save(scene, \"res://path/name.tscn\")  # Or \"user://...\"\n\tif error != OK:\n\t\tpush_error(\"An error occurred while saving the scene to disk.\")\n</code>\n```csharp\n// Create the objects.\nvar node = new Node2D();\nvar body = new RigidBody2D();\nvar collision = new CollisionShape2D();\n\n// Create the object hierarchy.\nbody.AddChild(collision);\nnode.AddChild(body);\n\n// Change owner of `body`, but not of `collision`.\nbody.Owner = node;\nvar scene = new PackedScene();\n\n// Only `node` and `body` are now packed.\nError result = scene.Pack(node);\nif (result == Error.Ok)\n{\n\tError error = ResourceSaver.Save(scene, \"res://path/name.tscn\"); // Or \"user://...\"\n\tif (error != Error.Ok)\n\t{\n\t\tGD.PushError(\"An error occurred while saving the scene to disk.\");\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"PackedInt64Array": {
		"brief_description": "A packed array of 64-bit integers.",
		"description": "An array specifically designed to hold 64-bit integer values. Packs data tightly, so it saves memory for large array sizes.\n<b>Note:</b> This type stores signed 64-bit integers, which means it can take values in the interval <code>[-2^63, 2^63 - 1]</code>, i.e. <code>[-9223372036854775808, 9223372036854775807]</code>. Exceeding those bounds will wrap around. If you only need to pack 32-bit integers tightly, see [PackedInt32Array](../PackedInt32Array) for a more memory-friendly alternative."
	},
	"PackedInt32Array": {
		"brief_description": "A packed array of 32-bit integers.",
		"description": "An array specifically designed to hold 32-bit integer values. Packs data tightly, so it saves memory for large array sizes.\n<b>Note:</b> This type stores signed 32-bit integers, which means it can take values in the interval <code>[-2^31, 2^31 - 1]</code>, i.e. <code>[-2147483648, 2147483647]</code>. Exceeding those bounds will wrap around. In comparison, [int](../int) uses signed 64-bit integers which can hold much larger values. If you need to pack 64-bit integers tightly, see [PackedInt64Array](../PackedInt64Array)."
	},
	"PackedFloat64Array": {
		"brief_description": "A packed array of 64-bit floating-point values.",
		"description": "An array specifically designed to hold 64-bit floating-point values (double). Packs data tightly, so it saves memory for large array sizes.\nIf you only need to pack 32-bit floats tightly, see [PackedFloat32Array](../PackedFloat32Array) for a more memory-friendly alternative."
	},
	"PackedFloat32Array": {
		"brief_description": "A packed array of 32-bit floating-point values.",
		"description": "An array specifically designed to hold 32-bit floating-point values (float). Packs data tightly, so it saves memory for large array sizes.\nIf you need to pack 64-bit floats tightly, see [PackedFloat64Array](../PackedFloat64Array)."
	},
	"PackedDataContainerRef": {
		"brief_description": "Reference-counted version of [PackedDataContainer](../PackedDataContainer).",
		"description": ""
	},
	"PackedDataContainer": {
		"brief_description": "",
		"description": ""
	},
	"PackedColorArray": {
		"brief_description": "A packed array of [Color](../Color)s.",
		"description": "An array specifically designed to hold [Color](../Color). Packs data tightly, so it saves memory for large array sizes."
	},
	"PackedByteArray": {
		"brief_description": "A packed array of bytes.",
		"description": "An array specifically designed to hold bytes. Packs data tightly, so it saves memory for large array sizes.\n[PackedByteArray](../PackedByteArray) also provides methods to encode/decode various types to/from bytes. The way values are encoded is an implementation detail and shouldn't be relied upon when interacting with external apps."
	},
	"OS": {
		"brief_description": "Operating System functions.",
		"description": "Operating System functions. [OS](../OS) wraps the most common functionality to communicate with the host operating system, such as the clipboard, video driver, delays, environment variables, execution of binaries, command line, etc.\n<b>Note:</b> In Godot 4, [OS](../OS) functions related to window management were moved to the [DisplayServer](../DisplayServer) singleton."
	},
	"ORMMaterial3D": {
		"brief_description": "Physically based rendering (PBR) material that can be applied to 3D objects, can use an ORM texture.",
		"description": "ORMMaterial3D's properties are inherited from [BaseMaterial3D](../BaseMaterial3D). Unlike [StandardMaterial3D](../StandardMaterial3D), ORMMaterial3D uses a single texture for ambient occlusion, roughness and metallic maps, known as an ORM texture."
	},
	"OptionButton": {
		"brief_description": "Button control that provides selectable options when pressed.",
		"description": "OptionButton is a type button that provides a selectable list of items when pressed. The item selected becomes the \"current\" item and is displayed as the button text.\nSee also [BaseButton](../BaseButton) which contains common properties and methods associated with this node.\n<b>Note:</b> Properties <a href=\"../Button#text\">Button.text<a> and <a href=\"../Button#icon\">Button.icon<a> are automatically set based on the selected item. They shouldn't be changed manually."
	},
	"OptimizedTranslation": {
		"brief_description": "Optimized translation.",
		"description": "Optimized translation. Uses real-time compressed translations, which results in very small dictionaries."
	},
	"OmniLight3D": {
		"brief_description": "Omnidirectional light, such as a light bulb or a candle.",
		"description": "An Omnidirectional light is a type of [Light3D](../Light3D) that emits light in all directions. The light is attenuated by distance and this attenuation can be configured by changing its energy, radius, and attenuation parameters.\n<b>Note:</b> When using the Mobile rendering method, only 8 omni lights can be displayed on each mesh resource. Attempting to display more than 8 omni lights on a single mesh resource will result in omni lights flickering in and out as the camera moves. When using the Compatibility rendering method, only 8 omni lights can be displayed on each mesh resource by default, but this can be increased by adjusting [member ProjectSettings.rendering/limits/opengl/max_lights_per_object].\n<b>Note:</b> When using the Mobile or Compatibility rendering methods, omni lights will only correctly affect meshes whose visibility AABB intersects with the light's AABB. If using a shader to deform the mesh in a way that makes it go outside its AABB, <a href=\"../GeometryInstance3D#extra_cull_margin\">GeometryInstance3D.extra_cull_margin<a> must be increased on the mesh. Otherwise, the light may not be visible on the mesh."
	},
	"OfflineMultiplayerPeer": {
		"brief_description": "A [MultiplayerPeer](../MultiplayerPeer) which is always connected and acts as a server.",
		"description": "This is the default <a href=\"../MultiplayerAPI#multiplayer_peer\">MultiplayerAPI.multiplayer_peer<a> for the <a href=\"../Node#multiplayer\">Node.multiplayer<a>. It mimics the behavior of a server with no peers connected.\nThis means that the [SceneTree](../SceneTree) will act as the multiplayer authority by default. Calls to <a href=\"../MultiplayerAPI#is_server\">MultiplayerAPI.is_server<a> will return <code>true</code>, and calls to <a href=\"../MultiplayerAPI#get_unique_id\">MultiplayerAPI.get_unique_id<a> will return <a href=\"../MultiplayerPeer#TARGET_PEER_SERVER\">MultiplayerPeer.TARGET_PEER_SERVER<a>."
	},
	"OccluderPolygon2D": {
		"brief_description": "Defines a 2D polygon for LightOccluder2D.",
		"description": "Editor facility that helps you draw a 2D polygon used as resource for [LightOccluder2D](../LightOccluder2D)."
	},
	"OccluderInstance3D": {
		"brief_description": "Provides occlusion culling for 3D nodes, which improves performance in closed areas.",
		"description": "Occlusion culling can improve rendering performance in closed/semi-open areas by hiding geometry that is occluded by other objects.\nThe occlusion culling system is mostly static. [OccluderInstance3D](../OccluderInstance3D)s can be moved or hidden at run-time, but doing so will trigger a background recomputation that can take several frames. It is recommended to only move [OccluderInstance3D](../OccluderInstance3D)s sporadically (e.g. for procedural generation purposes), rather than doing so every frame.\nThe occlusion culling system works by rendering the occluders on the CPU in parallel using [Embree](https://www.embree.org/), drawing the result to a low-resolution buffer then using this to cull 3D nodes individually. In the 3D editor, you can preview the occlusion culling buffer by choosing <b>Perspective > Debug Advanced... > Occlusion Culling Buffer</b> in the top-left corner of the 3D viewport. The occlusion culling buffer quality can be adjusted in the Project Settings.\n<b>Baking:</b> Select an [OccluderInstance3D](../OccluderInstance3D) node, then use the <b>Bake Occluders</b> button at the top of the 3D editor. Only opaque materials will be taken into account; transparent materials (alpha-blended or alpha-tested) will be ignored by the occluder generation.\n<b>Note:</b> Occlusion culling is only effective if [member ProjectSettings.rendering/occlusion_culling/use_occlusion_culling] is <code>true</code>. Enabling occlusion culling has a cost on the CPU. Only enable occlusion culling if you actually plan to use it. Large open scenes with few or no objects blocking the view will generally not benefit much from occlusion culling. Large open scenes generally benefit more from mesh LOD and visibility ranges (<a href=\"../GeometryInstance3D#visibility_range_begin\">GeometryInstance3D.visibility_range_begin<a> and <a href=\"../GeometryInstance3D#visibility_range_end\">GeometryInstance3D.visibility_range_end<a>) compared to occlusion culling."
	},
	"Occluder3D": {
		"brief_description": "Occluder shape resource for use with occlusion culling in [OccluderInstance3D](../OccluderInstance3D).",
		"description": "[Occluder3D](../Occluder3D) stores an occluder shape that can be used by the engine's occlusion culling system.\nSee [OccluderInstance3D](../OccluderInstance3D)'s documentation for instructions on setting up occlusion culling."
	},
	"Object": {
		"brief_description": "Base class for all other classes in the engine.",
		"description": "An advanced [Variant](../Variant) type. All classes in the engine inherit from Object. Each class may define new properties, methods or signals, which are available to all inheriting classes. For example, a [Sprite2D](../Sprite2D) instance is able to call <a href=\"../Node#add_child\">Node.add_child<a> because it inherits from [Node](../Node).\nYou can create new instances, using <code>Object.new()</code> in GDScript, or <code>new Object</code> in C#.\nTo delete an Object instance, call <a href=\"#free\">free</a>. This is necessary for most classes inheriting Object, because they do not manage memory on their own, and will otherwise cause memory leaks when no longer in use. There are a few classes that perform memory management. For example, [RefCounted](../RefCounted) (and by extension [Resource](../Resource)) deletes itself when no longer referenced, and [Node](../Node) deletes its children when freed.\nObjects can have a [Script](../Script) attached to them. Once the [Script](../Script) is instantiated, it effectively acts as an extension to the base class, allowing it to define and inherit new properties, methods and signals.\nInside a [Script](../Script), <a href=\"#_get_property_list\">_get_property_list</a> may be overridden to customize properties in several ways. This allows them to be available to the editor, display as lists of options, sub-divide into groups, save on disk, etc. Scripting languages offer easier ways to customize properties, such as with the [annotation @GDScript.@export] annotation.\nGodot is very dynamic. An object's script, and therefore its properties, methods and signals, can be changed at run-time. Because of this, there can be occasions where, for example, a property required by a method may not exist. To prevent run-time errors, see methods such as <a href=\"#set\">set</a>, <a href=\"#get\">get</a>, <a href=\"#call\">call</a>, <a href=\"#has_method\">has_method</a>, <a href=\"#has_signal\">has_signal</a>, etc. Note that these methods are <b>much</b> slower than direct references.\nIn GDScript, you can also check if a given property, method, or signal name exists in an object with the <code>in</code> operator:\n<code>\nvar node = Node.new()\nprint(\"name\" in node)\t\t # Prints true\nprint(\"get_parent\" in node)   # Prints true\nprint(\"tree_entered\" in node) # Prints true\nprint(\"unknown\" in node)\t  # Prints false\n</code>\nNotifications are [int](../int) constants commonly sent and received by objects. For example, on every rendered frame, the [SceneTree](../SceneTree) notifies nodes inside the tree with a <a href=\"../Node#NOTIFICATION_PROCESS\">Node.NOTIFICATION_PROCESS<a>. The nodes receive it and may call <a href=\"../Node#_process\">Node._process<a> to update. To make use of notifications, see <a href=\"#notification\">notification</a> and <a href=\"#_notification\">_notification</a>.\nLastly, every object can also contain metadata (data about data). <a href=\"#set_meta\">set_meta</a> can be useful to store information that the object itself does not depend on. To keep your code clean, making excessive use of metadata is discouraged.\n<b>Note:</b> Unlike references to a [RefCounted](../RefCounted), references to an object stored in a variable can become invalid without being set to <code>null</code>. To check if an object has been deleted, do <i>not</i> compare it against <code>null</code>. Instead, use [method @GlobalScope.is_instance_valid]. It's also recommended to inherit from [RefCounted](../RefCounted) for classes storing data instead of [Object](../Object).\n<b>Note:</b> The <code>script</code> is not exposed like most properties. To set or get an object's [Script](../Script) in code, use <a href=\"#set_script\">set_script</a> and <a href=\"#get_script\">get_script</a>, respectively."
	},
	"NodePath": {
		"brief_description": "Pre-parsed scene tree path.",
		"description": "A pre-parsed relative or absolute path in a scene tree, for use with <a href=\"../Node#get_node\">Node.get_node<a> and similar functions. It can reference a node, a resource within a node, or a property of a node or resource. For example, <code>\"Path2D/PathFollow2D/Sprite2D:texture:size\"</code> would refer to the <code>size</code> property of the <code>texture</code> resource on the node named <code>\"Sprite2D\"</code> which is a child of the other named nodes in the path.\nYou will usually just pass a string to <a href=\"../Node#get_node\">Node.get_node<a> and it will be automatically converted, but you may occasionally want to parse a path ahead of time with [NodePath](../NodePath) or the literal syntax <code>^\"path\"</code>. Exporting a [NodePath](../NodePath) variable will give you a node selection widget in the properties panel of the editor, which can often be useful.\nA [NodePath](../NodePath) is composed of a list of slash-separated node names (like a filesystem path) and an optional colon-separated list of \"subnames\" which can be resources or properties.\nSome examples of NodePaths include the following:\n<code>\n# No leading slash means it is relative to the current node.\n^\"A\" # Immediate child A\n^\"A/B\" # A's child B\n^\".\" # The current node.\n^\"..\" # The parent node.\n^\"../C\" # A sibling node C.\n# A leading slash means it is absolute from the SceneTree.\n^\"/root\" # Equivalent to get_tree().get_root().\n^\"/root/Main\" # If your main scene's root node were named \"Main\".\n^\"/root/MyAutoload\" # If you have an autoloaded node or scene.\n</code>\nSee also [StringName](../StringName), which is a similar concept for general-purpose string interning.\n<b>Note:</b> In the editor, [NodePath](../NodePath) properties are automatically updated when moving, renaming or deleting a node in the scene tree, but they are never updated at runtime."
	},
	"Node3DGizmo": {
		"brief_description": "",
		"description": ""
	},
	"Node3D": {
		"brief_description": "Most basic 3D game object, parent of all 3D-related nodes.",
		"description": "Most basic 3D game object, with a [Transform3D](../Transform3D) and visibility settings. All other 3D game objects inherit from Node3D. Use [Node3D](../Node3D) as a parent node to move, scale, rotate and show/hide children in a 3D project.\nAffine operations (rotate, scale, translate) happen in parent's local coordinate system, unless the [Node3D](../Node3D) object is set as top-level. Affine operations in this coordinate system correspond to direct affine operations on the [Node3D](../Node3D)'s transform. The word local below refers to this coordinate system. The coordinate system that is attached to the [Node3D](../Node3D) object itself is referred to as object-local coordinate system.\n<b>Note:</b> Unless otherwise specified, all methods that have angle parameters must have angles specified as <i>radians</i>. To convert degrees to radians, use [method @GlobalScope.deg_to_rad]."
	},
	"Node2D": {
		"brief_description": "A 2D game object, inherited by all 2D-related nodes. Has a position, rotation, scale, and Z index.",
		"description": "A 2D game object, with a transform (position, rotation, and scale). All 2D nodes, including physics objects and sprites, inherit from Node2D. Use Node2D as a parent node to move, scale and rotate children in a 2D project. Also gives control of the node's render order."
	},
	"Node": {
		"brief_description": "Base class for all <i>scene</i> objects.",
		"description": "Nodes are Godot's building blocks. They can be assigned as the child of another node, resulting in a tree arrangement. A given node can contain any number of nodes as children with the requirement that all siblings (direct children of a node) should have unique names.\nA tree of nodes is called a <i>scene</i>. Scenes can be saved to the disk and then instantiated into other scenes. This allows for very high flexibility in the architecture and data model of Godot projects.\n<b>Scene tree:</b> The [SceneTree](../SceneTree) contains the active tree of nodes. When a node is added to the scene tree, it receives the <a href=\"#NOTIFICATION_ENTER_TREE\">NOTIFICATION_ENTER_TREE</a> notification and its <a href=\"#_enter_tree\">_enter_tree</a> callback is triggered. Child nodes are always added <i>after</i> their parent node, i.e. the <a href=\"#_enter_tree\">_enter_tree</a> callback of a parent node will be triggered before its child's.\nOnce all nodes have been added in the scene tree, they receive the <a href=\"#NOTIFICATION_READY\">NOTIFICATION_READY</a> notification and their respective <a href=\"#_ready\">_ready</a> callbacks are triggered. For groups of nodes, the <a href=\"#_ready\">_ready</a> callback is called in reverse order, starting with the children and moving up to the parent nodes.\nThis means that when adding a node to the scene tree, the following order will be used for the callbacks: <a href=\"#_enter_tree\">_enter_tree</a> of the parent, <a href=\"#_enter_tree\">_enter_tree</a> of the children, <a href=\"#_ready\">_ready</a> of the children and finally <a href=\"#_ready\">_ready</a> of the parent (recursively for the entire scene tree).\n<b>Processing:</b> Nodes can override the \"process\" state, so that they receive a callback on each frame requesting them to process (do something). Normal processing (callback <a href=\"#_process\">_process</a>, toggled with <a href=\"#set_process\">set_process</a>) happens as fast as possible and is dependent on the frame rate, so the processing time <i>delta</i> (in seconds) is passed as an argument. Physics processing (callback <a href=\"#_physics_process\">_physics_process</a>, toggled with <a href=\"#set_physics_process\">set_physics_process</a>) happens a fixed number of times per second (60 by default) and is useful for code related to the physics engine.\nNodes can also process input events. When present, the <a href=\"#_input\">_input</a> function will be called for each input that the program receives. In many cases, this can be overkill (unless used for simple projects), and the <a href=\"#_unhandled_input\">_unhandled_input</a> function might be preferred; it is called when the input event was not handled by anyone else (typically, GUI [Control](../Control) nodes), ensuring that the node only receives the events that were meant for it.\nTo keep track of the scene hierarchy (especially when instancing scenes into other scenes), an \"owner\" can be set for the node with the <a href=\"#owner\">owner</a> property. This keeps track of who instantiated what. This is mostly useful when writing editors and tools, though.\nFinally, when a node is freed with <a href=\"../Object#free\">Object.free<a> or <a href=\"#queue_free\">queue_free</a>, it will also free all its children.\n<b>Groups:</b> Nodes can be added to as many groups as you want to be easy to manage, you could create groups like \"enemies\" or \"collectables\" for example, depending on your game. See <a href=\"#add_to_group\">add_to_group</a>, <a href=\"#is_in_group\">is_in_group</a> and <a href=\"#remove_from_group\">remove_from_group</a>. You can then retrieve all nodes in these groups, iterate them and even call methods on groups via the methods on [SceneTree](../SceneTree).\n<b>Networking with nodes:</b> After connecting to a server (or making one, see [ENetMultiplayerPeer](../ENetMultiplayerPeer)), it is possible to use the built-in RPC (remote procedure call) system to communicate over the network. By calling <a href=\"#rpc\">rpc</a> with a method name, it will be called locally and in all connected peers (peers = clients and the server that accepts connections). To identify which node receives the RPC call, Godot will use its [NodePath](../NodePath) (make sure node names are the same on all peers). Also, take a look at the high-level networking tutorial and corresponding demos.\n<b>Note:</b> The <code>script</code> property is part of the [Object](../Object) class, not [Node](../Node). It isn't exposed like most properties but does have a setter and getter (<code>set_script()</code> and <code>get_script()</code>)."
	},
	"NinePatchRect": {
		"brief_description": "Scalable texture-based frame that tiles the texture's centers and sides, but keeps the corners' original size. Perfect for panels and dialog boxes.",
		"description": "Also known as 9-slice panels, NinePatchRect produces clean panels of any size, based on a small texture. To do so, it splits the texture in a 33 grid. When you scale the node, it tiles the texture's sides horizontally or vertically, the center on both axes but it doesn't scale or tile the corners."
	},
	"NavigationServer3D": {
		"brief_description": "Server interface for low-level 3D navigation access.",
		"description": "NavigationServer3D is the server responsible for all 3D navigation. It handles several objects, namely maps, regions and agents.\nMaps are made up of regions, which are made of navigation meshes. Together, they define the navigable areas in the 3D world.\n<b>Note:</b> Most NavigationServer changes take effect after the next physics frame and not immediately. This includes all changes made to maps, regions or agents by navigation related Nodes in the SceneTree or made through scripts.\nFor two regions to be connected to each other, they must share a similar edge. An edge is considered connected to another if both of its two vertices are at a distance less than <code>edge_connection_margin</code> to the respective other edge's vertex.\nYou may assign navigation layers to regions with <a href=\"../NavigationServer3D#region_set_navigation_layers\">NavigationServer3D.region_set_navigation_layers<a>, which then can be checked upon when requesting a path with <a href=\"../NavigationServer3D#map_get_path\">NavigationServer3D.map_get_path<a>. This allows allowing or forbidding some areas to 3D objects.\nTo use the collision avoidance system, you may use agents. You can set an agent's target velocity, then the servers will emit a callback with a modified velocity.\n<b>Note:</b> The collision avoidance system ignores regions. Using the modified velocity as-is might lead to pushing and agent outside of a navigable area. This is a limitation of the collision avoidance system, any more complex situation may require the use of the physics engine.\nThis server keeps tracks of any call and executes them during the sync phase. This means that you can request any change to the map, using any thread, without worrying."
	},
	"NavigationServer2D": {
		"brief_description": "Server interface for low-level 2D navigation access.",
		"description": "NavigationServer2D is the server responsible for all 2D navigation. It handles several objects, namely maps, regions and agents.\nMaps are made up of regions, which are made of navigation polygons. Together, they define the navigable areas in the 2D world.\n<b>Note:</b> Most NavigationServer changes take effect after the next physics frame and not immediately. This includes all changes made to maps, regions or agents by navigation related Nodes in the SceneTree or made through scripts.\nFor two regions to be connected to each other, they must share a similar edge. An edge is considered connected to another if both of its two vertices are at a distance less than <code>edge_connection_margin</code> to the respective other edge's vertex.\nYou may assign navigation layers to regions with <a href=\"../NavigationServer2D#region_set_navigation_layers\">NavigationServer2D.region_set_navigation_layers<a>, which then can be checked upon when requesting a path with <a href=\"../NavigationServer2D#map_get_path\">NavigationServer2D.map_get_path<a>. This allows allowing or forbidding some areas to 2D objects.\nTo use the collision avoidance system, you may use agents. You can set an agent's target velocity, then the servers will emit a callback with a modified velocity.\n<b>Note:</b> The collision avoidance system ignores regions. Using the modified velocity as-is might lead to pushing and agent outside of a navigable area. This is a limitation of the collision avoidance system, any more complex situation may require the use of the physics engine.\nThis server keeps tracks of any call and executes them during the sync phase. This means that you can request any change to the map, using any thread, without worrying."
	},
	"NavigationRegion3D": {
		"brief_description": "A region of the navigation map.",
		"description": "A region of the navigation map. It tells the [NavigationServer3D](../NavigationServer3D) what can be navigated and what cannot, based on its [NavigationMesh](../NavigationMesh) resource.\nTwo regions can be connected to each other if they share a similar edge. You can set the minimum distance between two vertices required to connect two edges by using <a href=\"../NavigationServer3D#map_set_edge_connection_margin\">NavigationServer3D.map_set_edge_connection_margin<a>.\n<b>Note:</b> Overlapping two regions' navigation meshes is not enough for connecting two regions. They must share a similar edge.\nThe cost of entering this region from another region can be controlled with the <a href=\"#enter_cost\">enter_cost</a> value.\n<b>Note:</b> This value is not added to the path cost when the start position is already inside this region.\nThe cost of traveling distances inside this region can be controlled with the <a href=\"#travel_cost\">travel_cost</a> multiplier.\n<b>Note:</b> This node caches changes to its properties, so if you make changes to the underlying region [RID](../RID) in [NavigationServer3D](../NavigationServer3D), they will not be reflected in this node's properties."
	},
	"NavigationRegion2D": {
		"brief_description": "A region of the 2D navigation map.",
		"description": "A region of the navigation map. It tells the [NavigationServer2D](../NavigationServer2D) what can be navigated and what cannot, based on its [NavigationPolygon](../NavigationPolygon) resource.\nTwo regions can be connected to each other if they share a similar edge. You can set the minimum distance between two vertices required to connect two edges by using <a href=\"../NavigationServer2D#map_set_edge_connection_margin\">NavigationServer2D.map_set_edge_connection_margin<a>.\n<b>Note:</b> Overlapping two regions' navigation polygons is not enough for connecting two regions. They must share a similar edge.\nThe pathfinding cost of entering this region from another region can be controlled with the <a href=\"#enter_cost\">enter_cost</a> value.\n<b>Note:</b> This value is not added to the path cost when the start position is already inside this region.\nThe pathfinding cost of traveling distances inside this region can be controlled with the <a href=\"#travel_cost\">travel_cost</a> multiplier.\n<b>Note:</b> This node caches changes to its properties, so if you make changes to the underlying region [RID](../RID) in [NavigationServer2D](../NavigationServer2D), they will not be reflected in this node's properties."
	},
	"NavigationPolygon": {
		"brief_description": "A node that has methods to draw outlines or use indices of vertices to create navigation polygons.",
		"description": "There are two ways to create polygons. Either by using the <a href=\"#add_outline\">add_outline</a> method, or using the <a href=\"#add_polygon\">add_polygon</a> method.\nUsing <a href=\"#add_outline\">add_outline</a>:\n<!-- <codeblocks> -->\n<code>\nvar polygon = NavigationPolygon.new()\nvar outline = PackedVector2Array([Vector2(0, 0), Vector2(0, 50), Vector2(50, 50), Vector2(50, 0)])\npolygon.add_outline(outline)\npolygon.make_polygons_from_outlines()\n$NavigationRegion2D.navigation_polygon = polygon\n</code>\n```csharp\nvar polygon = new NavigationPolygon();\nvar outline = new Vector2[] { new Vector2(0, 0), new Vector2(0, 50), new Vector2(50, 50), new Vector2(50, 0) };\npolygon.AddOutline(outline);\npolygon.MakePolygonsFromOutlines();\nGetNode<NavigationRegion2D>(\"NavigationRegion2D\").NavigationPolygon = polygon;\n```\n<!-- </codeblocks> -->\nUsing <a href=\"#add_polygon\">add_polygon</a> and indices of the vertices array.\n<!-- <codeblocks> -->\n<code>\nvar polygon = NavigationPolygon.new()\nvar vertices = PackedVector2Array([Vector2(0, 0), Vector2(0, 50), Vector2(50, 50), Vector2(50, 0)])\npolygon.vertices = vertices\nvar indices = PackedInt32Array([0, 1, 2, 3])\npolygon.add_polygon(indices)\n$NavigationRegion2D.navigation_polygon = polygon\n</code>\n```csharp\nvar polygon = new NavigationPolygon();\nvar vertices = new Vector2[] { new Vector2(0, 0), new Vector2(0, 50), new Vector2(50, 50), new Vector2(50, 0) };\npolygon.Vertices = vertices;\nvar indices = new int[] { 0, 1, 2, 3 };\npolygon.AddPolygon(indices);\nGetNode<NavigationRegion2D>(\"NavigationRegion2D\").NavigationPolygon = polygon;\n```\n<!-- </codeblocks> -->"
	},
	"NavigationPathQueryResult3D": {
		"brief_description": "Result from a [NavigationPathQueryParameters3D](../NavigationPathQueryParameters3D) navigation path query.",
		"description": "This class contains the result of a navigation path query from <a href=\"../NavigationServer3D#query_path\">NavigationServer3D.query_path<a>."
	},
	"NavigationPathQueryResult2D": {
		"brief_description": "Result from a [NavigationPathQueryParameters2D](../NavigationPathQueryParameters2D) navigation path query.",
		"description": "This class contains the result of a navigation path query from <a href=\"../NavigationServer2D#query_path\">NavigationServer2D.query_path<a>."
	},
	"NavigationPathQueryParameters3D": {
		"brief_description": "Parameters to be sent to a 3D navigation path query.",
		"description": "This class contains the start and target position and other parameters to be used with <a href=\"../NavigationServer3D#query_path\">NavigationServer3D.query_path<a>."
	},
	"NavigationPathQueryParameters2D": {
		"brief_description": "Parameters to be sent to a 2D navigation path query.",
		"description": "This class contains the start and target position and other parameters to be used with <a href=\"../NavigationServer2D#query_path\">NavigationServer2D.query_path<a>."
	},
	"NavigationObstacle3D": {
		"brief_description": "3D Obstacle used in navigation for collision avoidance.",
		"description": "3D Obstacle used in navigation for collision avoidance. The obstacle needs navigation data to work correctly. [NavigationObstacle3D](../NavigationObstacle3D) is physics safe.\nObstacles <b>don't</b> change the resulting path from the pathfinding, they only affect the navigation agent movement in a radius. Therefore, using obstacles for the static walls in your level won't work because those walls don't exist in the pathfinding. The navigation agent will be pushed in a semi-random direction away while moving inside that radius. Obstacles are intended as a last resort option for constantly moving objects that cannot be (re)baked to a navigation mesh efficiently."
	},
	"NavigationObstacle2D": {
		"brief_description": "2D Obstacle used in navigation for collision avoidance.",
		"description": "2D Obstacle used in navigation for collision avoidance. The obstacle needs navigation data to work correctly. [NavigationObstacle2D](../NavigationObstacle2D) is physics safe.\nObstacles <b>don't</b> change the resulting path from the pathfinding, they only affect the navigation agent movement in a radius. Therefore, using obstacles for the static walls in your level won't work because those walls don't exist in the pathfinding. The navigation agent will be pushed in a semi-random direction away while moving inside that radius. Obstacles are intended as a last resort option for constantly moving objects that cannot be (re)baked to a navigation mesh efficiently."
	},
	"NavigationMeshGenerator": {
		"brief_description": "Helper class for creating and clearing navigation meshes.",
		"description": "This class is responsible for creating and clearing 3D navigation meshes used as [NavigationMesh](../NavigationMesh) resources inside [NavigationRegion3D](../NavigationRegion3D). The [NavigationMeshGenerator](../NavigationMeshGenerator) has very limited to no use for 2D as the navigation mesh baking process expects 3D node types and 3D source geometry to parse.\nThe entire navigation mesh baking is best done in a separate thread as the voxelization, collision tests and mesh optimization steps involved are very performance and time hungry operations.\nNavigation mesh baking happens in multiple steps and the result depends on 3D source geometry and properties of the [NavigationMesh](../NavigationMesh) resource. In the first step, starting from a root node and depending on [NavigationMesh](../NavigationMesh) properties all valid 3D source geometry nodes are collected from the [SceneTree](../SceneTree). Second, all collected nodes are parsed for their relevant 3D geometry data and a combined 3D mesh is build. Due to the many different types of parsable objects, from normal [MeshInstance3D](../MeshInstance3D)s to [CSGShape3D](../CSGShape3D)s or various [CollisionObject3D](../CollisionObject3D)s, some operations to collect geometry data can trigger [RenderingServer](../RenderingServer) and [PhysicsServer3D](../PhysicsServer3D) synchronizations. Server synchronization can have a negative effect on baking time or framerate as it often involves [Mutex](../Mutex) locking for thread security. Many parsable objects and the continuous synchronization with other threaded Servers can increase the baking time significantly. On the other hand only a few but very large and complex objects will take some time to prepare for the Servers which can noticeably stall the next frame render. As a general rule the total number of parsable objects and their individual size and complexity should be balanced to avoid framerate issues or very long baking times. The combined mesh is then passed to the Recast Navigation Object to test the source geometry for walkable terrain suitable to [NavigationMesh](../NavigationMesh) agent properties by creating a voxel world around the meshes bounding area.\nThe finalized navigation mesh is then returned and stored inside the [NavigationMesh](../NavigationMesh) for use as a resource inside [NavigationRegion3D](../NavigationRegion3D) nodes.\n<b>Note:</b> Using meshes to not only define walkable surfaces but also obstruct navigation baking does not always work. The navigation baking has no concept of what is a geometry \"inside\" when dealing with mesh source geometry and this is intentional. Depending on current baking parameters, as soon as the obstructing mesh is large enough to fit a navigation mesh area inside, the baking will generate navigation mesh areas that are inside the obstructing source geometry mesh."
	},
	"NavigationMesh": {
		"brief_description": "A mesh to approximate the walkable areas and obstacles.",
		"description": "A navigation mesh is a collection of polygons that define which areas of an environment are traversable to aid agents in pathfinding through complicated spaces."
	},
	"NavigationLink3D": {
		"brief_description": "Creates a link between two positions that [NavigationServer3D](../NavigationServer3D) can route agents through.",
		"description": "Creates a link between two positions that [NavigationServer3D](../NavigationServer3D) can route agents through. Links can be used to express navigation methods that aren't just traveling along the surface of the navigation mesh, like zip-lines, teleporters, or jumping across gaps."
	},
	"NavigationLink2D": {
		"brief_description": "Creates a link between two positions that [NavigationServer2D](../NavigationServer2D) can route agents through.",
		"description": "Creates a link between two positions that [NavigationServer2D](../NavigationServer2D) can route agents through. Links can be used to express navigation methods that aren't just traveling along the surface of the navigation mesh, like zip-lines, teleporters, or jumping across gaps."
	},
	"NavigationAgent3D": {
		"brief_description": "3D Agent used in navigation for collision avoidance.",
		"description": "3D Agent that is used in navigation to reach a position while avoiding static and dynamic obstacles. The dynamic obstacles are avoided using RVO collision avoidance. The agent needs navigation data to work correctly. [NavigationAgent3D](../NavigationAgent3D) is physics safe.\n<b>Note:</b> After setting <a href=\"#target_position\">target_position</a> it is required to use the <a href=\"#get_next_path_position\">get_next_path_position</a> function once every physics frame to update the internal path logic of the NavigationAgent. The returned vector position from this function should be used as the next movement position for the agent's parent Node."
	},
	"NavigationAgent2D": {
		"brief_description": "2D Agent used in navigation for collision avoidance.",
		"description": "2D Agent that is used in navigation to reach a position while avoiding static and dynamic obstacles. The dynamic obstacles are avoided using RVO collision avoidance. The agent needs navigation data to work correctly. [NavigationAgent2D](../NavigationAgent2D) is physics safe.\n<b>Note:</b> After setting <a href=\"#target_position\">target_position</a> it is required to use the <a href=\"#get_next_path_position\">get_next_path_position</a> function once every physics frame to update the internal path logic of the NavigationAgent. The returned vector position from this function should be used as the next movement position for the agent's parent Node."
	},
	"Mutex": {
		"brief_description": "A synchronization mutex (mutual exclusion).",
		"description": "A synchronization mutex (mutual exclusion). This is used to synchronize multiple [Thread](../Thread)s, and is equivalent to a binary [Semaphore](../Semaphore). It guarantees that only one thread can ever acquire the lock at a time. A mutex can be used to protect a critical section; however, be careful to avoid deadlocks."
	},
	"MultiplayerPeerExtension": {
		"brief_description": "Class that can be inherited to implement custom multiplayer API networking layers via GDExtension.",
		"description": "This class is designed to be inherited from a GDExtension plugin to implement custom networking layers for the multiplayer API (such as WebRTC). All the methods below <b>must</b> be implemented to have a working custom multiplayer implementation. See also [MultiplayerAPI](../MultiplayerAPI)."
	},
	"MultiplayerPeer": {
		"brief_description": "Abstract class for specialized [PacketPeer](../PacketPeer)s used by the [MultiplayerAPI](../MultiplayerAPI).",
		"description": "Manages the connection with one or more remote peers acting as server or client and assigning unique IDs to each of them. See also [MultiplayerAPI](../MultiplayerAPI).\n<b>Note:</b> The [MultiplayerAPI](../MultiplayerAPI) protocol is an implementation detail and isn't meant to be used by non-Godot servers. It may change without notice.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"MultiplayerAPIExtension": {
		"brief_description": "Base class used for extending the [MultiplayerAPI](../MultiplayerAPI).",
		"description": "This class can be used to augment or replace the default [MultiplayerAPI](../MultiplayerAPI) implementation via script or extensions.\nThe following example augment the default implementation ([SceneMultiplayer](../SceneMultiplayer)) by logging every RPC being made, and every object being configured for replication.\n<!-- <codeblocks> -->\n<code>\nextends MultiplayerAPIExtension\nclass_name LogMultiplayer\n\n# We want to augment the default SceneMultiplayer.\nvar base_multiplayer = SceneMultiplayer.new()\n\nfunc _init():\n\t# Just passthourgh base signals (copied to var to avoid cyclic reference)\n\tvar cts = connected_to_server\n\tvar cf = connection_failed\n\tvar pc = peer_connected\n\tvar pd = peer_disconnected\n\tbase_multiplayer.connected_to_server.connect(func(): cts.emit())\n\tbase_multiplayer.connection_failed.connect(func(): cf.emit())\n\tbase_multiplayer.peer_connected.connect(func(id): pc.emit(id))\n\tbase_multiplayer.peer_disconnected.connect(func(id): pd.emit(id))\n\n# Log RPC being made and forward it to the default multiplayer.\nfunc _rpc(peer: int, object: Object, method: StringName, args: Array) -> int: # Error\n\tprint(\"Got RPC for %d: %s::%s(%s)\" % [peer, object, method, args])\n\treturn base_multiplayer.rpc(peer, object, method, args)\n\n# Log configuration add. E.g. root path (nullptr, NodePath), replication (Node, Spawner|Synchronizer), custom.\nfunc _object_configuration_add(object, config: Variant) -> int: # Error\n\tif config is MultiplayerSynchronizer:\n\t\tprint(\"Adding synchronization configuration for %s. Synchronizer: %s\" % [object, config])\n\telif config is MultiplayerSpawner:\n\t\tprint(\"Adding node %s to the spawn list. Spawner: %s\" % [object, config])\n\treturn base_multiplayer.object_configuration_add(object, config)\n\n# Log configuration remove. E.g. root path (nullptr, NodePath), replication (Node, Spawner|Synchronizer), custom.\nfunc _object_configuration_remove(object, config: Variant) -> int: # Error\n\tif config is MultiplayerSynchronizer:\n\t\tprint(\"Removing synchronization configuration for %s. Synchronizer: %s\" % [object, config])\n\telif config is MultiplayerSpawner:\n\t\tprint(\"Removing node %s from the spawn list. Spawner: %s\" % [object, config])\n\treturn base_multiplayer.object_configuration_remove(object, config)\n\n# These can be optional, but in our case we want to augment SceneMultiplayer, so forward everything.\nfunc _set_multiplayer_peer(p_peer: MultiplayerPeer):\n\tbase_multiplayer.multiplayer_peer = p_peer\n\nfunc _get_multiplayer_peer() -> MultiplayerPeer:\n\treturn base_multiplayer.multiplayer_peer\n\nfunc _get_unique_id() -> int:\n\treturn base_multiplayer.get_unique_id()\n\nfunc _get_peer_ids() -> PackedInt32Array:\n\treturn base_multiplayer.get_peers()\n</code>\n<!-- </codeblocks> -->\nThen in your main scene or in an autoload call <a href=\"../SceneTree#set_multiplayer\">SceneTree.set_multiplayer<a> to start using your custom [MultiplayerAPI](../MultiplayerAPI):\n<!-- <codeblocks> -->\n<code>\n# autoload.gd\nfunc _enter_tree():\n\t# Sets our custom multiplayer as the main one in SceneTree.\nget_tree().set_multiplayer(LogMultiplayer.new())\n</code>\n<!-- </codeblocks> -->\nNative extensions can alternatively use the <a href=\"../MultiplayerAPI#set_default_interface\">MultiplayerAPI.set_default_interface<a> method during initialization to configure themselves as the default implementation."
	},
	"MultiplayerAPI": {
		"brief_description": "High-level multiplayer API interface.",
		"description": "Base class for high-level multiplayer API implementations. See also [MultiplayerPeer](../MultiplayerPeer).\nBy default, [SceneTree](../SceneTree) has a reference to an implementation of this class and uses it to provide multiplayer capabilities (i.e. RPCs) across the whole scene.\nIt is possible to override the MultiplayerAPI instance used by specific tree branches by calling the <a href=\"../SceneTree#set_multiplayer\">SceneTree.set_multiplayer<a> method, effectively allowing to run both client and server in the same scene.\nIt is also possible to extend or replace the default implementation via scripting or native extensions. See [MultiplayerAPIExtension](../MultiplayerAPIExtension) for details about extensions, [SceneMultiplayer](../SceneMultiplayer) for the details about the default implementation."
	},
	"MultiMeshInstance3D": {
		"brief_description": "Node that instances a [MultiMesh](../MultiMesh).",
		"description": "[MultiMeshInstance3D](../MultiMeshInstance3D) is a specialized node to instance [GeometryInstance3D](../GeometryInstance3D)s based on a [MultiMesh](../MultiMesh) resource.\nThis is useful to optimize the rendering of a high number of instances of a given mesh (for example trees in a forest or grass strands)."
	},
	"MultiMeshInstance2D": {
		"brief_description": "Node that instances a [MultiMesh](../MultiMesh) in 2D.",
		"description": "[MultiMeshInstance2D](../MultiMeshInstance2D) is a specialized node to instance a [MultiMesh](../MultiMesh) resource in 2D.\nUsage is the same as [MultiMeshInstance3D](../MultiMeshInstance3D)."
	},
	"MultiMesh": {
		"brief_description": "Provides high-performance drawing of a mesh multiple times using GPU instancing.",
		"description": "MultiMesh provides low-level mesh instancing. Drawing thousands of [MeshInstance3D](../MeshInstance3D) nodes can be slow, since each object is submitted to the GPU then drawn individually.\nMultiMesh is much faster as it can draw thousands of instances with a single draw call, resulting in less API overhead.\nAs a drawback, if the instances are too far away from each other, performance may be reduced as every single instance will always render (they are spatially indexed as one, for the whole object).\nSince instances may have any behavior, the AABB used for visibility must be provided by the user.\n<b>Note:</b> A MultiMesh is a single object, therefore the same maximum lights per object restriction applies. This means, that once the maximum lights are consumed by one or more instances, the rest of the MultiMesh instances will <b>not</b> receive any lighting.\n<b>Note:</b> Blend Shapes will be ignored if used in a MultiMesh."
	},
	"MovieWriter": {
		"brief_description": "Abstract class for non-real-time video recording encoders.",
		"description": "Godot can record videos with non-real-time simulation. Like the <code>--fixed-fps</code> [command line argument]($DOCS_URL/tutorials/editor/command_line_tutorial.html), this forces the reported <code>delta</code> in <a href=\"../Node#_process\">Node._process<a> functions to be identical across frames, regardless of how long it actually took to render the frame. This can be used to record high-quality videos with perfect frame pacing regardless of your hardware's capabilities.\nGodot has 2 built-in [MovieWriter](../MovieWriter)s:\n- AVI container with MJPEG for video and uncompressed audio (<code>.avi</code> file extension). Lossy compression, medium file sizes, fast encoding. The lossy compression quality can be adjusted by changing [member ProjectSettings.editor/movie_writer/mjpeg_quality]. The resulting file can be viewed in most video players, but it must be converted to another format for viewing on the web or by Godot with [VideoStreamPlayer](../VideoStreamPlayer). MJPEG does not support transparency. AVI output is currently limited to a file of 4 GB in size at most.\n- PNG image sequence for video and WAV for audio (<code>.png</code> file extension). Lossless compression, large file sizes, slow encoding. Designed to be encoded to a video file with another tool such as [FFmpeg](https://ffmpeg.org/) after recording. Transparency is currently not supported, even if the root viewport is set to be transparent.\nIf you need to encode to a different format or pipe a stream through third-party software, you can extend the [MovieWriter](../MovieWriter) class to create your own movie writers. This should typically be done using GDExtension for performance reasons.\n<b>Editor usage:</b> A default movie file path can be specified in [member ProjectSettings.editor/movie_writer/movie_file]. Alternatively, for running single scenes, a <code>movie_path</code> metadata can be added to the root node, specifying the path to a movie file that will be used when recording that scene. Once a path is set, click the video reel icon in the top-right corner of the editor to enable Movie Maker mode, then run any scene as usual. The engine will start recording as soon as the splash screen is finished, and it will only stop recording when the engine quits. Click the video reel icon again to disable Movie Maker mode. Note that toggling Movie Maker mode does not affect project instances that are already running.\n<b>Note:</b> MovieWriter is available for use in both the editor and exported projects, but it is <i>not</i> designed for use by end users to record videos while playing. Players wishing to record gameplay videos should install tools such as [OBS Studio](https://obsproject.com/) or [SimpleScreenRecorder](https://www.maartenbaert.be/simplescreenrecorder/) instead."
	},
	"MissingResource": {
		"brief_description": "This is an internal editor class intended for keeping data of resources of unknown type.",
		"description": "This is an internal editor class intended for keeping data of resources of unknown type (most likely this type was supplied by an extension that is no longer loaded). It can't be manually instantiated or placed in the scene. Ignore it if you don't know what it is."
	},
	"MissingNode": {
		"brief_description": "This is an internal editor class intended for keeping data of nodes of unknown type.",
		"description": "This is an internal editor class intended for keeping data of nodes of unknown type (most likely this type was supplied by an extension that is no longer loaded). It can't be manually instantiated or placed in the scene. Ignore it if you don't know what it is."
	},
	"MethodTweener": {
		"brief_description": "Interpolates an abstract value and supplies it to a method called over time.",
		"description": "[MethodTweener](../MethodTweener) is similar to a combination of [CallbackTweener](../CallbackTweener) and [PropertyTweener](../PropertyTweener). It calls a method providing an interpolated value as a parameter. See <a href=\"../Tween#tween_method\">Tween.tween_method<a> for more usage information.\n<b>Note:</b> <a href=\"../Tween#tween_method\">Tween.tween_method<a> is the only correct way to create [MethodTweener](../MethodTweener). Any [MethodTweener](../MethodTweener) created manually will not function correctly."
	},
	"MeshTexture": {
		"brief_description": "Simple texture that uses a mesh to draw itself.",
		"description": "Simple texture that uses a mesh to draw itself. It's limited because flags can't be changed and region drawing is not supported."
	},
	"MeshLibrary": {
		"brief_description": "Library of meshes.",
		"description": "A library of meshes. Contains a list of [Mesh](../Mesh) resources, each with a name and ID. Each item can also include collision and navigation shapes. This resource is used in [GridMap](../GridMap)."
	},
	"MeshInstance3D": {
		"brief_description": "Node that instances meshes into a scenario.",
		"description": "MeshInstance3D is a node that takes a [Mesh](../Mesh) resource and adds it to the current scenario by creating an instance of it. This is the class most often used render 3D geometry and can be used to instance a single [Mesh](../Mesh) in many places. This allows reusing geometry, which can save on resources. When a [Mesh](../Mesh) has to be instantiated more than thousands of times at close proximity, consider using a [MultiMesh](../MultiMesh) in a [MultiMeshInstance3D](../MultiMeshInstance3D) instead."
	},
	"MeshInstance2D": {
		"brief_description": "Node used for displaying a [Mesh](../Mesh) in 2D.",
		"description": "Node used for displaying a [Mesh](../Mesh) in 2D. A [MeshInstance2D](../MeshInstance2D) can be automatically created from an existing [Sprite2D](../Sprite2D) via a tool in the editor toolbar. Select the [Sprite2D](../Sprite2D) node, then choose <b>Sprite2D > Convert to MeshInstance2D</b> at the top of the 2D editor viewport."
	},
	"MeshDataTool": {
		"brief_description": "Helper tool to access and edit [Mesh](../Mesh) data.",
		"description": "MeshDataTool provides access to individual vertices in a [Mesh](../Mesh). It allows users to read and edit vertex data of meshes. It also creates an array of faces and edges.\nTo use MeshDataTool, load a mesh with <a href=\"#create_from_surface\">create_from_surface</a>. When you are finished editing the data commit the data to a mesh with <a href=\"#commit_to_surface\">commit_to_surface</a>.\nBelow is an example of how MeshDataTool may be used.\n<!-- <codeblocks> -->\n<code>\nvar mesh = ArrayMesh.new()\nmesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, BoxMesh.new().get_mesh_arrays())\nvar mdt = MeshDataTool.new()\nmdt.create_from_surface(mesh, 0)\nfor i in range(mdt.get_vertex_count()):\n\tvar vertex = mdt.get_vertex(i)\n\t# In this example we extend the mesh by one unit, which results in separated faces as it is flat shaded.\n\tvertex += mdt.get_vertex_normal(i)\n\t# Save your change.\n\tmdt.set_vertex(i, vertex)\nmesh.surface_remove(0)\nmdt.commit_to_surface(mesh)\nvar mi = MeshInstance.new()\nmi.mesh = mesh\nadd_child(mi)\n</code>\n```csharp\nvar mesh = new ArrayMesh();\nmesh.AddSurfaceFromArrays(Mesh.PrimitiveType.Triangles, new BoxMesh().GetMeshArrays());\nvar mdt = new MeshDataTool();\nmdt.CreateFromSurface(mesh, 0);\nfor (var i = 0; i < mdt.GetVertexCount(); i++)\n{\n\tVector3 vertex = mdt.GetVertex(i);\n\t// In this example we extend the mesh by one unit, which results in separated faces as it is flat shaded.\n\tvertex += mdt.GetVertexNormal(i);\n\t// Save your change.\n\tmdt.SetVertex(i, vertex);\n}\nmesh.SurfaceRemove(0);\nmdt.CommitToSurface(mesh);\nvar mi = new MeshInstance();\nmi.Mesh = mesh;\nAddChild(mi);\n```\n<!-- </codeblocks> -->\nSee also [ArrayMesh](../ArrayMesh), [ImmediateMesh](../ImmediateMesh) and [SurfaceTool](../SurfaceTool) for procedural geometry generation.\n<b>Note:</b> Godot uses clockwise [winding order](https://learnopengl.com/Advanced-OpenGL/Face-culling) for front faces of triangle primitive modes."
	},
	"Mesh": {
		"brief_description": "A [Resource](../Resource) that contains vertex array-based geometry.",
		"description": "Mesh is a type of [Resource](../Resource) that contains vertex array-based geometry, divided in <i>surfaces</i>. Each surface contains a completely separate array and a material used to draw it. Design wise, a mesh with multiple surfaces is preferred to a single surface, because objects created in 3D editing software commonly contain multiple materials."
	},
	"MenuButton": {
		"brief_description": "Special button that brings up a [PopupMenu](../PopupMenu) when clicked.",
		"description": "Special button that brings up a [PopupMenu](../PopupMenu) when clicked.\nNew items can be created inside this [PopupMenu](../PopupMenu) using <code>get_popup().add_item(\"My Item Name\")</code>. You can also create them directly from the editor. To do so, select the [MenuButton](../MenuButton) node, then in the toolbar at the top of the 2D editor, click <b>Items</b> then click <b>Add</b> in the popup. You will be able to give each item new properties.\nSee also [BaseButton](../BaseButton) which contains common properties and methods associated with this node."
	},
	"MenuBar": {
		"brief_description": "A horizontal menu bar, which displays [PopupMenu](../PopupMenu)s or system global menu.",
		"description": "New items can be created by adding [PopupMenu](../PopupMenu) nodes to this node."
	},
	"Material": {
		"brief_description": "Abstract base [Resource](../Resource) for coloring and shading geometry.",
		"description": "Material is a base [Resource](../Resource) used for coloring and shading geometry. All materials inherit from it and almost all [VisualInstance3D](../VisualInstance3D) derived nodes carry a Material. A few flags and parameters are shared between all material types and are configured here."
	},
	"Marshalls": {
		"brief_description": "Data transformation (marshaling) and encoding helpers.",
		"description": "Provides data transformation and encoding utility functions."
	},
	"Marker3D": {
		"brief_description": "Generic 3D position hint for editing.",
		"description": "Generic 3D position hint for editing. It's just like a plain [Node3D](../Node3D), but it displays as a cross in the 3D editor at all times."
	},
	"Marker2D": {
		"brief_description": "Generic 2D position hint for editing.",
		"description": "Generic 2D position hint for editing. It's just like a plain [Node2D](../Node2D), but it displays as a cross in the 2D editor at all times. You can set cross' visual size by using the gizmo in the 2D editor while the node is selected."
	},
	"MarginContainer": {
		"brief_description": "Simple margin container.",
		"description": "Adds a top, left, bottom, and right margin to all [Control](../Control) nodes that are direct children of the container. To control the [MarginContainer](../MarginContainer)'s margin, use the <code>margin_*</code> theme properties listed below.\n<b>Note:</b> Be careful, [Control](../Control) margin values are different from the constant margin values. If you want to change the custom margin values of the [MarginContainer](../MarginContainer) by code, you should use the following examples:\n<!-- <codeblocks> -->\n<code>\n# This code sample assumes the current script is extending MarginContainer.\nvar margin_value = 100\nadd_theme_constant_override(\"margin_top\", margin_value)\nadd_theme_constant_override(\"margin_left\", margin_value)\nadd_theme_constant_override(\"margin_bottom\", margin_value)\nadd_theme_constant_override(\"margin_right\", margin_value)\n</code>\n```csharp\n// This code sample assumes the current script is extending MarginContainer.\nint marginValue = 100;\nAddThemeConstantOverride(\"margin_top\", marginValue);\nAddThemeConstantOverride(\"margin_left\", marginValue);\nAddThemeConstantOverride(\"margin_bottom\", marginValue);\nAddThemeConstantOverride(\"margin_right\", marginValue);\n```\n<!-- </codeblocks> -->"
	},
	"MainLoop": {
		"brief_description": "Abstract base class for the game's main loop.",
		"description": "[MainLoop](../MainLoop) is the abstract base class for a Godot project's game loop. It is inherited by [SceneTree](../SceneTree), which is the default game loop implementation used in Godot projects, though it is also possible to write and use one's own [MainLoop](../MainLoop) subclass instead of the scene tree.\nUpon the application start, a [MainLoop](../MainLoop) implementation must be provided to the OS; otherwise, the application will exit. This happens automatically (and a [SceneTree](../SceneTree) is created) unless a [MainLoop](../MainLoop) [Script](../Script) is provided from the command line (with e.g. <code>godot -s my_loop.gd</code> or the \"Main Loop Type\" project setting is overwritten.\nHere is an example script implementing a simple [MainLoop](../MainLoop):\n<!-- <codeblocks> -->\n<code>\nclass_name CustomMainLoop\nextends MainLoop\n\nvar time_elapsed = 0\n\nfunc _initialize():\n\tprint(\"Initialized:\")\n\tprint(\"  Starting time: %s\" % str(time_elapsed))\n\nfunc _process(delta):\n\ttime_elapsed += delta\n\t# Return true to end the main loop.\n\treturn Input.get_mouse_button_mask() != 0 || Input.is_key_pressed(KEY_ESCAPE)\n\nfunc _finalize():\n\tprint(\"Finalized:\")\n\tprint(\"  End time: %s\" % str(time_elapsed))\n</code>\n```csharp\nusing Godot;\n\npublic partial class CustomMainLoop : MainLoop\n{\n\tprivate double _timeElapsed = 0;\n\n\tpublic override void _Initialize()\n\t{\n\t\tGD.Print(\"Initialized:\");\n\t\tGD.Print($\"  Starting Time: {_timeElapsed}\");\n\t}\n\n\tpublic override bool _Process(double delta)\n\t{\n\t\t_timeElapsed += delta;\n\t\t// Return true to end the main loop.\n\t\treturn Input.GetMouseButtonMask() != 0 || Input.IsKeyPressed(Key.Escape);\n\t}\n\n\tprivate void _Finalize()\n\t{\n\t\tGD.Print(\"Finalized:\");\n\t\tGD.Print($\"  End Time: {_timeElapsed}\");\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"LinkButton": {
		"brief_description": "Simple button used to represent a link to some resource.",
		"description": "This kind of button is primarily used when the interaction with the button causes a context change (like linking to a web page).\nSee also [BaseButton](../BaseButton) which contains common properties and methods associated with this node."
	},
	"LineEdit": {
		"brief_description": "Control that provides single-line string editing.",
		"description": "LineEdit provides a single-line string editor, used for text fields.\nIt features many built-in shortcuts which will always be available (<kbd>Ctrl</kbd> here maps to <kbd>Cmd</kbd> on macOS):\n- <kbd>Ctrl + C</kbd>: Copy\n- <kbd>Ctrl + X</kbd>: Cut\n- <kbd>Ctrl + V</kbd> or <kbd>Ctrl + Y</kbd>: Paste/\"yank\"\n- <kbd>Ctrl + Z</kbd>: Undo\n- <kbd>Ctrl + ~</kbd>: Swap input direction.\n- <kbd>Ctrl + Shift + Z</kbd>: Redo\n- <kbd>Ctrl + U</kbd>: Delete text from the caret position to the beginning of the line\n- <kbd>Ctrl + K</kbd>: Delete text from the caret position to the end of the line\n- <kbd>Ctrl + A</kbd>: Select all text\n- <kbd>Up Arrow</kbd>/<kbd>Down Arrow</kbd>: Move the caret to the beginning/end of the line\nOn macOS, some extra keyboard shortcuts are available:\n- <kbd>Ctrl + F</kbd>: Same as <kbd>Right Arrow</kbd>, move the caret one character right\n- <kbd>Ctrl + B</kbd>: Same as <kbd>Left Arrow</kbd>, move the caret one character left\n- <kbd>Ctrl + P</kbd>: Same as <kbd>Up Arrow</kbd>, move the caret to the previous line\n- <kbd>Ctrl + N</kbd>: Same as <kbd>Down Arrow</kbd>, move the caret to the next line\n- <kbd>Ctrl + D</kbd>: Same as <kbd>Delete</kbd>, delete the character on the right side of caret\n- <kbd>Ctrl + H</kbd>: Same as <kbd>Backspace</kbd>, delete the character on the left side of the caret\n- <kbd>Ctrl + A</kbd>: Same as <kbd>Home</kbd>, move the caret to the beginning of the line\n- <kbd>Ctrl + E</kbd>: Same as <kbd>End</kbd>, move the caret to the end of the line\n- <kbd>Cmd + Left Arrow</kbd>: Same as <kbd>Home</kbd>, move the caret to the beginning of the line\n- <kbd>Cmd + Right Arrow</kbd>: Same as <kbd>End</kbd>, move the caret to the end of the line"
	},
	"Line2D": {
		"brief_description": "A 2D line.",
		"description": "A line through several points in 2D space."
	},
	"LightOccluder2D": {
		"brief_description": "Occludes light cast by a Light2D, casting shadows.",
		"description": "Occludes light cast by a Light2D, casting shadows. The LightOccluder2D must be provided with an [OccluderPolygon2D](../OccluderPolygon2D) in order for the shadow to be computed."
	},
	"LightmapProbe": {
		"brief_description": "Represents a single manually placed probe for dynamic object lighting with [LightmapGI](../LightmapGI).",
		"description": "[LightmapProbe](../LightmapProbe) represents the position of a single manually placed probe for dynamic object lighting with [LightmapGI](../LightmapGI).\nTypically, [LightmapGI](../LightmapGI) probes are placed automatically by setting <a href=\"../LightmapGI#generate_probes_subdiv\">LightmapGI.generate_probes_subdiv<a> to a value other than <a href=\"../LightmapGI#GENERATE_PROBES_DISABLED\">LightmapGI.GENERATE_PROBES_DISABLED<a>. By creating [LightmapProbe](../LightmapProbe) nodes before baking lightmaps, you can add more probes in specific areas for greater detail, or disable automatic generation and rely only on manually placed probes instead."
	},
	"LightmapperRD": {
		"brief_description": "The built-in GPU-based lightmapper for use with [LightmapGI](../LightmapGI).",
		"description": "LightmapperRD (\"RD\" stands for [RenderingDevice](../RenderingDevice)) is the built-in GPU-based lightmapper for use with [LightmapGI](../LightmapGI). On most dedicated GPUs, it can bake lightmaps much faster than most CPU-based lightmappers. LightmapperRD uses compute shaders to bake lightmaps, so it does not require CUDA or OpenCL libraries to be installed to be usable.\n<b>Note:</b> Only usable when using the Vulkan backend (Forward+ or Mobile), not OpenGL."
	},
	"Lightmapper": {
		"brief_description": "Abstract class extended by lightmappers, for use in [LightmapGI](../LightmapGI).",
		"description": "This class should be extended by custom lightmapper classes. Lightmappers can then be used with [LightmapGI](../LightmapGI) to provide fast baked global illumination in 3D.\nGodot contains a built-in GPU-based lightmapper [LightmapperRD](../LightmapperRD) that uses compute shaders, but custom lightmappers can be implemented by C++ modules."
	},
	"LightmapGIData": {
		"brief_description": "Contains baked lightmap and dynamic object probe data for [LightmapGI](../LightmapGI).",
		"description": "[LightmapGIData](../LightmapGIData) contains baked lightmap and dynamic object probe data for [LightmapGI](../LightmapGI). It is replaced every time lightmaps are baked in [LightmapGI](../LightmapGI)."
	},
	"LightmapGI": {
		"brief_description": "Computes and stores baked lightmaps for fast global illumination.",
		"description": "The [LightmapGI](../LightmapGI) node is used to compute and store baked lightmaps. Lightmaps are used to provide high-quality indirect lighting with very little light leaking. [LightmapGI](../LightmapGI) can also provide rough reflections using spherical harmonics if <a href=\"#directional\">directional</a> is enabled. Dynamic objects can receive indirect lighting thanks to <i>light probes</i>, which can be automatically placed by setting <a href=\"#generate_probes_subdiv\">generate_probes_subdiv</a> to a value other than <a href=\"#GENERATE_PROBES_DISABLED\">GENERATE_PROBES_DISABLED</a>. Additional lightmap probes can also be added by creating [LightmapProbe](../LightmapProbe) nodes. The downside is that lightmaps are fully static and cannot be baked in an exported project. Baking a [LightmapGI](../LightmapGI) node is also slower compared to [VoxelGI](../VoxelGI).\n<b>Procedural generation:</b> Lightmap baking functionality is only available in the editor. This means [LightmapGI](../LightmapGI) is not suited to procedurally generated or user-built levels. For procedurally generated or user-built levels, use [VoxelGI](../VoxelGI) or SDFGI instead (see <a href=\"../Environment#sdfgi_enabled\">Environment.sdfgi_enabled<a>).\n<b>Performance:</b> [LightmapGI](../LightmapGI) provides the best possible run-time performance for global illumination. It is suitable for low-end hardware including integrated graphics and mobile devices.\n<b>Note:</b> Due to how lightmaps work, most properties only have a visible effect once lightmaps are baked again.\n<b>Note:</b> Lightmap baking on [CSGShape3D](../CSGShape3D)s and [PrimitiveMesh](../PrimitiveMesh)es is not supported, as these cannot store UV2 data required for baking.\n<b>Note:</b> If no custom lightmappers are installed, [LightmapGI](../LightmapGI) can only be baked when using the Vulkan backend (Forward+ or Mobile), not OpenGL."
	},
	"Light3D": {
		"brief_description": "Provides a base class for different kinds of light nodes.",
		"description": "Light3D is the <i>abstract</i> base class for light nodes. As it can't be instantiated, it shouldn't be used directly. Other types of light nodes inherit from it. Light3D contains the common variables and parameters used for lighting."
	},
	"Light2D": {
		"brief_description": "Casts light in a 2D environment.",
		"description": "Casts light in a 2D environment. A light is defined as a color, an energy value, a mode (see constants), and various other parameters (range and shadows-related)."
	},
	"LabelSettings": {
		"brief_description": "Collection of common settings to customize label text.",
		"description": "[LabelSettings](../LabelSettings) is a resource that can be assigned to a [Label](../Label) node to customize it. It will take priority over the properties defined in theme. The resource can be shared between multiple labels and swapped on the fly, so it's convenient and flexible way to setup text style."
	},
	"Label3D": {
		"brief_description": "Displays plain text in a 3D world.",
		"description": "Label3D displays plain text in a 3D world. It gives you control over the horizontal and vertical alignment."
	},
	"Label": {
		"brief_description": "Displays plain text in a line or wrapped inside a rectangle. For formatted text, use [RichTextLabel](../RichTextLabel).",
		"description": "Label displays plain text on the screen. It gives you control over the horizontal and vertical alignment and can wrap the text inside the node's bounding rectangle. It doesn't support bold, italics, or other formatting. For that, use [RichTextLabel](../RichTextLabel) instead.\n<b>Note:</b> Contrarily to most other [Control](../Control)s, Label's <a href=\"../Control#mouse_filter\">Control.mouse_filter<a> defaults to <a href=\"../Control#MOUSE_FILTER_IGNORE\">Control.MOUSE_FILTER_IGNORE<a> (i.e. it doesn't react to mouse input events). This implies that a label won't display any configured <a href=\"../Control#tooltip_text\">Control.tooltip_text<a>, unless you change its mouse filter."
	},
	"KinematicCollision3D": {
		"brief_description": "Collision data for <a href=\"../PhysicsBody3D#move_and_collide\">PhysicsBody3D.move_and_collide<a> collisions.",
		"description": "Contains collision data for <a href=\"../PhysicsBody3D#move_and_collide\">PhysicsBody3D.move_and_collide<a> collisions. When a [PhysicsBody3D](../PhysicsBody3D) is moved using <a href=\"../PhysicsBody3D#move_and_collide\">PhysicsBody3D.move_and_collide<a>, it stops if it detects a collision with another body. If a collision is detected, a [KinematicCollision3D](../KinematicCollision3D) object is returned.\nThis object contains information about the collision, including the colliding object, the remaining motion, and the collision position. This information can be used to calculate a collision response."
	},
	"KinematicCollision2D": {
		"brief_description": "Collision data for <a href=\"../PhysicsBody2D#move_and_collide\">PhysicsBody2D.move_and_collide<a> collisions.",
		"description": "Contains collision data for <a href=\"../PhysicsBody2D#move_and_collide\">PhysicsBody2D.move_and_collide<a> collisions. When a [PhysicsBody2D](../PhysicsBody2D) is moved using <a href=\"../PhysicsBody2D#move_and_collide\">PhysicsBody2D.move_and_collide<a>, it stops if it detects a collision with another body. If a collision is detected, a [KinematicCollision2D](../KinematicCollision2D) object is returned.\nThis object contains information about the collision, including the colliding object, the remaining motion, and the collision position. This information can be used to calculate a collision response."
	},
	"JSONRPC": {
		"brief_description": "A helper to handle dictionaries which look like JSONRPC documents.",
		"description": "[JSON-RPC](https://www.jsonrpc.org/) is a standard which wraps a method call in a [JSON](../JSON) object. The object has a particular structure and identifies which method is called, the parameters to that function, and carries an ID to keep track of responses. This class implements that standard on top of [Dictionary](../Dictionary); you will have to convert between a [Dictionary](../Dictionary) and [JSON](../JSON) with other functions."
	},
	"JSON": {
		"brief_description": "Helper class for creating and parsing JSON data.",
		"description": "The [JSON](../JSON) enables all data types to be converted to and from a JSON string. This useful for serializing data to save to a file or send over the network.\n<a href=\"#stringify\">stringify</a> is used to convert any data type into a JSON string.\n<a href=\"#parse\">parse</a> is used to convert any existing JSON data into a [Variant](../Variant) that can be used within Godot. If successfully parsed, use <a href=\"#data\">data</a> to retrieve the [Variant](../Variant), and use <code>typeof</code> to check if the Variant's type is what you expect. JSON Objects are converted into a [Dictionary](../Dictionary), but JSON data can be used to store [Array](../Array)s, numbers, [String](../String)s and even just a boolean.\n<b>Example</b>\n<code>\nvar data_to_send = [\"a\", \"b\", \"c\"]\nvar json_string = JSON.stringify(data_to_send)\n# Save data\n# ...\n# Retrieve data\nvar error = json.parse(json_string)\nif error == OK:\n\tvar data_received = json.data\n\tif typeof(data_received) == TYPE_ARRAY:\n\t\tprint(data_received) # Prints array\n\telse:\n\t\tprint(\"Unexpected data\")\nelse:\n\tprint(\"JSON Parse Error: \", json.get_error_message(), \" in \", json_string, \" at line \", json.get_error_line())\n</code>\nAlternatively, you can parse string using the static <a href=\"#parse_string\">parse_string</a> method, but it doesn't allow to handle errors.\n<code>\nvar data = JSON.parse_string(json_string) # Returns null if parsing failed.\n</code>\n<b>Note:</b> Both parse methods do not fully comply with the JSON specification:\n- Trailing commas in arrays or objects are ignored, instead of causing a parser error.\n- New line and tab characters are accepted in string literals, and are treated like their corresponding escape sequences <code>\\n</code> and <code>\\t</code>.\n- Numbers are parsed using <a href=\"../String#to_float\">String.to_float<a> which is generally more lax than the JSON specification.\n- Certain errors, such as invalid Unicode sequences, do not cause a parser error. Instead, the string is cleansed and an error is logged to the console."
	},
	"Joint3D": {
		"brief_description": "Base class for all 3D joints.",
		"description": "Joints are used to bind together two physics bodies. They have a solver priority and can define if the bodies of the two attached nodes should be able to collide with each other. See also [Generic6DOFJoint3D](../Generic6DOFJoint3D)."
	},
	"Joint2D": {
		"brief_description": "Base node for all joint constraints in 2D physics.",
		"description": "Base node for all joint constraints in 2D physics. Joints take 2 bodies and apply a custom constraint."
	},
	"JNISingleton": {
		"brief_description": "Singleton that connects the engine with Android plugins to interface with native Android code.",
		"description": "The JNISingleton is implemented only in the Android export. It's used to call methods and connect signals from an Android plugin written in Java or Kotlin. Methods and signals can be called and connected to the JNISingleton as if it is a Node. See [Java Native Interface - Wikipedia](https://en.wikipedia.org/wiki/Java_Native_Interface) for more information."
	},
	"JavaScriptObject": {
		"brief_description": "A wrapper class for web native JavaScript objects.",
		"description": "JavaScriptObject is used to interact with JavaScript objects retrieved or created via <a href=\"../JavaScriptBridge#get_interface\">JavaScriptBridge.get_interface<a>, <a href=\"../JavaScriptBridge#create_object\">JavaScriptBridge.create_object<a>, or <a href=\"../JavaScriptBridge#create_callback\">JavaScriptBridge.create_callback<a>.\n<b>Example:</b>\n<code>\nextends Node\n\nvar _my_js_callback = JavaScriptBridge.create_callback(self, \"myCallback\") # This reference must be kept\nvar console = JavaScriptBridge.get_interface(\"console\")\n\nfunc _init():\n\tvar buf = JavaScriptBridge.create_object(\"ArrayBuffer\", 10) # new ArrayBuffer(10)\n\tprint(buf) # prints [JavaScriptObject:OBJECT_ID]\n\tvar uint8arr = JavaScriptBridge.create_object(\"Uint8Array\", buf) # new Uint8Array(buf)\n\tuint8arr[1](../1) = 255\n\tprints(uint8arr[1](../1), uint8arr.byteLength) # prints 255 10\n\tconsole.log(uint8arr) # prints in browser console \"Uint8Array(10) [ 0, 255, 0, 0, 0, 0, 0, 0, 0, 0 ]\"\n\n\t# Equivalent of JavaScriptBridge: Array.from(uint8arr).forEach(myCallback)\n\tJavaScriptBridge.get_interface(\"Array\").from(uint8arr).forEach(_my_js_callback)\n\nfunc myCallback(args):\n\t# Will be called with the parameters passed to the \"forEach\" callback\n\t# [0, 0, [JavaScriptObject:1173]]\n\t# [255, 1, [JavaScriptObject:1173]]\n\t# ...\n\t# [0, 9, [JavaScriptObject:1180]]\n\tprint(args)\n</code>\n<b>Note:</b> Only available in the Web platform."
	},
	"JavaScriptBridge": {
		"brief_description": "Singleton that connects the engine with the browser's JavaScript context in Web export.",
		"description": "The JavaScriptBridge singleton is implemented only in the Web export. It's used to access the browser's JavaScript context. This allows interaction with embedding pages or calling third-party JavaScript APIs.\n<b>Note:</b> This singleton can be disabled at build-time to improve security. By default, the JavaScriptBridge singleton is enabled. Official export templates also have the JavaScriptBridge singleton enabled. See [Compiling for the Web]($DOCS_URL/contributing/development/compiling/compiling_for_web.html) in the documentation for more information."
	},
	"JavaClassWrapper": {
		"brief_description": "",
		"description": ""
	},
	"JavaClass": {
		"brief_description": "",
		"description": ""
	},
	"ItemList": {
		"brief_description": "Control that provides a list of selectable items (and/or icons) in a single column, or optionally in multiple columns.",
		"description": "This control provides a selectable list of items that may be in a single (or multiple columns) with option of text, icons, or both text and icon. Tooltips are supported and may be different for every item in the list.\nSelectable items in the list may be selected or deselected and multiple selection may be enabled. Selection with right mouse button may also be enabled to allow use of popup context menus. Items may also be \"activated\" by double-clicking them or by pressing <kbd>Enter</kbd>.\nItem text only supports single-line strings, newline characters (e.g. <code>\\n</code>) in the string won't produce a newline. Text wrapping is enabled in <a href=\"#ICON_MODE_TOP\">ICON_MODE_TOP</a> mode, but column's width is adjusted to fully fit its content by default. You need to set <a href=\"#fixed_column_width\">fixed_column_width</a> greater than zero to wrap the text.\nAll <code>set_*</code> methods allow negative item index, which makes the item accessed from the last one.\n<b>Incremental search:</b> Like [PopupMenu](../PopupMenu) and [Tree](../Tree), [ItemList](../ItemList) supports searching within the list while the control is focused. Press a key that matches the first letter of an item's name to select the first item starting with the given letter. After that point, there are two ways to perform incremental search: 1) Press the same key again before the timeout duration to select the next item starting with the same letter. 2) Press letter keys that match the rest of the word before the timeout duration to match to select the item in question directly. Both of these actions will be reset to the beginning of the list if the timeout duration has passed since the last keystroke was registered. You can adjust the timeout duration by changing [member ProjectSettings.gui/timers/incremental_search_max_interval_msec]."
	},
	"IP": {
		"brief_description": "Internet protocol (IP) support functions such as DNS resolution.",
		"description": "IP contains support functions for the Internet Protocol (IP). TCP/IP support is in different classes (see [StreamPeerTCP](../StreamPeerTCP) and [TCPServer](../TCPServer)). IP provides DNS hostname resolution support, both blocking and threaded."
	},
	"IntervalTweener": {
		"brief_description": "Creates an idle interval in a [Tween](../Tween) animation.",
		"description": "[IntervalTweener](../IntervalTweener) is used to make delays in a tweening sequence. See <a href=\"../Tween#tween_interval\">Tween.tween_interval<a> for more usage information.\n<b>Note:</b> <a href=\"../Tween#tween_interval\">Tween.tween_interval<a> is the only correct way to create [IntervalTweener](../IntervalTweener). Any [IntervalTweener](../IntervalTweener) created manually will not function correctly."
	},
	"int": {
		"brief_description": "Integer built-in type.",
		"description": "Signed 64-bit integer type.\nIt can take values in the interval <code>[-2^63, 2^63 - 1]</code>, i.e. <code>[-9223372036854775808, 9223372036854775807]</code>. Exceeding those bounds will wrap around.\n[int](../int) is a [Variant](../Variant) type, and will thus be used when assigning an integer value to a [Variant](../Variant). It can also be enforced with the <code>: int</code> type hint.\n<!-- <codeblocks> -->\n<code>\nvar my_variant = 0 # int, value 0.\nmy_variant += 4.2 # float, value 4.2.\nvar my_int: int = 1 # int, value 1.\nmy_int = 4.2 # int, value 4, the right value is implicitly cast to int.\nmy_int = int(\"6.7\") # int, value 6, the String is explicitly cast with int.\nvar max_int = 9223372036854775807\nprint(max_int) # 9223372036854775807, OK.\nmax_int += 1\nprint(max_int) # -9223372036854775808, we overflowed and wrapped around.\n</code>\n```csharp\nint myInt = (int)\"6.7\".ToFloat(); // int, value 6, the String is explicitly cast with int.\n// We have to use `long` here, because GDSript's `int`\n// is 64 bits long while C#'s `int` is only 32 bits.\nlong maxInt = 9223372036854775807;\nGD.Print(maxInt); // 9223372036854775807, OK.\nmaxInt++;\nGD.Print(maxInt); // -9223372036854775808, we overflowed and wrapped around.\n\n// Alternatively, if we used C#'s 32-bit `int` type, the maximum value is much smaller:\nint halfInt = 2147483647;\nGD.Print(halfInt); // 2147483647, OK.\nhalfInt++;\nGD.Print(halfInt); // -2147483648, we overflowed and wrapped around.\n```\n<!-- </codeblocks> -->"
	},
	"InstancePlaceholder": {
		"brief_description": "Placeholder for the root [Node](../Node) of a [PackedScene](../PackedScene).",
		"description": "Turning on the option <b>Load As Placeholder</b> for an instantiated scene in the editor causes it to be replaced by an [InstancePlaceholder](../InstancePlaceholder) when running the game, this will not replace the node in the editor. This makes it possible to delay actually loading the scene until calling <a href=\"#create_instance\">create_instance</a>. This is useful to avoid loading large scenes all at once by loading parts of it selectively.\nThe [InstancePlaceholder](../InstancePlaceholder) does not have a transform. This causes any child nodes to be positioned relatively to the [Viewport](../Viewport) from point (0,0), rather than their parent as displayed in the editor. Replacing the placeholder with a scene with a transform will transform children relatively to their parent again."
	},
	"InputMap": {
		"brief_description": "Singleton that manages [InputEventAction](../InputEventAction).",
		"description": "Manages all [InputEventAction](../InputEventAction) which can be created/modified from the project settings menu <b>Project > Project Settings > Input Map</b> or in code with <a href=\"#add_action\">add_action</a> and <a href=\"#action_add_event\">action_add_event</a>. See <a href=\"../Node#_input\">Node._input<a>."
	},
	"InputEventWithModifiers": {
		"brief_description": "Base class for keys events with modifiers.",
		"description": "Contains keys events information with modifiers support like <kbd>Shift</kbd> or <kbd>Alt</kbd>. See <a href=\"../Node#_input\">Node._input<a>."
	},
	"InputEventShortcut": {
		"brief_description": "",
		"description": ""
	},
	"InputEventScreenTouch": {
		"brief_description": "Input event type for screen touch events.\n(only available on mobile devices)",
		"description": "Stores multi-touch press/release information. Supports touch press, touch release and <a href=\"#index\">index</a> for multi-touch count and order."
	},
	"InputEventScreenDrag": {
		"brief_description": "Input event type for screen drag events. Only available on mobile devices.",
		"description": "Contains screen drag information. See <a href=\"../Node#_input\">Node._input<a>."
	},
	"InputEventPanGesture": {
		"brief_description": "",
		"description": ""
	},
	"InputEventMouseMotion": {
		"brief_description": "Input event type for mouse motion events.",
		"description": "Contains mouse and pen motion information. Supports relative, absolute positions and velocity. See <a href=\"../Node#_input\">Node._input<a>.\n<b>Note:</b> By default, this event is only emitted once per frame rendered at most. If you need more precise input reporting, set <a href=\"../Input#use_accumulated_input\">Input.use_accumulated_input<a> to <code>false</code> to make events emitted as often as possible. If you use InputEventMouseMotion to draw lines, consider implementing [Bresenham's line algorithm](https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm) as well to avoid visible gaps in lines if the user is moving the mouse quickly."
	},
	"InputEventMouseButton": {
		"brief_description": "Input event type for mouse button events.",
		"description": "Contains mouse click information. See <a href=\"../Node#_input\">Node._input<a>."
	},
	"InputEventMouse": {
		"brief_description": "Base input event type for mouse events.",
		"description": "Stores general mouse events information."
	},
	"InputEventMIDI": {
		"brief_description": "Input event for MIDI inputs.",
		"description": "InputEventMIDI allows receiving input events from MIDI devices such as a piano. MIDI stands for Musical Instrument Digital Interface.\nMIDI signals can be sent over a 5-pin MIDI connector or over USB, if your device supports both be sure to check the settings in the device to see which output it's using.\nTo receive input events from MIDI devices, you need to call <a href=\"../OS#open_midi_inputs\">OS.open_midi_inputs<a>. You can check which devices are detected using <a href=\"../OS#get_connected_midi_inputs\">OS.get_connected_midi_inputs<a>.\n<!-- <codeblocks> -->\n<code>\nfunc _ready():\n\tOS.open_midi_inputs()\n\tprint(OS.get_connected_midi_inputs())\n\nfunc _input(input_event):\n\tif input_event is InputEventMIDI:\n\t\t_print_midi_info(input_event)\n\nfunc _print_midi_info(midi_event: InputEventMIDI):\n\tprint(midi_event)\n\tprint(\"Channel \" + str(midi_event.channel))\n\tprint(\"Message \" + str(midi_event.message))\n\tprint(\"Pitch \" + str(midi_event.pitch))\n\tprint(\"Velocity \" + str(midi_event.velocity))\n\tprint(\"Instrument \" + str(midi_event.instrument))\n\tprint(\"Pressure \" + str(midi_event.pressure))\n\tprint(\"Controller number: \" + str(midi_event.controller_number))\n\tprint(\"Controller value: \" + str(midi_event.controller_value))\n</code>\n```csharp\npublic override void _Ready()\n{\n\tOS.OpenMidiInputs();\n\tGD.Print(OS.GetConnectedMidiInputs());\n}\n\npublic override void _Input(InputEvent @event)\n{\n\tif (@event is InputEventMIDI midiEvent)\n\t{\n\t\tPrintMIDIInfo(midiEvent);\n\t}\n}\n\nprivate void PrintMIDIInfo(InputEventMIDI midiEvent)\n{\n\tGD.Print(midiEvent);\n\tGD.Print($\"Channel {midiEvent.Channel}\");\n\tGD.Print($\"Message {midiEvent.Message}\");\n\tGD.Print($\"Pitch {midiEvent.Pitch}\");\n\tGD.Print($\"Velocity {midiEvent.Velocity}\");\n\tGD.Print($\"Instrument {midiEvent.Instrument}\");\n\tGD.Print($\"Pressure {midiEvent.Pressure}\");\n\tGD.Print($\"Controller number: {midiEvent.ControllerNumber}\");\n\tGD.Print($\"Controller value: {midiEvent.ControllerValue}\");\n}\n```\n<!-- </codeblocks> -->\nNote that Godot does not currently support MIDI output, so there is no way to emit MIDI signals from Godot. Only MIDI input works."
	},
	"InputEventMagnifyGesture": {
		"brief_description": "",
		"description": ""
	},
	"InputEventKey": {
		"brief_description": "Input event type for keyboard events.",
		"description": "Stores key presses on the keyboard. Supports key presses, key releases and <a href=\"#echo\">echo</a> events.\n<b>Note:</b> Events received from the keyboard usually have all properties set. Event mappings should have only one of the <a href=\"#keycode\">keycode</a>, <a href=\"#physical_keycode\">physical_keycode</a> or <a href=\"#unicode\">unicode</a> set.\nWhen events are compared, properties are checked in the following priority - <a href=\"#keycode\">keycode</a>, <a href=\"#physical_keycode\">physical_keycode</a> and <a href=\"#unicode\">unicode</a>, events with the first matching value will be considered equal."
	},
	"InputEventJoypadMotion": {
		"brief_description": "Input event type for gamepad joysticks and other motions. For buttons, see <code>InputEventJoypadButton</code>.",
		"description": "Stores information about joystick motions. One [InputEventJoypadMotion](../InputEventJoypadMotion) represents one axis at a time."
	},
	"InputEventJoypadButton": {
		"brief_description": "Input event for gamepad buttons.",
		"description": "Input event type for gamepad buttons. For gamepad analog sticks and joysticks, see [InputEventJoypadMotion](../InputEventJoypadMotion)."
	},
	"InputEventGesture": {
		"brief_description": "Base class for touch control gestures.",
		"description": ""
	},
	"InputEventFromWindow": {
		"brief_description": "",
		"description": ""
	},
	"InputEventAction": {
		"brief_description": "Input event type for actions.",
		"description": "Contains a generic action which can be targeted from several types of inputs. Actions can be created from the <b>Input Map</b> tab in the <b>Project > Project Settings</b> menu. See <a href=\"../Node#_input\">Node._input<a>.\n<b>Note:</b> Unlike the other [InputEvent](../InputEvent) subclasses which map to unique physical events, this virtual one is not emitted by the engine. This class is useful to emit actions manually with <a href=\"../Input#parse_input_event\">Input.parse_input_event<a>, which are then received in <a href=\"../Node#_input\">Node._input<a>. To check if a physical event matches an action from the Input Map, use <a href=\"../InputEvent#is_action\">InputEvent.is_action<a> and <a href=\"../InputEvent#is_action_pressed\">InputEvent.is_action_pressed<a>."
	},
	"InputEvent": {
		"brief_description": "Generic input event.",
		"description": "Base class of all sort of input event. See <a href=\"../Node#_input\">Node._input<a>."
	},
	"Input": {
		"brief_description": "A singleton that deals with inputs.",
		"description": "A singleton that deals with inputs. This includes key presses, mouse buttons and movement, joypads, and input actions. Actions and their events can be set in the <b>Input Map</b> tab in the <b>Project > Project Settings</b>, or with the [InputMap](../InputMap) class."
	},
	"ImporterMeshInstance3D": {
		"brief_description": "",
		"description": ""
	},
	"ImporterMesh": {
		"brief_description": "A [Resource](../Resource) that contains vertex array-based geometry during the import process.",
		"description": "ImporterMesh is a type of [Resource](../Resource) analogous to [ArrayMesh](../ArrayMesh). It contains vertex array-based geometry, divided in <i>surfaces</i>. Each surface contains a completely separate array and a material used to draw it. Design wise, a mesh with multiple surfaces is preferred to a single surface, because objects created in 3D editing software commonly contain multiple materials.\nUnlike its runtime counterpart, [ImporterMesh](../ImporterMesh) contains mesh data before various import steps, such as lod and shadow mesh generation, have taken place. Modify surface data by calling <a href=\"#clear\">clear</a>, followed by <a href=\"#add_surface\">add_surface</a> for each surface."
	},
	"ImmediateMesh": {
		"brief_description": "Mesh optimized for creating geometry manually.",
		"description": "Mesh optimized for creating geometry manually, similar to OpenGL1.x immediate mode."
	},
	"ImageTextureLayered": {
		"brief_description": "Base class for texture types which contain the data of multiple [ImageTexture](../ImageTexture)s. Each image is of the same size and format.",
		"description": "Base class for [Texture2DArray](../Texture2DArray), [Cubemap](../Cubemap) and [CubemapArray](../CubemapArray). Cannot be used directly, but contains all the functions necessary for accessing the derived resource types. See also [Texture3D](../Texture3D)."
	},
	"ImageTexture3D": {
		"brief_description": "Texture with 3 dimensions.",
		"description": "[ImageTexture3D](../ImageTexture3D) is a 3-dimensional [ImageTexture](../ImageTexture) that has a width, height, and depth. See also [ImageTextureLayered](../ImageTextureLayered).\n3D textures are typically used to store density maps for [FogMaterial](../FogMaterial), color correction LUTs for [Environment](../Environment), vector fields for [GPUParticlesAttractorVectorField3D](../GPUParticlesAttractorVectorField3D) and collision maps for [GPUParticlesCollisionSDF3D](../GPUParticlesCollisionSDF3D). 3D textures can also be used in custom shaders."
	},
	"ImageTexture": {
		"brief_description": "A [Texture2D](../Texture2D) based on an [Image](../Image).",
		"description": "A [Texture2D](../Texture2D) based on an [Image](../Image). For an image to be displayed, an [ImageTexture](../ImageTexture) has to be created from it using the <a href=\"#create_from_image\">create_from_image</a> method:\n<code>\nvar image = Image.load_from_file(\"res://icon.svg\")\nvar texture = ImageTexture.create_from_image(image)\n$Sprite2D.texture = texture\n</code>\nThis way, textures can be created at run-time by loading images both from within the editor and externally.\n<b>Warning:</b> Prefer to load imported textures with [method @GDScript.load] over loading them from within the filesystem dynamically with <a href=\"../Image#load\">Image.load<a>, as it may not work in exported projects:\n<code>\nvar texture = load(\"res://icon.svg\")\n$Sprite2D.texture = texture\n</code>\nThis is because images have to be imported as a [CompressedTexture2D](../CompressedTexture2D) first to be loaded with [method @GDScript.load]. If you'd still like to load an image file just like any other [Resource](../Resource), import it as an [Image](../Image) resource instead, and then load it normally using the [method @GDScript.load] method.\n<b>Note:</b> The image can be retrieved from an imported texture using the <a href=\"../Texture2D#get_image\">Texture2D.get_image<a> method, which returns a copy of the image:\n<code>\nvar texture = load(\"res://icon.svg\")\nvar image: Image = texture.get_image()\n</code>\nAn [ImageTexture](../ImageTexture) is not meant to be operated from within the editor interface directly, and is mostly useful for rendering images on screen dynamically via code. If you need to generate images procedurally from within the editor, consider saving and importing images as custom texture resources implementing a new [EditorImportPlugin](../EditorImportPlugin).\n<b>Note:</b> The maximum texture size is 1638416384 pixels due to graphics hardware limitations."
	},
	"ImageFormatLoaderExtension": {
		"brief_description": "Base class for creating [ImageFormatLoader](../ImageFormatLoader) extensions (adding support for extra image formats).",
		"description": "The engine supports multiple image formats out of the box (PNG, SVG, JPEG, WebP to name a few), but you can choose to implement support for additional image formats by extending this class.\nBe sure to respect the documented return types and values. You should create an instance of it, and call <a href=\"#add_format_loader\">add_format_loader</a> to register that loader during the initialization phase."
	},
	"ImageFormatLoader": {
		"brief_description": "Base class to add support for specific image formats.",
		"description": "The engine supports multiple image formats out of the box (PNG, SVG, JPEG, WebP to name a few), but you can choose to implement support for additional image formats by extending [ImageFormatLoaderExtension](../ImageFormatLoaderExtension)."
	},
	"Image": {
		"brief_description": "Image datatype.",
		"description": "Native image datatype. Contains image data which can be converted to an [ImageTexture](../ImageTexture) and provides commonly used <i>image processing</i> methods. The maximum width and height for an [Image](../Image) are <a href=\"#MAX_WIDTH\">MAX_WIDTH</a> and <a href=\"#MAX_HEIGHT\">MAX_HEIGHT</a>.\nAn [Image](../Image) cannot be assigned to a <code>texture</code> property of an object directly (such as [Sprite2D](../Sprite2D)), and has to be converted manually to an [ImageTexture](../ImageTexture) first.\n<b>Note:</b> The maximum image size is 1638416384 pixels due to graphics hardware limitations. Larger images may fail to import."
	},
	"HTTPRequest": {
		"brief_description": "A node with the ability to send HTTP(S) requests.",
		"description": "A node with the ability to send HTTP requests. Uses [HTTPClient](../HTTPClient) internally.\nCan be used to make HTTP requests, i.e. download or upload files or web content via HTTP.\n<b>Warning:</b> See the notes and warnings on [HTTPClient](../HTTPClient) for limitations, especially regarding TLS security.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android.\n<b>Example of contacting a REST API and printing one of its returned fields:</b>\n<!-- <codeblocks> -->\n<code>\nfunc _ready():\n\t# Create an HTTP request node and connect its completion signal.\n\tvar http_request = HTTPRequest.new()\n\tadd_child(http_request)\n\thttp_request.request_completed.connect(self._http_request_completed)\n\n\t# Perform a GET request. The URL below returns JSON as of writing.\n\tvar error = http_request.request(\"https://httpbin.org/get\")\n\tif error != OK:\n\t\tpush_error(\"An error occurred in the HTTP request.\")\n\n\t# Perform a POST request. The URL below returns JSON as of writing.\n\t# Note: Don't make simultaneous requests using a single HTTPRequest node.\n\t# The snippet below is provided for reference only.\n\tvar body = JSON.new().stringify({\"name\": \"Godette\"})\n\terror = http_request.request(\"https://httpbin.org/post\", [], true, HTTPClient.METHOD_POST, body)\n\tif error != OK:\n\t\tpush_error(\"An error occurred in the HTTP request.\")\n\n# Called when the HTTP request is completed.\nfunc _http_request_completed(result, response_code, headers, body):\n\tvar json = JSON.new()\n\tjson.parse(body.get_string_from_utf8())\n\tvar response = json.get_data()\n\n\t# Will print the user agent string used by the HTTPRequest node (as recognized by httpbin.org).\n\tprint(response.headers[\"User-Agent\"])\n</code>\n```csharp\npublic override void _Ready()\n{\n\t// Create an HTTP request node and connect its completion signal.\n\tvar httpRequest = new HTTPRequest();\n\tAddChild(httpRequest);\n\thttpRequest.RequestCompleted += HttpRequestCompleted;\n\n\t// Perform a GET request. The URL below returns JSON as of writing.\n\tError error = httpRequest.Request(\"https://httpbin.org/get\");\n\tif (error != Error.Ok)\n\t{\n\t\tGD.PushError(\"An error occurred in the HTTP request.\");\n\t}\n\n\t// Perform a POST request. The URL below returns JSON as of writing.\n\t// Note: Don't make simultaneous requests using a single HTTPRequest node.\n\t// The snippet below is provided for reference only.\n\tstring body = new Json().Stringify(new Godot.Collections.Dictionary\n\t{\n\t\t{ \"name\", \"Godette\" }\n\t});\n\terror = httpRequest.Request(\"https://httpbin.org/post\", null, true, HTTPClient.Method.Post, body);\n\tif (error != Error.Ok)\n\t{\n\t\tGD.PushError(\"An error occurred in the HTTP request.\");\n\t}\n}\n\n// Called when the HTTP request is completed.\nprivate void HttpRequestCompleted(long result, long responseCode, string[] headers, byte[] body)\n{\n\tvar json = new Json();\n\tjson.Parse(body.GetStringFromUtf8());\n\tvar response = json.GetData().AsGodotDictionary();\n\n\t// Will print the user agent string used by the HTTPRequest node (as recognized by httpbin.org).\n\tGD.Print((response[\"headers\"].AsGodotDictionary())[\"User-Agent\"]);\n}\n```\n<!-- </codeblocks> -->\n<b>Example of loading and displaying an image using HTTPRequest:</b>\n<!-- <codeblocks> -->\n<code>\nfunc _ready():\n\t# Create an HTTP request node and connect its completion signal.\n\tvar http_request = HTTPRequest.new()\n\tadd_child(http_request)\n\thttp_request.request_completed.connect(self._http_request_completed)\n\n\t# Perform the HTTP request. The URL below returns a PNG image as of writing.\n\tvar error = http_request.request(\"https://via.placeholder.com/512\")\n\tif error != OK:\n\t\tpush_error(\"An error occurred in the HTTP request.\")\n\n# Called when the HTTP request is completed.\nfunc _http_request_completed(result, response_code, headers, body):\n\tif result != HTTPRequest.RESULT_SUCCESS:\n\t\tpush_error(\"Image couldn't be downloaded. Try a different image.\")\n\n\tvar image = Image.new()\n\tvar error = image.load_png_from_buffer(body)\n\tif error != OK:\n\t\tpush_error(\"Couldn't load the image.\")\n\n\tvar texture = ImageTexture.create_from_image(image)\n\n\t# Display the image in a TextureRect node.\n\tvar texture_rect = TextureRect.new()\n\tadd_child(texture_rect)\n\ttexture_rect.texture = texture\n</code>\n```csharp\npublic override void _Ready()\n{\n\t// Create an HTTP request node and connect its completion signal.\n\tvar httpRequest = new HTTPRequest();\n\tAddChild(httpRequest);\n\thttpRequest.RequestCompleted += HttpRequestCompleted;\n\n\t// Perform the HTTP request. The URL below returns a PNG image as of writing.\n\tError error = httpRequest.Request(\"https://via.placeholder.com/512\");\n\tif (error != Error.Ok)\n\t{\n\t\tGD.PushError(\"An error occurred in the HTTP request.\");\n\t}\n}\n\n// Called when the HTTP request is completed.\nprivate void HttpRequestCompleted(long result, long responseCode, string[] headers, byte[] body)\n{\n\tif (result != (long)HTTPRequest.Result.Success)\n\t{\n\t\tGD.PushError(\"Image couldn't be downloaded. Try a different image.\");\n\t}\n\tvar image = new Image();\n\tError error = image.LoadPngFromBuffer(body);\n\tif (error != Error.Ok)\n\t{\n\t\tGD.PushError(\"Couldn't load the image.\");\n\t}\n\n\tvar texture = ImageTexture.CreateFromImage(image);\n\n\t// Display the image in a TextureRect node.\n\tvar textureRect = new TextureRect();\n\tAddChild(textureRect);\n\ttextureRect.Texture = texture;\n}\n```\n<!-- </codeblocks> -->\n<b>Gzipped response bodies</b>: HTTPRequest will automatically handle decompression of response bodies. A <code>Accept-Encoding</code> header will be automatically added to each of your requests, unless one is already specified. Any response with a <code>Content-Encoding: gzip</code> header will automatically be decompressed and delivered to you as uncompressed bytes."
	},
	"HTTPClient": {
		"brief_description": "Low-level hyper-text transfer protocol client.",
		"description": "Hyper-text transfer protocol client (sometimes called \"User Agent\"). Used to make HTTP requests to download web content, upload files and other data or to communicate with various services, among other use cases.\nSee the [HTTPRequest](../HTTPRequest) node for a higher-level alternative.\n<b>Note:</b> This client only needs to connect to a host once (see <a href=\"#connect_to_host\">connect_to_host</a>) to send multiple requests. Because of this, methods that take URLs usually take just the part after the host instead of the full URL, as the client is already connected to a host. See <a href=\"#request\">request</a> for a full example and to get started.\nA [HTTPClient](../HTTPClient) should be reused between multiple requests or to connect to different hosts instead of creating one client per request. Supports Transport Layer Security (TLS), including server certificate verification. HTTP status codes in the 2xx range indicate success, 3xx redirection (i.e. \"try again, but over here\"), 4xx something was wrong with the request, and 5xx something went wrong on the server's side.\nFor more information on HTTP, see https://developer.mozilla.org/en-US/docs/Web/HTTP (or read RFC 2616 to get it straight from the source: https://tools.ietf.org/html/rfc2616).\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android.\n<b>Note:</b> It's recommended to use transport encryption (TLS) and to avoid sending sensitive information (such as login credentials) in HTTP GET URL parameters. Consider using HTTP POST requests or HTTP headers for such information instead.\n<b>Note:</b> When performing HTTP requests from a project exported to Web, keep in mind the remote server may not allow requests from foreign origins due to [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS). If you host the server in question, you should modify its backend to allow requests from foreign origins by adding the <code>Access-Control-Allow-Origin: *</code> HTTP header.\n<b>Note:</b> TLS support is currently limited to TLS 1.0, TLS 1.1, and TLS 1.2. Attempting to connect to a TLS 1.3-only server will return an error.\n<b>Warning:</b> TLS certificate revocation and certificate pinning are currently not supported. Revoked certificates are accepted as long as they are otherwise valid. If this is a concern, you may want to use automatically managed certificates with a short validity period."
	},
	"HSplitContainer": {
		"brief_description": "Horizontal split container.",
		"description": "Horizontal split container. See [SplitContainer](../SplitContainer). This goes from left to right."
	},
	"HSlider": {
		"brief_description": "Horizontal slider.",
		"description": "Horizontal slider. See [Slider](../Slider). This one goes from left (min) to right (max).\n<b>Note:</b> The <a href=\"../Range#changed\">Range.changed<a> and <a href=\"../Range#value_changed\">Range.value_changed<a> signals are part of the [Range](../Range) class which this class inherits from."
	},
	"HSeparator": {
		"brief_description": "Horizontal separator.",
		"description": "Horizontal separator. See [Separator](../Separator). Even though it looks horizontal, it is used to separate objects vertically."
	},
	"HScrollBar": {
		"brief_description": "Horizontal scroll bar.",
		"description": "Horizontal version of [ScrollBar](../ScrollBar), which goes from left (min) to right (max)."
	},
	"HMACContext": {
		"brief_description": "Used to create an HMAC for a message using a key.",
		"description": "The HMACContext class is useful for advanced HMAC use cases, such as streaming the message as it supports creating the message over time rather than providing it all at once.\n<!-- <codeblocks> -->\n<code>\nextends Node\nvar ctx = HMACContext.new()\n\nfunc _ready():\n\tvar key = \"supersecret\".to_utf8()\n\tvar err = ctx.start(HashingContext.HASH_SHA256, key)\n\tassert(err == OK)\n\tvar msg1 = \"this is \".to_utf8()\n\tvar msg2 = \"super duper secret\".to_utf8()\n\terr = ctx.update(msg1)\n\tassert(err == OK)\n\terr = ctx.update(msg2)\n\tassert(err == OK)\n\tvar hmac = ctx.finish()\n\tprint(hmac.hex_encode())\n\n</code>\n```csharp\nusing Godot;\nusing System.Diagnostics;\n\npublic partial class MyNode : Node\n{\n\tprivate HmacContext _ctx = new HmacContext();\n\n\tpublic override void _Ready()\n\t{\n\t\tbyte[] key = \"supersecret\".ToUtf8();\n\t\tError err = _ctx.Start(HashingContext.HashType.Sha256, key);\n\t\tDebug.Assert(err == Error.Ok);\n\t\tbyte[] msg1 = \"this is \".ToUtf8();\n\t\tbyte[] msg2 = \"super duper secret\".ToUtf8();\n\t\terr = _ctx.Update(msg1);\n\t\tDebug.Assert(err == Error.Ok);\n\t\terr = _ctx.Update(msg2);\n\t\tDebug.Assert(err == Error.Ok);\n\t\tbyte[] hmac = _ctx.Finish();\n\t\tGD.Print(hmac.HexEncode());\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"HingeJoint3D": {
		"brief_description": "A hinge between two 3D PhysicsBodies.",
		"description": "A HingeJoint3D normally uses the Z axis of body A as the hinge axis, another axis can be specified when adding it manually though. See also [Generic6DOFJoint3D](../Generic6DOFJoint3D)."
	},
	"HFlowContainer": {
		"brief_description": "Horizontal flow container.",
		"description": "Horizontal version of [FlowContainer](../FlowContainer)."
	},
	"HeightMapShape3D": {
		"brief_description": "Height map shape resource for 3D physics.",
		"description": "Height map shape resource, which can be added to a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D). Heightmap collision is typically used for colliding with terrains. However, since heightmaps cannot store overhangs, collisions with other structures (such as buildings) must be done with other collision shapes such as [ConcavePolygonShape3D](../ConcavePolygonShape3D). If needed, \"holes\" can be created in an [HeightMapShape3D](../HeightMapShape3D) by assigning very low points (like <code>-100000</code>) in the desired area.\n<b>Performance:</b> [HeightMapShape3D](../HeightMapShape3D) is faster to check collisions against compared to [ConcavePolygonShape3D](../ConcavePolygonShape3D), but it is slower than primitive collision shapes such as [SphereShape3D](../SphereShape3D) or [BoxShape3D](../BoxShape3D)."
	},
	"HBoxContainer": {
		"brief_description": "Horizontal box container.",
		"description": "Horizontal box container. See [BoxContainer](../BoxContainer)."
	},
	"HashingContext": {
		"brief_description": "Context to compute cryptographic hashes over multiple iterations.",
		"description": "The HashingContext class provides an interface for computing cryptographic hashes over multiple iterations. This is useful for example when computing hashes of big files (so you don't have to load them all in memory), network streams, and data streams in general (so you don't have to hold buffers).\nThe <a href=\"#HashType\">HashType</a> enum shows the supported hashing algorithms.\n<!-- <codeblocks> -->\n<code>\nconst CHUNK_SIZE = 1024\n\nfunc hash_file(path):\n\t# Check that file exists.\n\tif not FileAccess.file_exists(path):\n\t\treturn\n\t# Start a SHA-256 context.\n\tvar ctx = HashingContext.new()\n\tctx.start(HashingContext.HASH_SHA256)\n\t# Open the file to hash.\n\tvar file = FileAccess.open(path, FileAccess.READ)\n\t# Update the context after reading each chunk.\n\twhile not file.eof_reached():\n\t\tctx.update(file.get_buffer(CHUNK_SIZE))\n\t# Get the computed hash.\n\tvar res = ctx.finish()\n\t# Print the result as hex string and array.\n\tprintt(res.hex_encode(), Array(res))\n</code>\n```csharp\npublic const int ChunkSize = 1024;\n\npublic void HashFile(string path)\n{\n\t// Check that file exists.\n\tif (!FileAccess.FileExists(path))\n\t{\n\t\treturn;\n\t}\n\t// Start a SHA-256 context.\n\tvar ctx = new HashingContext();\n\tctx.Start(HashingContext.HashType.Sha256);\n\t// Open the file to hash.\n\tusing var file = FileAccess.Open(path, FileAccess.ModeFlags.Read);\n\t// Update the context after reading each chunk.\n\twhile (!file.EofReached())\n\t{\n\t\tctx.Update(file.GetBuffer(ChunkSize));\n\t}\n\t// Get the computed hash.\n\tbyte[] res = ctx.Finish();\n\t// Print the result as hex string and array.\n\tGD.PrintT(res.HexEncode(), (Variant)res);\n}\n```\n<!-- </codeblocks> -->"
	},
	"GrooveJoint2D": {
		"brief_description": "Groove constraint for 2D physics.",
		"description": "Groove constraint for 2D physics. This is useful for making a body \"slide\" through a segment placed in another."
	},
	"GridContainer": {
		"brief_description": "Grid container used to arrange Control-derived children in a grid like layout.",
		"description": "GridContainer will arrange its Control-derived children in a grid like structure, the grid columns are specified using the <a href=\"#columns\">columns</a> property and the number of rows will be equal to the number of children in the container divided by the number of columns. For example, if the container has 5 children, and 2 columns, there will be 3 rows in the container.\nNotice that grid layout will preserve the columns and rows for every size of the container, and that empty columns will be expanded automatically.\n<b>Note:</b> GridContainer only works with child nodes inheriting from Control. It won't rearrange child nodes inheriting from Node2D."
	},
	"GraphNode": {
		"brief_description": "GraphNode is a [Container](../Container) control that represents a single data unit in a [GraphEdit](../GraphEdit) graph. You can customize the number, type, and color of left- and right-side connection ports.",
		"description": "<b>Note:</b> Please be aware that this node will undergo extensive refactoring in a future 4.x version involving compatibility-breaking API changes.\nGraphNode allows to create nodes for a [GraphEdit](../GraphEdit) graph with customizable content based on its child [Control](../Control)s. GraphNode is a [Container](../Container) and is responsible for placing its children on screen. This works similar to [VBoxContainer](../VBoxContainer). Children, in turn, provide GraphNode with so-called slots, each of which can have a connection port on either side. This is similar to how [TabContainer](../TabContainer) uses children to create the tabs.\nEach GraphNode slot is defined by its index and can provide the node with up to two ports: one on the left, and one on the right. By convention the left port is also referred to as the input port and the right port is referred to as the output port. Each port can be enabled and configured individually, using different type and color. The type is an arbitrary value that you can define using your own considerations. The parent [GraphEdit](../GraphEdit) will receive this information on each connect and disconnect request.\nSlots can be configured in the Inspector dock once you add at least one child [Control](../Control). The properties are grouped by each slot's index in the \"Slot\" section.\n<b>Note:</b> While GraphNode is set up using slots and slot indices, connections are made between the ports which are enabled. Because of that [GraphEdit](../GraphEdit) uses port's index and not slot's index. You can use <a href=\"#get_connection_input_slot\">get_connection_input_slot</a> and <a href=\"#get_connection_output_slot\">get_connection_output_slot</a> to get the slot index from the port index."
	},
	"GraphEdit": {
		"brief_description": "GraphEdit is a control responsible for displaying and manipulating graph-like data using [GraphNode](../GraphNode)s. It provides access to creation, removal, connection, and disconnection of nodes.",
		"description": "<b>Note:</b> Please be aware that this node will undergo extensive refactoring in a future 4.x version involving compatibility-breaking API changes.\nGraphEdit provides tools for creation, manipulation, and display of various graphs. Its main purpose in the engine is to power the visual programming systems, such as visual shaders, but it is also available for use in user projects.\nGraphEdit by itself is only an empty container, representing an infinite grid where [GraphNode](../GraphNode)s can be placed. Each [GraphNode](../GraphNode) represent a node in the graph, a single unit of data in the connected scheme. GraphEdit, in turn, helps to control various interactions with nodes and between nodes. When the user attempts to connect, disconnect, or close a [GraphNode](../GraphNode), a signal is emitted in the GraphEdit, but no action is taken by default. It is the responsibility of the programmer utilizing this control to implement the necessary logic to determine how each request should be handled.\n<b>Performance:</b> It is greatly advised to enable low-processor usage mode (see <a href=\"../OS#low_processor_usage_mode\">OS.low_processor_usage_mode<a>) when using GraphEdits."
	},
	"GradientTexture2D": {
		"brief_description": "Gradient-filled 2D texture.",
		"description": "The texture uses a [Gradient](../Gradient) to fill the texture data in 2D space. The gradient is filled according to the specified <a href=\"#fill\">fill</a> and <a href=\"#repeat\">repeat</a> types using colors obtained from the gradient. The texture does not necessarily represent an exact copy of the gradient, but instead an interpolation of samples obtained from the gradient at fixed steps (see <a href=\"#width\">width</a> and <a href=\"#height\">height</a>). See also [GradientTexture1D](../GradientTexture1D), [CurveTexture](../CurveTexture) and [CurveXYZTexture](../CurveXYZTexture)."
	},
	"GradientTexture1D": {
		"brief_description": "Gradient-filled texture.",
		"description": "GradientTexture1D uses a [Gradient](../Gradient) to fill the texture data. The gradient will be filled from left to right using colors obtained from the gradient. This means the texture does not necessarily represent an exact copy of the gradient, but instead an interpolation of samples obtained from the gradient at fixed steps (see <a href=\"#width\">width</a>). See also [GradientTexture2D](../GradientTexture2D), [CurveTexture](../CurveTexture) and [CurveXYZTexture](../CurveXYZTexture)."
	},
	"Gradient": {
		"brief_description": "A color interpolator resource which can be used to generate colors between user-defined color points.",
		"description": "Given a set of colors, this resource will interpolate them in order. This means that if you have color 1, color 2 and color 3, the gradient will interpolate from color 1 to color 2 and from color 2 to color 3. The gradient will initially have 2 colors (black and white), one (black) at gradient lower offset 0 and the other (white) at the gradient higher offset 1.\nSee also [Curve](../Curve) which supports more complex easing methods, but does not support colors."
	},
	"GPUParticlesCollisionSphere3D": {
		"brief_description": "Sphere-shaped 3D particle collision shape affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Sphere-shaped 3D particle collision shape affecting [GPUParticles3D](../GPUParticles3D) nodes.\n<b>Note:</b> <a href=\"../ParticleProcessMaterial#collision_mode\">ParticleProcessMaterial.collision_mode<a> must be <a href=\"../ParticleProcessMaterial#COLLISION_RIGID\">ParticleProcessMaterial.COLLISION_RIGID<a> or <a href=\"../ParticleProcessMaterial#COLLISION_HIDE_ON_CONTACT\">ParticleProcessMaterial.COLLISION_HIDE_ON_CONTACT<a> on the [GPUParticles3D](../GPUParticles3D)'s process material for collision to work.\n<b>Note:</b> Particle collision only affects [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D)."
	},
	"GPUParticlesCollisionSDF3D": {
		"brief_description": "Baked signed distance field 3D particle attractor affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Baked signed distance field 3D particle attractor affecting [GPUParticles3D](../GPUParticles3D) nodes.\nSigned distance fields (SDF) allow for efficiently representing approximate collision shapes for convex and concave objects of any shape. This is more flexible than [GPUParticlesCollisionHeightField3D](../GPUParticlesCollisionHeightField3D), but it requires a baking step.\n<b>Baking:</b> The signed distance field texture can be baked by selecting the [GPUParticlesCollisionSDF3D](../GPUParticlesCollisionSDF3D) node in the editor, then clicking <b>Bake SDF</b> at the top of the 3D viewport. Any <i>visible</i> [MeshInstance3D](../MeshInstance3D)s within the <a href=\"#size\">size</a> will be taken into account for baking, regardless of their <a href=\"../GeometryInstance3D#gi_mode\">GeometryInstance3D.gi_mode<a>.\n<b>Note:</b> Baking a [GPUParticlesCollisionSDF3D](../GPUParticlesCollisionSDF3D)'s <a href=\"#texture\">texture</a> is only possible within the editor, as there is no bake method exposed for use in exported projects. However, it's still possible to load pre-baked [Texture3D](../Texture3D)s into its <a href=\"#texture\">texture</a> property in an exported project.\n<b>Note:</b> <a href=\"../ParticleProcessMaterial#collision_mode\">ParticleProcessMaterial.collision_mode<a> must be <a href=\"../ParticleProcessMaterial#COLLISION_RIGID\">ParticleProcessMaterial.COLLISION_RIGID<a> or <a href=\"../ParticleProcessMaterial#COLLISION_HIDE_ON_CONTACT\">ParticleProcessMaterial.COLLISION_HIDE_ON_CONTACT<a> on the [GPUParticles3D](../GPUParticles3D)'s process material for collision to work.\n<b>Note:</b> Particle collision only affects [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D)."
	},
	"GPUParticlesCollisionHeightField3D": {
		"brief_description": "Real-time heightmap-shaped 3D particle attractor affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Real-time heightmap-shaped 3D particle attractor affecting [GPUParticles3D](../GPUParticles3D) nodes.\nHeightmap shapes allow for efficiently representing collisions for convex and concave objects with a single \"floor\" (such as terrain). This is less flexible than [GPUParticlesCollisionSDF3D](../GPUParticlesCollisionSDF3D), but it doesn't require a baking step.\n[GPUParticlesCollisionHeightField3D](../GPUParticlesCollisionHeightField3D) can also be regenerated in real-time when it is moved, when the camera moves, or even continuously. This makes [GPUParticlesCollisionHeightField3D](../GPUParticlesCollisionHeightField3D) a good choice for weather effects such as rain and snow and games with highly dynamic geometry. However, since heightmaps cannot represent overhangs, [GPUParticlesCollisionHeightField3D](../GPUParticlesCollisionHeightField3D) is not suited for indoor particle collision.\n<b>Note:</b> <a href=\"../ParticleProcessMaterial#collision_mode\">ParticleProcessMaterial.collision_mode<a> must be <code>true</code> on the [GPUParticles3D](../GPUParticles3D)'s process material for collision to work.\n<b>Note:</b> Particle collision only affects [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D)."
	},
	"GPUParticlesCollisionBox3D": {
		"brief_description": "Box-shaped 3D particle collision shape affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Box-shaped 3D particle collision shape affecting [GPUParticles3D](../GPUParticles3D) nodes.\n<b>Note:</b> <a href=\"../ParticleProcessMaterial#collision_mode\">ParticleProcessMaterial.collision_mode<a> must be <a href=\"../ParticleProcessMaterial#COLLISION_RIGID\">ParticleProcessMaterial.COLLISION_RIGID<a> or <a href=\"../ParticleProcessMaterial#COLLISION_HIDE_ON_CONTACT\">ParticleProcessMaterial.COLLISION_HIDE_ON_CONTACT<a> on the [GPUParticles3D](../GPUParticles3D)'s process material for collision to work.\n<b>Note:</b> Particle collision only affects [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D)."
	},
	"GPUParticlesCollision3D": {
		"brief_description": "Abstract class for 3D particle collision shapes affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Particle collision shapes can be used to make particles stop or bounce against them.\nParticle collision shapes in real-time and can be moved, rotated and scaled during gameplay. Unlike attractors, non-uniform scaling of collision shapes is <i>not</i> supported.\nParticle collision shapes can be temporarily disabled by hiding them.\n<b>Note:</b> <a href=\"../ParticleProcessMaterial#collision_mode\">ParticleProcessMaterial.collision_mode<a> must be <a href=\"../ParticleProcessMaterial#COLLISION_RIGID\">ParticleProcessMaterial.COLLISION_RIGID<a> or <a href=\"../ParticleProcessMaterial#COLLISION_HIDE_ON_CONTACT\">ParticleProcessMaterial.COLLISION_HIDE_ON_CONTACT<a> on the [GPUParticles3D](../GPUParticles3D)'s process material for collision to work.\n<b>Note:</b> Particle collision only affects [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D).\n<b>Note:</b> Particles pushed by a collider that is being moved will not be interpolated, which can result in visible stuttering. This can be alleviated by setting <a href=\"../GPUParticles3D#fixed_fps\">GPUParticles3D.fixed_fps<a> to <code>0</code> or a value that matches or exceeds the target framerate."
	},
	"GPUParticlesAttractorVectorField3D": {
		"brief_description": "Box-shaped 3D particle attractor with strength varying within the box, affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Box-shaped 3D particle attractor with strength varying within the box, affecting [GPUParticles3D](../GPUParticles3D) nodes.\nUnlike [GPUParticlesAttractorBox3D](../GPUParticlesAttractorBox3D), [GPUParticlesAttractorVectorField3D](../GPUParticlesAttractorVectorField3D) uses a <a href=\"#texture\">texture</a> to affect attraction strength within the box. This can be used to create complex attraction scenarios where particles travel in different directions depending on their location. This can be useful for weather effects such as sandstorms.\n<b>Note:</b> Particle attractors only affect [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D)."
	},
	"GPUParticlesAttractorSphere3D": {
		"brief_description": "Ellipse-shaped 3D particle attractor affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Ellipse-shaped 3D particle attractor affecting [GPUParticles3D](../GPUParticles3D) nodes.\n<b>Note:</b> Particle attractors only affect [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D)."
	},
	"GPUParticlesAttractorBox3D": {
		"brief_description": "Box-shaped 3D particle attractor affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Box-shaped 3D particle attractor affecting [GPUParticles3D](../GPUParticles3D) nodes.\n<b>Note:</b> Particle attractors only affect [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D)."
	},
	"GPUParticlesAttractor3D": {
		"brief_description": "Abstract class for 3D particle attractors affecting [GPUParticles3D](../GPUParticles3D) nodes.",
		"description": "Particle attractors can be used to attract particles towards the attractor's origin, or to push them away from the attractor's origin.\nParticle attractors work in real-time and can be moved, rotated and scaled during gameplay. Unlike collision shapes, non-uniform scaling of attractors is also supported.\nAttractors can be temporarily disabled by hiding them, or by setting their <a href=\"#strength\">strength</a> to <code>0.0</code>.\n<b>Note:</b> Particle attractors only affect [GPUParticles3D](../GPUParticles3D), not [CPUParticles3D](../CPUParticles3D)."
	},
	"GPUParticles3D": {
		"brief_description": "3D particle emitter.",
		"description": "3D particle node used to create a variety of particle systems and effects. [GPUParticles3D](../GPUParticles3D) features an emitter that generates some number of particles at a given rate.\nUse the <code>process_material</code> property to add a [ParticleProcessMaterial](../ParticleProcessMaterial) to configure particle appearance and behavior. Alternatively, you can add a [ShaderMaterial](../ShaderMaterial) which will be applied to all particles."
	},
	"GPUParticles2D": {
		"brief_description": "2D particle emitter.",
		"description": "2D particle node used to create a variety of particle systems and effects. [GPUParticles2D](../GPUParticles2D) features an emitter that generates some number of particles at a given rate.\nUse the <a href=\"#process_material\">process_material</a> property to add a [ParticleProcessMaterial](../ParticleProcessMaterial) to configure particle appearance and behavior. Alternatively, you can add a [ShaderMaterial](../ShaderMaterial) which will be applied to all particles.\n2D particles can optionally collide with [LightOccluder2D](../LightOccluder2D) nodes (note: they don't collide with [PhysicsBody2D](../PhysicsBody2D) nodes)."
	},
	"GeometryInstance3D": {
		"brief_description": "Base node for geometry-based visual instances.",
		"description": "Base node for geometry-based visual instances. Shares some common functionality like visibility and custom materials."
	},
	"Geometry3D": {
		"brief_description": "Helper node to calculate generic geometry operations in 3D space.",
		"description": "Geometry3D provides users with a set of helper functions to create geometric shapes, compute intersections between shapes, and process various other geometric operations."
	},
	"Geometry2D": {
		"brief_description": "Helper node to calculate generic geometry operations in 2D space.",
		"description": "Geometry2D provides users with a set of helper functions to create geometric shapes, compute intersections between shapes, and process various other geometric operations."
	},
	"Generic6DOFJoint3D": {
		"brief_description": "The generic 6-degrees-of-freedom joint can implement a variety of joint types by locking certain axes' rotation or translation.",
		"description": "The first 3 DOF axes are linear axes, which represent translation of Bodies, and the latter 3 DOF axes represent the angular motion. Each axis can be either locked, or limited."
	},
	"GDExtensionManager": {
		"brief_description": "",
		"description": ""
	},
	"GDExtension": {
		"brief_description": "",
		"description": ""
	},
	"FontVariation": {
		"brief_description": "Variation of the [Font](../Font).",
		"description": "OpenType variations, simulated bold / slant, and additional font settings like OpenType features and extra spacing.\nTo use simulated bold font variant:\n<!-- <codeblocks> -->\n<code>\nvar fv = FontVariation.new()\nfv.set_base_font(load(\"res://BarlowCondensed-Regular.ttf\"))\nfv.set_variation_embolden(1.2)\n$Label.add_theme_font_override(\"font\", fv)\n$Label.add_theme_font_size_override(\"font_size\", 64)\n</code>\n```csharp\nvar fv = new FontVariation();\nfv.SetBaseFont(ResourceLoader.Load<FontFile>(\"res://BarlowCondensed-Regular.ttf\"));\nfv.SetVariationEmbolden(1.2);\nGetNode(\"Label\").AddThemeFontOverride(\"font\", fv);\nGetNode(\"Label\").AddThemeFontSizeOverride(\"font_size\", 64);\n```\n<!-- </codeblocks> -->\nTo set the coordinate of multiple variation axes:\n<code>\nvar fv = FontVariation.new();\nvar ts = TextServerManager.get_primary_interface()\nfv.base_font = load(\"res://BarlowCondensed-Regular.ttf\")\nfv.variation_opentype = { ts.name_to_tag(\"wght\"): 900, ts.name_to_tag(\"custom_hght\"): 900 }\n</code>"
	},
	"FontFile": {
		"brief_description": "Font source data and prerendered glyph cache, imported from dynamic or bitmap font.",
		"description": "[FontFile](../FontFile) contains a set of glyphs to represent Unicode characters imported from a font file, as well as a cache of rasterized glyphs, and a set of fallback [Font](../Font)s to use.\nUse [FontVariation](../FontVariation) to access specific OpenType variation of the font, create simulated bold / slanted version, and draw lines of text.\nFor more complex text processing, use [FontVariation](../FontVariation) in conjunction with [TextLine](../TextLine) or [TextParagraph](../TextParagraph).\nSupported font formats:\n- Dynamic font importer: TrueType (.ttf), TrueType collection (.ttc), OpenType (.otf), OpenType collection (.otc), WOFF (.woff), WOFF2 (.woff2), Type 1 (.pfb, .pfm).\n- Bitmap font importer: AngelCode BMFont (.fnt, .font), text and binary (version 3) format variants.\n- Monospace image font importer: All supported image formats.\n<b>Note:</b> A character is a symbol that represents an item (letter, digit etc.) in an abstract way.\n<b>Note:</b> A glyph is a bitmap or shape used to draw a one or more characters in a context-dependent manner. Glyph indices are bound to the specific font data source.\n<b>Note:</b> If a none of the font data sources contain glyphs for a character used in a string, the character in question will be replaced with a box displaying its hexadecimal code.\n<!-- <codeblocks> -->\n<code>\nvar f = load(\"res://BarlowCondensed-Bold.ttf\")\n$Label.add_theme_font_override(\"font\", f)\n$Label.add_theme_font_size_override(\"font_size\", 64)\n</code>\n```csharp\nvar f = ResourceLoader.Load<FontFile>(\"res://BarlowCondensed-Bold.ttf\");\nGetNode(\"Label\").AddThemeFontOverride(\"font\", f);\nGetNode(\"Label\").AddThemeFontSizeOverride(\"font_size\", 64);\n```\n<!-- </codeblocks> -->"
	},
	"Font": {
		"brief_description": "Base class for fonts and font variations.",
		"description": "Font is the abstract base class for font, so it shouldn't be used directly. Other types of fonts inherit from it."
	},
	"FogVolume": {
		"brief_description": "A node used to add local fog with the volumetric fog effect.",
		"description": "[FogVolume](../FogVolume)s are used to add localized fog into the global volumetric fog effect. [FogVolume](../FogVolume)s can also remove volumetric fog from specific areas if using a [FogMaterial](../FogMaterial) with a negative <a href=\"../FogMaterial#density\">FogMaterial.density<a>.\nPerformance of [FogVolume](../FogVolume)s is directly related to their relative size on the screen and the complexity of their attached [FogMaterial](../FogMaterial). It is best to keep [FogVolume](../FogVolume)s relatively small and simple where possible.\n<b>Note:</b> [FogVolume](../FogVolume)s only have a visible effect if <a href=\"../Environment#volumetric_fog_enabled\">Environment.volumetric_fog_enabled<a> is <code>true</code>. If you don't want fog to be globally visible (but only within [FogVolume](../FogVolume) nodes), set <a href=\"../Environment#volumetric_fog_density\">Environment.volumetric_fog_density<a> to <code>0.0</code>."
	},
	"FogMaterial": {
		"brief_description": "[Material](../Material) used with a [FogVolume](../FogVolume) to draw things with the volumetric fog effect.",
		"description": "A [Material](../Material) resource that can be used by [FogVolume](../FogVolume)s to draw volumetric effects.\nIf you need more advanced effects, use a custom [fog shader]($DOCS_URL/tutorials/shaders/shader_reference/fog_shader.html)."
	},
	"FlowContainer": {
		"brief_description": "Base class for flow containers.",
		"description": "Arranges child [Control](../Control) nodes vertically or horizontally in a left-to-right or top-to-bottom flow.\nA line is filled with [Control](../Control) nodes until no more fit on the same line, similar to text in an autowrapped label."
	},
	"float": {
		"brief_description": "Float built-in type.",
		"description": "The [float](../float) built-in type is a 64-bit double-precision floating-point number, equivalent to <code>double</code> in C++. This type has 14 reliable decimal digits of precision. The [float](../float) type can be stored in [Variant](../Variant), which is the generic type used by the engine. The maximum value of [float](../float) is approximately <code>1.79769e308</code>, and the minimum is approximately <code>-1.79769e308</code>.\nMany methods and properties in the engine use 32-bit single-precision floating-point numbers instead, equivalent to <code>float</code> in C++, which have 6 reliable decimal digits of precision. For data structures such as [Vector2](../Vector2) and [Vector3](../Vector3), Godot uses 32-bit floating-point numbers by default, but it can be changed to use 64-bit doubles if Godot is compiled with the <code>precision=double</code> option.\nMath done using the [float](../float) type is not guaranteed to be exact or deterministic, and will often result in small errors. You should usually use the [method @GlobalScope.is_equal_approx] and [method @GlobalScope.is_zero_approx] methods instead of <code>==</code> to compare [float](../float) values for equality."
	},
	"FileSystemDock": {
		"brief_description": "",
		"description": ""
	},
	"FileDialog": {
		"brief_description": "Dialog for selecting files or directories in the filesystem.",
		"description": "FileDialog is a preset dialog used to choose files and directories in the filesystem. It supports filter masks. The FileDialog automatically sets its window title according to the <a href=\"#file_mode\">file_mode</a>. If you want to use a custom title, disable this by setting <a href=\"#mode_overrides_title\">mode_overrides_title</a> to <code>false</code>."
	},
	"FileAccess": {
		"brief_description": "Type to handle file reading and writing operations.",
		"description": "File type. This is used to permanently store data into the user device's file system and to read from it. This can be used to store game save data or player configuration files, for example.\nHere's a sample on how to write and read from a file:\n<!-- <codeblocks> -->\n<code>\nfunc save(content):\n\tvar file = FileAccess.open(\"user://save_game.dat\", FileAccess.WRITE)\n\tfile.store_string(content)\n\nfunc load():\n\tvar file = FileAccess.open(\"user://save_game.dat\", FileAccess.READ)\n\tvar content = file.get_as_text()\n\treturn content\n</code>\n```csharp\npublic void Save(string content)\n{\n\tusing var file = FileAccess.Open(\"user://save_game.dat\", FileAccess.ModeFlags.Write);\n\tfile.StoreString(content);\n}\n\npublic string Load()\n{\n\tusing var file = FileAccess.Open(\"user://save_game.dat\", FileAccess.ModeFlags.Read);\n\tstring content = file.GetAsText();\n\treturn content;\n}\n```\n<!-- </codeblocks> -->\nIn the example above, the file will be saved in the user data folder as specified in the [Data paths]($DOCS_URL/tutorials/io/data_paths.html) documentation.\n[FileAccess](../FileAccess) will close when it's freed, which happens when it goes out of scope or when it gets assigned with <code>null</code>. In C# the reference must be disposed after we are done using it, this can be done with the <code>using</code> statement or calling the <code>Dispose</code> method directly.\n<!-- <codeblocks> -->\n<code>\nvar file = FileAccess.open(\"res://something\") # File is opened and locked for use.\nfile = null # File is closed.\n</code>\n```csharp\nusing var file = FileAccess.Open(\"res://something\"); // File is opened and locked for use.\n// The using statement calls Dispose when going out of scope.\n```\n<!-- </codeblocks> -->\n<b>Note:</b> To access project resources once exported, it is recommended to use [ResourceLoader](../ResourceLoader) instead of the [FileAccess](../FileAccess) API, as some files are converted to engine-specific formats and their original source files might not be present in the exported PCK package.\n<b>Note:</b> Files are automatically closed only if the process exits \"normally\" (such as by clicking the window manager's close button or pressing <b>Alt + F4</b>). If you stop the project execution by pressing <b>F8</b> while the project is running, the file won't be closed as the game process will be killed. You can work around this by calling <a href=\"#flush\">flush</a> at regular intervals."
	},
	"Expression": {
		"brief_description": "A class that stores an expression you can execute.",
		"description": "An expression can be made of any arithmetic operation, built-in math function call, method call of a passed instance, or built-in type construction call.\nAn example expression text using the built-in math functions could be <code>sqrt(pow(3, 2) + pow(4, 2))</code>.\nIn the following example we use a [LineEdit](../LineEdit) node to write our expression and show the result.\n<!-- <codeblocks> -->\n<code>\nvar expression = Expression.new()\n\nfunc _ready():\n\t$LineEdit.text_submitted.connect(self._on_text_submitted)\n\nfunc _on_text_submitted(command):\n\tvar error = expression.parse(command)\n\tif error != OK:\n\t\tprint(expression.get_error_text())\n\t\treturn\n\tvar result = expression.execute()\n\tif not expression.has_execute_failed():\n\t\t$LineEdit.text = str(result)\n</code>\n```csharp\nprivate Expression _expression = new Expression();\n\npublic override void _Ready()\n{\n\tGetNode<LineEdit>(\"LineEdit\").TextSubmitted += OnTextEntered;\n}\n\nprivate void OnTextEntered(string command)\n{\n\tError error = _expression.Parse(command);\n\tif (error != Error.Ok)\n\t{\n\t\tGD.Print(_expression.GetErrorText());\n\t\treturn;\n\t}\n\tVariant result = _expression.Execute();\n\tif (!_expression.HasExecuteFailed())\n\t{\n\t\tGetNode<LineEdit>(\"LineEdit\").Text = result.ToString();\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"Environment": {
		"brief_description": "Resource for environment nodes (like [WorldEnvironment](../WorldEnvironment)) that define multiple rendering options.",
		"description": "Resource for environment nodes (like [WorldEnvironment](../WorldEnvironment)) that define multiple environment operations (such as background [Sky](../Sky) or [Color](../Color), ambient light, fog, depth-of-field...). These parameters affect the final render of the scene. The order of these operations is:\n- Depth of Field Blur\n- Glow\n- Tonemap (Auto Exposure)\n- Adjustments"
	},
	"EngineProfiler": {
		"brief_description": "Base class for creating custom profilers.",
		"description": "This class can be used to implement custom profilers that are able to interact with the engine and editor debugger.\nSee [EngineDebugger](../EngineDebugger) and [EditorDebuggerPlugin](../EditorDebuggerPlugin) for more information."
	},
	"EngineDebugger": {
		"brief_description": "Exposes the internal debugger.",
		"description": "[EngineDebugger](../EngineDebugger) handles the communication between the editor and the running game. It is active in the running game. Messages can be sent/received through it. It also manages the profilers."
	},
	"Engine": {
		"brief_description": "Access to engine properties.",
		"description": "The [Engine](../Engine) singleton allows you to query and modify the project's run-time parameters, such as frames per second, time scale, and others."
	},
	"EncodedObjectAsID": {
		"brief_description": "Holds a reference to an [Object](../Object)'s instance ID.",
		"description": "Utility class which holds a reference to the internal identifier of an [Object](../Object) instance, as given by <a href=\"../Object#get_instance_id\">Object.get_instance_id<a>. This ID can then be used to retrieve the object instance with [method @GlobalScope.instance_from_id].\nThis class is used internally by the editor inspector and script debugger, but can also be used in plugins to pass and display objects as their IDs."
	},
	"EditorVCSInterface": {
		"brief_description": "Version Control System (VCS) interface, which reads and writes to the local VCS in use.",
		"description": "Defines the API that the editor uses to extract information from the underlying VCS. The implementation of this API is included in VCS plugins, which are GDExtension plugins that inherit [EditorVCSInterface](../EditorVCSInterface) and are attached (on demand) to the singleton instance of [EditorVCSInterface](../EditorVCSInterface). Instead of performing the task themselves, all the virtual functions listed below are calling the internally overridden functions in the VCS plugins to provide a plug-n-play experience. A custom VCS plugin is supposed to inherit from [EditorVCSInterface](../EditorVCSInterface) and override each of these virtual functions."
	},
	"EditorUndoRedoManager": {
		"brief_description": "Manages undo history of scenes opened in the editor.",
		"description": "[EditorUndoRedoManager](../EditorUndoRedoManager) is a manager for [UndoRedo](../UndoRedo) objects associated with edited scenes. Each scene has its own undo history and [EditorUndoRedoManager](../EditorUndoRedoManager) ensures that each action performed in the editor gets associated with a proper scene. For actions not related to scenes ([ProjectSettings](../ProjectSettings) edits, external resources, etc.), a separate global history is used.\nThe usage is mostly the same as [UndoRedo](../UndoRedo). You create and commit actions and the manager automatically decides under-the-hood what scenes it belongs to. The scene is deduced based on the first operation in an action, using the object from the operation. The rules are as follows:\n- If the object is a [Node](../Node), use the currently edited scene;\n- If the object is a built-in resource, use the scene from its path;\n- If the object is external resource or anything else, use global history.\nThis guessing can sometimes yield false results, so you can provide a custom context object when creating an action."
	},
	"EditorTranslationParserPlugin": {
		"brief_description": "Plugin for adding custom parsers to extract strings that are to be translated from custom files (.csv, .json etc.).",
		"description": "[EditorTranslationParserPlugin](../EditorTranslationParserPlugin) is invoked when a file is being parsed to extract strings that require translation. To define the parsing and string extraction logic, override the <a href=\"#_parse_file\">_parse_file</a> method in script.\nAdd the extracted strings to argument <code>msgids</code> or <code>msgids_context_plural</code> if context or plural is used.\nWhen adding to <code>msgids_context_plural</code>, you must add the data using the format <code>[\"A\", \"B\", \"C\"]</code>, where <code>A</code> represents the extracted string, <code>B</code> represents the context, and <code>C</code> represents the plural version of the extracted string. If you want to add only context but not plural, put <code>\"\"</code> for the plural slot. The idea is the same if you only want to add plural but not context. See the code below for concrete examples.\nThe extracted strings will be written into a POT file selected by user under \"POT Generation\" in \"Localization\" tab in \"Project Settings\" menu.\nBelow shows an example of a custom parser that extracts strings from a CSV file to write into a POT.\n<!-- <codeblocks> -->\n<code>\n@tool\nextends EditorTranslationParserPlugin\n\nfunc _parse_file(path, msgids, msgids_context_plural):\n\tvar file = FileAccess.open(path, FileAccess.READ)\n\tvar text = file.get_as_text()\n\tvar split_strs = text.split(\",\", false)\n\tfor s in split_strs:\n\t\tmsgids.append(s)\n\t\t#print(\"Extracted string: \" + s)\n\nfunc _get_recognized_extensions():\n\treturn [\"csv\"]\n</code>\n```csharp\nusing Godot;\n\n[Tool](../Tool)\npublic partial class CustomParser : EditorTranslationParserPlugin\n{\n\tpublic override void _ParseFile(string path, Godot.Collections.Array<string> msgids, Godot.Collections.Array<Godot.Collections.Array> msgidsContextPlural)\n\t{\n\t\tusing var file = FileAccess.Open(path, FileAccess.ModeFlags.Read);\n\t\tstring text = file.GetAsText();\n\t\tstring[] splitStrs = text.Split(\",\", allowEmpty: false);\n\t\tforeach (string s in splitStrs)\n\t\t{\n\t\t\tmsgids.Add(s);\n\t\t\t//GD.Print($\"Extracted string: {s}\");\n\t\t}\n\t}\n\n\tpublic override string[] _GetRecognizedExtensions()\n\t{\n\t\treturn new string[] { \"csv\" };\n\t}\n}\n```\n<!-- </codeblocks> -->\nTo add a translatable string associated with context or plural, add it to <code>msgids_context_plural</code>:\n<!-- <codeblocks> -->\n<code>\n# This will add a message with msgid \"Test 1\", msgctxt \"context\", and msgid_plural \"test 1 plurals\".\nmsgids_context_plural.append([\"Test 1\", \"context\", \"test 1 plurals\"])\n# This will add a message with msgid \"A test without context\" and msgid_plural \"plurals\".\nmsgids_context_plural.append([\"A test without context\", \"\", \"plurals\"])\n# This will add a message with msgid \"Only with context\" and msgctxt \"a friendly context\".\nmsgids_context_plural.append([\"Only with context\", \"a friendly context\", \"\"])\n</code>\n```csharp\n// This will add a message with msgid \"Test 1\", msgctxt \"context\", and msgid_plural \"test 1 plurals\".\nmsgidsContextPlural.Add(new Godot.Collections.Array{\"Test 1\", \"context\", \"test 1 Plurals\"});\n// This will add a message with msgid \"A test without context\" and msgid_plural \"plurals\".\nmsgidsContextPlural.Add(new Godot.Collections.Array{\"A test without context\", \"\", \"plurals\"});\n// This will add a message with msgid \"Only with context\" and msgctxt \"a friendly context\".\nmsgidsContextPlural.Add(new Godot.Collections.Array{\"Only with context\", \"a friendly context\", \"\"});\n```\n<!-- </codeblocks> -->\n<b>Note:</b> If you override parsing logic for standard script types (GDScript, C#, etc.), it would be better to load the <code>path</code> argument using <a href=\"../ResourceLoader#load\">ResourceLoader.load<a>. This is because built-in scripts are loaded as [Resource](../Resource) type, not [FileAccess](../FileAccess) type.\nFor example:\n<!-- <codeblocks> -->\n<code>\nfunc _parse_file(path, msgids, msgids_context_plural):\n\tvar res = ResourceLoader.load(path, \"Script\")\n\tvar text = res.source_code\n\t# Parsing logic.\n\nfunc _get_recognized_extensions():\n\treturn [\"gd\"]\n</code>\n```csharp\npublic override void _ParseFile(string path, Godot.Collections.Array<string> msgids, Godot.Collections.Array<Godot.Collections.Array> msgidsContextPlural)\n{\n\tvar res = ResourceLoader.Load<Script>(path, \"Script\");\n\tstring text = res.SourceCode;\n\t// Parsing logic.\n}\n\npublic override string[] _GetRecognizedExtensions()\n{\n\treturn new string[] { \"gd\" };\n}\n```\n<!-- </codeblocks> -->\nTo use [EditorTranslationParserPlugin](../EditorTranslationParserPlugin), register it using the <a href=\"../EditorPlugin#add_translation_parser_plugin\">EditorPlugin.add_translation_parser_plugin<a> method first."
	},
	"EditorSyntaxHighlighter": {
		"brief_description": "Base Syntax highlighter resource for the [ScriptEditor](../ScriptEditor).",
		"description": "Base syntax highlighter resource all editor syntax highlighters extend from, it is used in the [ScriptEditor](../ScriptEditor).\nAdd a syntax highlighter to an individual script by calling <a href=\"../ScriptEditorBase#add_syntax_highlighter\">ScriptEditorBase.add_syntax_highlighter<a>. To apply to all scripts on open, call <a href=\"../ScriptEditor#register_syntax_highlighter\">ScriptEditor.register_syntax_highlighter<a>"
	},
	"EditorSpinSlider": {
		"brief_description": "Godot editor's control for editing numeric values.",
		"description": "This [Control](../Control) node is used in the editor's Inspector dock to allow editing of numeric values. Can be used with [EditorInspectorPlugin](../EditorInspectorPlugin) to recreate the same behavior."
	},
	"EditorSettings": {
		"brief_description": "Object that holds the project-independent editor settings.",
		"description": "Object that holds the project-independent editor settings. These settings are generally visible in the <b>Editor > Editor Settings</b> menu.\nProperty names use slash delimiters to distinguish sections. Setting values can be of any [Variant](../Variant) type. It's recommended to use <code>snake_case</code> for editor settings to be consistent with the Godot editor itself.\nAccessing the settings can be done using the following methods, such as:\n<!-- <codeblocks> -->\n<code>\nvar settings = EditorInterface.get_editor_settings()\n# `settings.set(\"some/property\", 10)` also works as this class overrides `_set()` internally.\nsettings.set_setting(\"some/property\", 10)\n# `settings.get(\"some/property\")` also works as this class overrides `_get()` internally.\nsettings.get_setting(\"some/property\")\nvar list_of_settings = settings.get_property_list()\n</code>\n```csharp\nEditorSettings settings = GetEditorInterface().GetEditorSettings();\n// `settings.set(\"some/property\", value)` also works as this class overrides `_set()` internally.\nsettings.SetSetting(\"some/property\", Value);\n// `settings.get(\"some/property\", value)` also works as this class overrides `_get()` internally.\nsettings.GetSetting(\"some/property\");\nGodot.Collections.Array<Godot.Collections.Dictionary> listOfSettings = settings.GetPropertyList();\n```\n<!-- </codeblocks> -->\n<b>Note:</b> This class shouldn't be instantiated directly. Instead, access the singleton using <a href=\"../EditorInterface#get_editor_settings\">EditorInterface.get_editor_settings<a>."
	},
	"EditorSelection": {
		"brief_description": "Manages the SceneTree selection in the editor.",
		"description": "This object manages the SceneTree selection in the editor.\n<b>Note:</b> This class shouldn't be instantiated directly. Instead, access the singleton using <a href=\"../EditorInterface#get_selection\">EditorInterface.get_selection<a>."
	},
	"EditorScriptPicker": {
		"brief_description": "Godot editor's control for selecting the <code>script</code> property of a [Node](../Node).",
		"description": "Similar to [EditorResourcePicker](../EditorResourcePicker) this [Control](../Control) node is used in the editor's Inspector dock, but only to edit the <code>script</code> property of a [Node](../Node). Default options for creating new resources of all possible subtypes are replaced with dedicated buttons that open the \"Attach Node Script\" dialog. Can be used with [EditorInspectorPlugin](../EditorInspectorPlugin) to recreate the same behavior.\n<b>Note:</b> You must set the <a href=\"#script_owner\">script_owner</a> for the custom context menu items to work."
	},
	"EditorScript": {
		"brief_description": "Base script that can be used to add extension functions to the editor.",
		"description": "Scripts extending this class and implementing its <a href=\"#_run\">_run</a> method can be executed from the Script Editor's <b>File > Run</b> menu option (or by pressing <kbd>Ctrl + Shift + X</kbd>) while the editor is running. This is useful for adding custom in-editor functionality to Godot. For more complex additions, consider using [EditorPlugin](../EditorPlugin)s instead.\n<b>Note:</b> Extending scripts need to have <code>tool</code> mode enabled.\n<b>Example script:</b>\n<!-- <codeblocks> -->\n<code>\n@tool\nextends EditorScript\n\nfunc _run():\n\tprint(\"Hello from the Godot Editor!\")\n</code>\n```csharp\nusing Godot;\n\n[Tool](../Tool)\npublic partial class HelloEditor : EditorScript\n{\n\tpublic override void _Run()\n\t{\n\t\tGD.Print(\"Hello from the Godot Editor!\");\n\t}\n}\n```\n<!-- </codeblocks> -->\n<b>Note:</b> The script is run in the Editor context, which means the output is visible in the console window started with the Editor (stdout) instead of the usual Godot <b>Output</b> dock.\n<b>Note:</b> EditorScript is [RefCounted](../RefCounted), meaning it is destroyed when nothing references it. This can cause errors during asynchronous operations if there are no references to the script."
	},
	"EditorScenePostImportPlugin": {
		"brief_description": "Plugin to control and modifying the process of importing a scene.",
		"description": "This plugin type exists to modify the process of importing scenes, allowing to change the content as well as add importer options at every stage of the process."
	},
	"EditorScenePostImport": {
		"brief_description": "Post-processes scenes after import.",
		"description": "Imported scenes can be automatically modified right after import by setting their <b>Custom Script</b> Import property to a <code>tool</code> script that inherits from this class.\nThe <a href=\"#_post_import\">_post_import</a> callback receives the imported scene's root node and returns the modified version of the scene. Usage example:\n<!-- <codeblocks> -->\n<code>\n@tool # Needed so it runs in editor.\nextends EditorScenePostImport\n\n# This sample changes all node names.\n# Called right after the scene is imported and gets the root node.\nfunc _post_import(scene):\n\t# Change all node names to \"modified_[oldnodename](../oldnodename)\"\n\titerate(scene)\n\treturn scene # Remember to return the imported scene\n\nfunc iterate(node):\n\tif node != null:\n\t\tnode.name = \"modified_\" + node.name\n\t\tfor child in node.get_children():\n\t\t\titerate(child)\n</code>\n```csharp\nusing Godot;\n\n// This sample changes all node names.\n// Called right after the scene is imported and gets the root node.\n[Tool](../Tool)\npublic partial class NodeRenamer : EditorScenePostImport\n{\n\tpublic override GodotObject _PostImport(Node scene)\n\t{\n\t\t// Change all node names to \"modified_[oldnodename](../oldnodename)\"\n\t\tIterate(scene);\n\t\treturn scene; // Remember to return the imported scene\n\t}\n\n\tpublic void Iterate(Node node)\n\t{\n\t\tif (node != null)\n\t\t{\n\t\t\tnode.Name = $\"modified_{node.Name}\";\n\t\t\tforeach (Node child in node.GetChildren())\n\t\t\t{\n\t\t\t\tIterate(child);\n\t\t\t}\n\t\t}\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"EditorSceneFormatImporter": {
		"brief_description": "Imports scenes from third-parties' 3D files.",
		"description": "[EditorSceneFormatImporter](../EditorSceneFormatImporter) allows to define an importer script for a third-party 3D format.\nTo use [EditorSceneFormatImporter](../EditorSceneFormatImporter), register it using the <a href=\"../EditorPlugin#add_scene_format_importer_plugin\">EditorPlugin.add_scene_format_importer_plugin<a> method first."
	},
	"EditorResourcePreviewGenerator": {
		"brief_description": "Custom generator of previews.",
		"description": "Custom code to generate previews. Please check <code>file_dialog/thumbnail_size</code> in [EditorSettings](../EditorSettings) to find out the right size to do previews at."
	},
	"EditorResourcePreview": {
		"brief_description": "Helper to generate previews of resources or files.",
		"description": "This object is used to generate previews for resources of files.\n<b>Note:</b> This class shouldn't be instantiated directly. Instead, access the singleton using <a href=\"../EditorInterface#get_resource_previewer\">EditorInterface.get_resource_previewer<a>."
	},
	"EditorResourcePicker": {
		"brief_description": "Godot editor's control for selecting [Resource](../Resource) type properties.",
		"description": "This [Control](../Control) node is used in the editor's Inspector dock to allow editing of [Resource](../Resource) type properties. It provides options for creating, loading, saving and converting resources. Can be used with [EditorInspectorPlugin](../EditorInspectorPlugin) to recreate the same behavior.\n<b>Note:</b> This [Control](../Control) does not include any editor for the resource, as editing is controlled by the Inspector dock itself or sub-Inspectors."
	},
	"EditorResourceConversionPlugin": {
		"brief_description": "Plugin for adding custom converters from one resource format to another in the editor resource picker context menu; for example, converting a [StandardMaterial3D](../StandardMaterial3D) to a [ShaderMaterial](../ShaderMaterial).",
		"description": "[EditorResourceConversionPlugin](../EditorResourceConversionPlugin) is invoked when the context menu is brought up for a resource in the editor inspector. Relevant conversion plugins will appear as menu options to convert the given resource to a target type.\nBelow shows an example of a basic plugin that will convert an [ImageTexture](../ImageTexture) to a [PortableCompressedTexture2D](../PortableCompressedTexture2D).\n<!-- <codeblocks> -->\n<code>\nextends EditorResourceConversionPlugin\n\nfunc _handles(resource: Resource):\n\treturn resource is ImageTexture\n\nfunc _converts_to():\n\treturn \"PortableCompressedTexture2D\"\n\nfunc _convert(itex: Resource):\n\tvar ptex = PortableCompressedTexture2D.new()\n\tptex.create_from_image(itex.get_image(), PortableCompressedTexture2D.COMPRESSION_MODE_LOSSLESS)\n\treturn ptex\n</code>\n<!-- </codeblocks> -->\nTo use an [EditorResourceConversionPlugin](../EditorResourceConversionPlugin), register it using the <a href=\"../EditorPlugin#add_resource_conversion_plugin\">EditorPlugin.add_resource_conversion_plugin<a> method first."
	},
	"EditorProperty": {
		"brief_description": "Custom control to edit properties for adding into the inspector.",
		"description": "This control allows property editing for one or multiple properties into [EditorInspector](../EditorInspector). It is added via [EditorInspectorPlugin](../EditorInspectorPlugin)."
	},
	"EditorPlugin": {
		"brief_description": "Used by the editor to extend its functionality.",
		"description": "Plugins are used by the editor to extend functionality. The most common types of plugins are those which edit a given node or resource type, import plugins and export plugins. See also [EditorScript](../EditorScript) to add functions to the editor."
	},
	"EditorPaths": {
		"brief_description": "Editor-only singleton that returns paths to various OS-specific data folders and files.",
		"description": "This editor-only singleton returns OS-specific paths to various data folders and files. It can be used in editor plugins to ensure files are saved in the correct location on each operating system.\n<b>Note:</b> This singleton is not accessible in exported projects. Attempting to access it in an exported project will result in a script error as the singleton won't be declared. To prevent script errors in exported projects, use <a href=\"../Engine#has_singleton\">Engine.has_singleton<a> to check whether the singleton is available before using it.\n<b>Note:</b> On the Linux/BSD platform, Godot complies with the [XDG Base Directory Specification](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html). You can override environment variables following the specification to change the editor and project data paths."
	},
	"EditorNode3DGizmoPlugin": {
		"brief_description": "Used by the editor to define Node3D gizmo types.",
		"description": "[EditorNode3DGizmoPlugin](../EditorNode3DGizmoPlugin) allows you to define a new type of Gizmo. There are two main ways to do so: extending [EditorNode3DGizmoPlugin](../EditorNode3DGizmoPlugin) for the simpler gizmos, or creating a new [EditorNode3DGizmo](../EditorNode3DGizmo) type. See the tutorial in the documentation for more info.\nTo use [EditorNode3DGizmoPlugin](../EditorNode3DGizmoPlugin), register it using the <a href=\"../EditorPlugin#add_node_3d_gizmo_plugin\">EditorPlugin.add_node_3d_gizmo_plugin<a> method first."
	},
	"EditorNode3DGizmo": {
		"brief_description": "Gizmo for editing Node3D objects.",
		"description": "Gizmo that is used for providing custom visualization and editing (handles and subgizmos) for Node3D objects. Can be overridden to create custom gizmos, but for simple gizmos creating a [EditorNode3DGizmoPlugin](../EditorNode3DGizmoPlugin) is usually recommended."
	},
	"EditorInterface": {
		"brief_description": "Godot editor's interface.",
		"description": "EditorInterface gives you control over Godot editor's window. It allows customizing the window, saving and (re-)loading scenes, rendering mesh previews, inspecting and editing resources and objects, and provides access to [EditorSettings](../EditorSettings), [EditorFileSystem](../EditorFileSystem), [EditorResourcePreview](../EditorResourcePreview), [ScriptEditor](../ScriptEditor), the editor viewport, and information about scenes.\n<b>Note:</b> This class shouldn't be instantiated directly. Instead, access the singleton using <a href=\"../EditorPlugin#get_editor_interface\">EditorPlugin.get_editor_interface<a>."
	},
	"EditorInspectorPlugin": {
		"brief_description": "Plugin for adding custom property editors on the inspector.",
		"description": "[EditorInspectorPlugin](../EditorInspectorPlugin) allows adding custom property editors to [EditorInspector](../EditorInspector).\nWhen an object is edited, the <a href=\"#_can_handle\">_can_handle</a> function is called and must return <code>true</code> if the object type is supported.\nIf supported, the function <a href=\"#_parse_begin\">_parse_begin</a> will be called, allowing to place custom controls at the beginning of the class.\nSubsequently, the <a href=\"#_parse_category\">_parse_category</a> and <a href=\"#_parse_property\">_parse_property</a> are called for every category and property. They offer the ability to add custom controls to the inspector too.\nFinally, <a href=\"#_parse_end\">_parse_end</a> will be called.\nOn each of these calls, the \"add\" functions can be called.\nTo use [EditorInspectorPlugin](../EditorInspectorPlugin), register it using the <a href=\"../EditorPlugin#add_inspector_plugin\">EditorPlugin.add_inspector_plugin<a> method first."
	},
	"EditorInspector": {
		"brief_description": "A control used to edit properties of an object.",
		"description": "This is the control that implements property editing in the editor's Settings dialogs, the Inspector dock, etc. To get the [EditorInspector](../EditorInspector) used in the editor's Inspector dock, use <a href=\"../EditorInterface#get_inspector\">EditorInterface.get_inspector<a>.\n[EditorInspector](../EditorInspector) will show properties in the same order as the array returned by <a href=\"../Object#get_property_list\">Object.get_property_list<a>.\nIf a property's name is path-like (i.e. if it contains forward slashes), [EditorInspector](../EditorInspector) will create nested sections for \"directories\" along the path. For example, if a property is named <code>highlighting/gdscript/node_path_color</code>, it will be shown as \"Node Path Color\" inside the \"GDScript\" section nested inside the \"Highlighting\" section.\nIf a property has <a href=\"#PROPERTY_USAGE_GROUP\">PROPERTY_USAGE_GROUP</a> usage, it will group subsequent properties whose name starts with the property's hint string. The group ends when a property does not start with that hint string or when a new group starts. An empty group name effectively ends the current group. [EditorInspector](../EditorInspector) will create a top-level section for each group. For example, if a property with group usage is named <code>Collide With</code> and its hint string is <code>collide_with_</code>, a subsequent <code>collide_with_area</code> property will be shown as \"Area\" inside the \"Collide With\" section. There is also a special case: when the hint string contains the name of a property, that property is grouped too. This is mainly to help grouping properties like <code>font</code>, <code>font_color</code> and <code>font_size</code> (using the hint string <code>font_</code>).\nIf a property has <a href=\"#PROPERTY_USAGE_SUBGROUP\">PROPERTY_USAGE_SUBGROUP</a> usage, a subgroup will be created in the same way as a group, and a second-level section will be created for each subgroup.\n<b>Note:</b> Unlike sections created from path-like property names, [EditorInspector](../EditorInspector) won't capitalize the name for sections created from groups. So properties with group usage usually use capitalized names instead of snake_cased names."
	},
	"EditorImportPlugin": {
		"brief_description": "Registers a custom resource importer in the editor. Use the class to parse any file and import it as a new resource type.",
		"description": "[EditorImportPlugin](../EditorImportPlugin)s provide a way to extend the editor's resource import functionality. Use them to import resources from custom files or to provide alternatives to the editor's existing importers.\nEditorImportPlugins work by associating with specific file extensions and a resource type. See <a href=\"#_get_recognized_extensions\">_get_recognized_extensions</a> and <a href=\"#_get_resource_type\">_get_resource_type</a>. They may optionally specify some import presets that affect the import process. EditorImportPlugins are responsible for creating the resources and saving them in the <code>.godot/imported</code> directory (see [member ProjectSettings.application/config/use_hidden_project_data_directory]).\nBelow is an example EditorImportPlugin that imports a [Mesh](../Mesh) from a file with the extension \".special\" or \".spec\":\n<!-- <codeblocks> -->\n<code>\n@tool\nextends EditorImportPlugin\n\nfunc _get_importer_name():\n\treturn \"my.special.plugin\"\n\nfunc _get_visible_name():\n\treturn \"Special Mesh\"\n\nfunc _get_recognized_extensions():\n\treturn [\"special\", \"spec\"]\n\nfunc _get_save_extension():\n\treturn \"mesh\"\n\nfunc _get_resource_type():\n\treturn \"Mesh\"\n\nfunc _get_preset_count():\n\treturn 1\n\nfunc _get_preset_name(i):\n\treturn \"Default\"\n\nfunc _get_import_options(i):\n\treturn [{\"name\": \"my_option\", \"default_value\": false}]\n\nfunc _import(source_file, save_path, options, platform_variants, gen_files):\n\tvar file = FileAccess.open(source_file, FileAccess.READ)\n\tif file == null:\n\t\treturn FAILED\n\tvar mesh = ArrayMesh.new()\n\t# Fill the Mesh with data read in \"file\", left as an exercise to the reader.\n\n\tvar filename = save_path + \".\" + _get_save_extension()\n\treturn ResourceSaver.save(mesh, filename)\n</code>\n```csharp\nusing Godot;\n\npublic partial class MySpecialPlugin : EditorImportPlugin\n{\n\tpublic override string _GetImporterName()\n\t{\n\t\treturn \"my.special.plugin\";\n\t}\n\n\tpublic override string _GetVisibleName()\n\t{\n\t\treturn \"Special Mesh\";\n\t}\n\n\tpublic override string[] _GetRecognizedExtensions()\n\t{\n\t\treturn new string[] { \"special\", \"spec\" };\n\t}\n\n\tpublic override string _GetSaveExtension()\n\t{\n\t\treturn \"mesh\";\n\t}\n\n\tpublic override string _GetResourceType()\n\t{\n\t\treturn \"Mesh\";\n\t}\n\n\tpublic override int _GetPresetCount()\n\t{\n\t\treturn 1;\n\t}\n\n\tpublic override string _GetPresetName(int presetIndex)\n\t{\n\t\treturn \"Default\";\n\t}\n\n\tpublic override Godot.Collections.Array<Godot.Collections.Dictionary> _GetImportOptions(string path, int presetIndex)\n\t{\n\t\treturn new Godot.Collections.Array<Godot.Collections.Dictionary>\n\t\t{\n\t\t\tnew Godot.Collections.Dictionary\n\t\t\t{\n\t\t\t\t{ \"name\", \"myOption\" },\n\t\t\t\t{ \"defaultValue\", false },\n\t\t\t}\n\t\t};\n\t}\n\n\tpublic override int _Import(string sourceFile, string savePath, Godot.Collections.Dictionary options, Godot.Collections.Array<string> platformVariants, Godot.Collections.Array<string> genFiles)\n\t{\n\t\tusing var file = FileAccess.Open(sourceFile, FileAccess.ModeFlags.Read);\n\t\tif (file.GetError() != Error.Ok)\n\t\t{\n\t\t\treturn (int)Error.Failed;\n\t\t}\n\n\t\tvar mesh = new ArrayMesh();\n\t\t// Fill the Mesh with data read in \"file\", left as an exercise to the reader.\n\t\tstring filename = $\"{savePath}.{_GetSaveExtension()}\";\n\t\treturn (int)ResourceSaver.Save(mesh, filename);\n\t}\n}\n```\n<!-- </codeblocks> -->\nTo use [EditorImportPlugin](../EditorImportPlugin), register it using the <a href=\"../EditorPlugin#add_import_plugin\">EditorPlugin.add_import_plugin<a> method first."
	},
	"EditorFileSystemImportFormatSupportQuery": {
		"brief_description": "Used to query and configure import format support.",
		"description": "This class is used to query and configure a certain import format. It is used in conjunction with asset format import plugins."
	},
	"EditorFileSystemDirectory": {
		"brief_description": "A directory for the resource filesystem.",
		"description": "A more generalized, low-level variation of the directory concept."
	},
	"EditorFileSystem": {
		"brief_description": "Resource filesystem, as the editor sees it.",
		"description": "This object holds information of all resources in the filesystem, their types, etc.\n<b>Note:</b> This class shouldn't be instantiated directly. Instead, access the singleton using <a href=\"../EditorInterface#get_resource_filesystem\">EditorInterface.get_resource_filesystem<a>."
	},
	"EditorFileDialog": {
		"brief_description": "A modified version of [FileDialog](../FileDialog) used by the editor.",
		"description": "[EditorFileDialog](../EditorFileDialog) is an enhanced version of [FileDialog](../FileDialog) available only to editor plugins. Additional features include list of favorited/recent files and ability to see files as thumbnails grid instead of list."
	},
	"EditorFeatureProfile": {
		"brief_description": "An editor feature profile which can be used to disable specific features.",
		"description": "An editor feature profile can be used to disable specific features of the Godot editor. When disabled, the features won't appear in the editor, which makes the editor less cluttered. This is useful in education settings to reduce confusion or when working in a team. For example, artists and level designers could use a feature profile that disables the script editor to avoid accidentally making changes to files they aren't supposed to edit.\nTo manage editor feature profiles visually, use <b>Editor > Manage Feature Profiles...</b> at the top of the editor window."
	},
	"EditorExportPlugin": {
		"brief_description": "A script that is executed when exporting the project.",
		"description": "[EditorExportPlugin](../EditorExportPlugin)s are automatically invoked whenever the user exports the project. Their most common use is to determine what files are being included in the exported project. For each plugin, <a href=\"#_export_begin\">_export_begin</a> is called at the beginning of the export process and then <a href=\"#_export_file\">_export_file</a> is called for each exported file.\nTo use [EditorExportPlugin](../EditorExportPlugin), register it using the <a href=\"../EditorPlugin#add_export_plugin\">EditorPlugin.add_export_plugin<a> method first."
	},
	"EditorExportPlatform": {
		"brief_description": "Identifies a supported export platform, and internally provides the functionality of exporting to that platform.",
		"description": "Base resource that provides the functionality of exporting a release build of a project to a platform, from the editor. Stores platform-specific metadata such as the name and supported features of the platform, and performs the exporting of projects, PCK files, and ZIP files. Uses an export template for the platform provided at the time of project exporting.\nUsed in scripting by [EditorExportPlugin](../EditorExportPlugin) to configure platform-specific customization of scenes and resources. See <a href=\"../EditorExportPlugin#_begin_customize_scenes\">EditorExportPlugin._begin_customize_scenes<a> and <a href=\"../EditorExportPlugin#_begin_customize_resources\">EditorExportPlugin._begin_customize_resources<a> for more details."
	},
	"EditorDebuggerSession": {
		"brief_description": "A class to interact with the editor debugger.",
		"description": "This class cannot be directly instantiated and must be retrieved via a [EditorDebuggerPlugin](../EditorDebuggerPlugin).\nYou can add tabs to the session UI via <a href=\"#add_session_tab\">add_session_tab</a>, send messages via <a href=\"#send_message\">send_message</a>, and toggle [EngineProfiler](../EngineProfiler)s via <a href=\"#toggle_profiler\">toggle_profiler</a>."
	},
	"EditorDebuggerPlugin": {
		"brief_description": "A base class to implement debugger plugins.",
		"description": "[EditorDebuggerPlugin](../EditorDebuggerPlugin) provides functions related to the editor side of the debugger.\nTo interact with the debugger, an instance of this class must be added to the editor via <a href=\"../EditorPlugin#add_debugger_plugin\">EditorPlugin.add_debugger_plugin<a>.\nOnce added, the <a href=\"#_setup_session\">_setup_session</a> callback will be called for every [EditorDebuggerSession](../EditorDebuggerSession) available to the plugin, and when new ones are created (the sessions may be inactive during this stage).\nYou can retrieve the available [EditorDebuggerSession](../EditorDebuggerSession)s via <a href=\"#get_sessions\">get_sessions</a> or get a specific one via <a href=\"#get_session\">get_session</a>.\n<!-- <codeblocks> -->\n<code>\n@tool\nextends EditorPlugin\n\nclass ExampleEditorDebugger extends EditorDebuggerPlugin:\n\n\tfunc _has_capture(prefix):\n\t\t# Return true if you wish to handle message with this prefix.\n\t\treturn prefix == \"my_plugin\"\n\n\tfunc _capture(message, data, session_id):\n\t\tif message == \"my_plugin:ping\":\n\t\t\tget_session(session_id).send_message(\"my_plugin:echo\", data)\n\n\tfunc _setup_session(session_id):\n\t\t# Add a new tab in the debugger session UI containing a label.\n\t\tvar label = Label.new()\n\t\tlabel.name = \"Example plugin\"\n\t\tlabel.text = \"Example plugin\"\n\t\tvar session = get_session(session_id)\n\t\t# Listens to the session started and stopped signals.\n\t\tsession.started.connect(func (): print(\"Session started\"))\n\t\tsession.stopped.connect(func (): print(\"Session stopped\"))\n\t\tsession.add_session_tab(label)\n\nvar debugger = ExampleEditorDebugger.new()\n\nfunc _enter_tree():\n\tadd_debugger_plugin(debugger)\n\nfunc _exit_tree():\n\tremove_debugger_plugin(debugger)\n</code>\n<!-- </codeblocks> -->"
	},
	"EditorCommandPalette": {
		"brief_description": "Godot editor's command palette.",
		"description": "Object that holds all the available Commands and their shortcuts text. These Commands can be accessed through <b>Editor > Command Palette</b> menu.\nCommand key names use slash delimiters to distinguish sections, for example: <code>\"example/command1\"</code> then <code>example</code> will be the section name.\n<!-- <codeblocks> -->\n<code>\nvar command_palette = get_editor_interface().get_command_palette()\n# external_command is a function that will be called with the command is executed.\nvar command_callable = Callable(self, \"external_command\").bind(arguments)\ncommand_palette.add_command(\"command\", \"test/command\",command_callable)\n</code>\n```csharp\nEditorCommandPalette commandPalette = GetEditorInterface().GetCommandPalette();\n// ExternalCommand is a function that will be called with the command is executed.\nCallable commandCallable = new Callable(this, MethodName.ExternalCommand);\ncommandPalette.AddCommand(\"command\", \"test/command\", commandCallable)\n```\n<!-- </codeblocks> -->\n<b>Note:</b> This class shouldn't be instantiated directly. Instead, access the singleton using <a href=\"../EditorInterface#get_command_palette\">EditorInterface.get_command_palette<a>."
	},
	"DTLSServer": {
		"brief_description": "Helper class to implement a DTLS server.",
		"description": "This class is used to store the state of a DTLS server. Upon <a href=\"#setup\">setup</a> it converts connected [PacketPeerUDP](../PacketPeerUDP) to [PacketPeerDTLS](../PacketPeerDTLS) accepting them via <a href=\"#take_connection\">take_connection</a> as DTLS clients. Under the hood, this class is used to store the DTLS state and cookies of the server. The reason of why the state and cookies are needed is outside of the scope of this documentation.\nBelow a small example of how to use it:\n<!-- <codeblocks> -->\n<code>\n# server_node.gd\nextends Node\n\nvar dtls := DTLSServer.new()\nvar server := UDPServer.new()\nvar peers = []\n\nfunc _ready():\n\tserver.listen(4242)\n\tvar key = load(\"key.key\") # Your private key.\n\tvar cert = load(\"cert.crt\") # Your X509 certificate.\n\tdtls.setup(key, cert)\n\nfunc _process(delta):\n\twhile server.is_connection_available():\n\t\tvar peer: PacketPeerUDP = server.take_connection()\n\t\tvar dtls_peer: PacketPeerDTLS = dtls.take_connection(peer)\n\t\tif dtls_peer.get_status() != PacketPeerDTLS.STATUS_HANDSHAKING:\n\t\t\tcontinue # It is normal that 50% of the connections fails due to cookie exchange.\n\t\tprint(\"Peer connected!\")\n\t\tpeers.append(dtls_peer)\n\n\tfor p in peers:\n\t\tp.poll() # Must poll to update the state.\n\t\tif p.get_status() == PacketPeerDTLS.STATUS_CONNECTED:\n\t\t\twhile p.get_available_packet_count() > 0:\n\t\t\t\tprint(\"Received message from client: %s\" % p.get_packet().get_string_from_utf8())\n\t\t\t\tp.put_packet(\"Hello DTLS client\".to_utf8())\n</code>\n```csharp\n// ServerNode.cs\nusing Godot;\n\npublic partial class ServerNode : Node\n{\n\tprivate DtlsServer _dtls = new DtlsServer();\n\tprivate UdpServer _server = new UdpServer();\n\tprivate Godot.Collections.Array<PacketPeerDTLS> _peers = new Godot.Collections.Array<PacketPeerDTLS>();\n\n\tpublic override void _Ready()\n\t{\n\t\t_server.Listen(4242);\n\t\tvar key = GD.Load<CryptoKey>(\"key.key\"); // Your private key.\n\t\tvar cert = GD.Load<X509Certificate>(\"cert.crt\"); // Your X509 certificate.\n\t\t_dtls.Setup(key, cert);\n\t}\n\n\tpublic override void _Process(double delta)\n\t{\n\t\twhile (Server.IsConnectionAvailable())\n\t\t{\n\t\t\tPacketPeerUDP peer = _server.TakeConnection();\n\t\t\tPacketPeerDTLS dtlsPeer = _dtls.TakeConnection(peer);\n\t\t\tif (dtlsPeer.GetStatus() != PacketPeerDtls.Status.Handshaking)\n\t\t\t{\n\t\t\t\tcontinue; // It is normal that 50% of the connections fails due to cookie exchange.\n\t\t\t}\n\t\t\tGD.Print(\"Peer connected!\");\n\t\t\t_peers.Add(dtlsPeer);\n\t\t}\n\n\t\tforeach (var p in _peers)\n\t\t{\n\t\t\tp.Poll(); // Must poll to update the state.\n\t\t\tif (p.GetStatus() == PacketPeerDtls.Status.Connected)\n\t\t\t{\n\t\t\t\twhile (p.GetAvailablePacketCount() > 0)\n\t\t\t\t{\n\t\t\t\t\tGD.Print($\"Received Message From Client: {p.GetPacket().GetStringFromUtf8()}\");\n\t\t\t\t\tp.PutPacket(\"Hello DTLS Client\".ToUtf8());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```\n<!-- </codeblocks> -->\n<!-- <codeblocks> -->\n<code>\n# client_node.gd\nextends Node\n\nvar dtls := PacketPeerDTLS.new()\nvar udp := PacketPeerUDP.new()\nvar connected = false\n\nfunc _ready():\n\tudp.connect_to_host(\"127.0.0.1\", 4242)\n\tdtls.connect_to_peer(udp, false) # Use true in production for certificate validation!\n\nfunc _process(delta):\n\tdtls.poll()\n\tif dtls.get_status() == PacketPeerDTLS.STATUS_CONNECTED:\n\t\tif !connected:\n\t\t\t# Try to contact server\n\t\t\tdtls.put_packet(\"The answer is... 42!\".to_utf8())\n\t\twhile dtls.get_available_packet_count() > 0:\n\t\t\tprint(\"Connected: %s\" % dtls.get_packet().get_string_from_utf8())\n\t\t\tconnected = true\n</code>\n```csharp\n// ClientNode.cs\nusing Godot;\nusing System.Text;\n\npublic partial class ClientNode : Node\n{\n\tprivate PacketPeerDtls _dtls = new PacketPeerDtls();\n\tprivate PacketPeerUdp _udp = new PacketPeerUdp();\n\tprivate bool _connected = false;\n\n\tpublic override void _Ready()\n\t{\n\t\t_udp.ConnectToHost(\"127.0.0.1\", 4242);\n\t\t_dtls.ConnectToPeer(_udp, validateCerts: false); // Use true in production for certificate validation!\n\t}\n\n\tpublic override void _Process(double delta)\n\t{\n\t\t_dtls.Poll();\n\t\tif (_dtls.GetStatus() == PacketPeerDtls.Status.Connected)\n\t\t{\n\t\t\tif (!_connected)\n\t\t\t{\n\t\t\t\t// Try to contact server\n\t\t\t\t_dtls.PutPacket(\"The Answer Is..42!\".ToUtf8());\n\t\t\t}\n\t\t\twhile (_dtls.GetAvailablePacketCount() > 0)\n\t\t\t{\n\t\t\t\tGD.Print($\"Connected: {_dtls.GetPacket().GetStringFromUtf8()}\");\n\t\t\t\t_connected = true;\n\t\t\t}\n\t\t}\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"DisplayServer": {
		"brief_description": "Singleton for window management functions.",
		"description": "[DisplayServer](../DisplayServer) handles everything related to window management. This is separated from [OS](../OS) as a single operating system may support multiple display servers.\n<b>Headless mode:</b> Starting the engine with the <code>--headless</code> [command line argument]($DOCS_URL/tutorials/editor/command_line_tutorial.html) disables all rendering and window management functions. Most functions from [DisplayServer](../DisplayServer) will return dummy values in this case."
	},
	"DirectionalLight3D": {
		"brief_description": "Directional light from a distance, as from the Sun.",
		"description": "A directional light is a type of [Light3D](../Light3D) node that models an infinite number of parallel rays covering the entire scene. It is used for lights with strong intensity that are located far away from the scene to model sunlight or moonlight. The worldspace location of the DirectionalLight3D transform (origin) is ignored. Only the basis is used to determine light direction."
	},
	"DirectionalLight2D": {
		"brief_description": "Directional 2D light from a distance.",
		"description": "A directional light is a type of [Light2D](../Light2D) node that models an infinite number of parallel rays covering the entire scene. It is used for lights with strong intensity that are located far away from the scene (for example: to model sunlight or moonlight).\n<b>Note:</b> [DirectionalLight2D](../DirectionalLight2D) does not support light cull masks (but it supports shadow cull masks). It will always light up 2D nodes, regardless of the 2D node's <a href=\"../CanvasItem#light_mask\">CanvasItem.light_mask<a>."
	},
	"DirAccess": {
		"brief_description": "Type used to handle the filesystem.",
		"description": "Directory type. It is used to manage directories and their content (not restricted to the project folder).\n[DirAccess](../DirAccess) can't be instantiated directly. Instead it is created with a static method that takes a path for which it will be opened.\nMost of the methods have a static alternative that can be used without creating a [DirAccess](../DirAccess). Static methods only support absolute paths (including <code>res://</code> and <code>user://</code>).\n<code>\n# Standard\nvar dir = DirAccess.open(\"user://levels\")\ndir.make_dir(\"world1\")\n# Static\nDirAccess.make_dir_absolute(\"user://levels/world1\")\n</code>\n<b>Note:</b> Many resources types are imported (e.g. textures or sound files), and their source asset will not be included in the exported game, as only the imported version is used. Use [ResourceLoader](../ResourceLoader) to access imported resources.\nHere is an example on how to iterate through the files of a directory:\n<!-- <codeblocks> -->\n<code>\nfunc dir_contents(path):\n\tvar dir = DirAccess.open(path)\n\tif dir:\n\t\tdir.list_dir_begin()\n\t\tvar file_name = dir.get_next()\n\t\twhile file_name != \"\":\n\t\t\tif dir.current_is_dir():\n\t\t\t\tprint(\"Found directory: \" + file_name)\n\t\t\telse:\n\t\t\t\tprint(\"Found file: \" + file_name)\n\t\t\tfile_name = dir.get_next()\n\telse:\n\t\tprint(\"An error occurred when trying to access the path.\")\n</code>\n```csharp\npublic void DirContents(string path)\n{\n\tusing var dir = DirAccess.Open(path);\n\tif (dir != null)\n\t{\n\t\tdir.ListDirBegin();\n\t\tstring fileName = dir.GetNext();\n\t\twhile (fileName != \"\")\n\t\t{\n\t\t\tif (dir.CurrentIsDir())\n\t\t\t{\n\t\t\t\tGD.Print($\"Found directory: {fileName}\");\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tGD.Print($\"Found file: {fileName}\");\n\t\t\t}\n\t\t\tfileName = dir.GetNext();\n\t\t}\n\t}\n\telse\n\t{\n\t\tGD.Print(\"An error occurred when trying to access the path.\");\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"Dictionary": {
		"brief_description": "Dictionary type.",
		"description": "Dictionary type. Associative container, which contains values referenced by unique keys. Dictionaries are composed of pairs of keys (which must be unique) and values. Dictionaries will preserve the insertion order when adding new entries. In other programming languages, this data structure is sometimes referred to as a hash map or associative array.\nYou can define a dictionary by placing a comma-separated list of <code>key: value</code> pairs in curly braces <code>{}</code>.\n<b>Note:</b> Dictionaries are always passed by reference. To get a copy of a dictionary which can be modified independently of the original dictionary, use <a href=\"#duplicate\">duplicate</a>.\nCreating a dictionary:\n<!-- <codeblocks> -->\n<code>\nvar my_dict = {} # Creates an empty dictionary.\n\nvar dict_variable_key = \"Another key name\"\nvar dict_variable_value = \"value2\"\nvar another_dict = {\n\t\"Some key name\": \"value1\",\n\tdict_variable_key: dict_variable_value,\n}\n\nvar points_dict = {\"White\": 50, \"Yellow\": 75, \"Orange\": 100}\n\n# Alternative Lua-style syntax.\n# Doesn't require quotes around keys, but only string constants can be used as key names.\n# Additionally, key names must start with a letter or an underscore.\n# Here, `some_key` is a string literal, not a variable!\nanother_dict = {\n\tsome_key = 42,\n}\n</code>\n```csharp\nvar myDict = new Godot.Collections.Dictionary(); // Creates an empty dictionary.\nvar pointsDict = new Godot.Collections.Dictionary\n{\n\t{\"White\", 50},\n\t{\"Yellow\", 75},\n\t{\"Orange\", 100}\n};\n```\n<!-- </codeblocks> -->\nYou can access a dictionary's value by referencing its corresponding key. In the above example, <code>points_dict[\"White\"]</code> will return <code>50</code>. You can also write <code>points_dict.White</code>, which is equivalent. However, you'll have to use the bracket syntax if the key you're accessing the dictionary with isn't a fixed string (such as a number or variable).\n<!-- <codeblocks> -->\n<code>\n@export_enum(\"White\", \"Yellow\", \"Orange\") var my_color: String\nvar points_dict = {\"White\": 50, \"Yellow\": 75, \"Orange\": 100}\nfunc _ready():\n\t# We can't use dot syntax here as `my_color` is a variable.\n\tvar points = points_dict[my_color](../my_color)\n</code>\n```csharp\n[Export(PropertyHint.Enum, \"White,Yellow,Orange\")]\npublic string MyColor { get; set; }\nprivate Godot.Collections.Dictionary _pointsDict = new Godot.Collections.Dictionary\n{\n\t{\"White\", 50},\n\t{\"Yellow\", 75},\n\t{\"Orange\", 100}\n};\n\npublic override void _Ready()\n{\n\tint points = (int)_pointsDict[MyColor](../MyColor);\n}\n```\n<!-- </codeblocks> -->\nIn the above code, <code>points</code> will be assigned the value that is paired with the appropriate color selected in <code>my_color</code>.\nDictionaries can contain more complex data:\n<!-- <codeblocks> -->\n<code>\nvar my_dict = {\n\t\"First Array\": [1, 2, 3, 4] # Assigns an Array to a String key.\n}\n</code>\n```csharp\nvar myDict = new Godot.Collections.Dictionary\n{\n\t{\"First Array\", new Godot.Collections.Array{1, 2, 3, 4}}\n};\n```\n<!-- </codeblocks> -->\nTo add a key to an existing dictionary, access it like an existing key and assign to it:\n<!-- <codeblocks> -->\n<code>\nvar points_dict = {\"White\": 50, \"Yellow\": 75, \"Orange\": 100}\npoints_dict[\"Blue\"] = 150 # Add \"Blue\" as a key and assign 150 as its value.\n</code>\n```csharp\nvar pointsDict = new Godot.Collections.Dictionary\n{\n\t{\"White\", 50},\n\t{\"Yellow\", 75},\n\t{\"Orange\", 100}\n};\npointsDict[\"Blue\"] = 150; // Add \"Blue\" as a key and assign 150 as its value.\n```\n<!-- </codeblocks> -->\nFinally, dictionaries can contain different types of keys and values in the same dictionary:\n<!-- <codeblocks> -->\n<code>\n# This is a valid dictionary.\n# To access the string \"Nested value\" below, use `my_dict.sub_dict.sub_key` or `my_dict[\"sub_dict\"][\"sub_key\"]`.\n# Indexing styles can be mixed and matched depending on your needs.\nvar my_dict = {\n\t\"String Key\": 5,\n\t4: [1, 2, 3],\n\t7: \"Hello\",\n\t\"sub_dict\": {\"sub_key\": \"Nested value\"},\n}\n</code>\n```csharp\n// This is a valid dictionary.\n// To access the string \"Nested value\" below, use `((Godot.Collections.Dictionary)myDict[\"sub_dict\"])[\"sub_key\"]`.\nvar myDict = new Godot.Collections.Dictionary {\n\t{\"String Key\", 5},\n\t{4, new Godot.Collections.Array{1,2,3}},\n\t{7, \"Hello\"},\n\t{\"sub_dict\", new Godot.Collections.Dictionary{{\"sub_key\", \"Nested value\"}}}\n};\n```\n<!-- </codeblocks> -->\nThe keys of a dictionary can be iterated with the <code>for</code> keyword:\n<!-- <codeblocks> -->\n<code>\nvar groceries = {\"Orange\": 20, \"Apple\": 2, \"Banana\": 4}\nfor fruit in groceries:\n\tvar amount = groceries[fruit](../fruit)\n</code>\n```csharp\nvar groceries = new Godot.Collections.Dictionary{{\"Orange\", 20}, {\"Apple\", 2}, {\"Banana\", 4}};\nforeach (var (fruit, amount) in groceries)\n{\n\t// `fruit` is the key, `amount` is the value.\n}\n```\n<!-- </codeblocks> -->\n<b>Note:</b> Erasing elements while iterating over dictionaries is <b>not</b> supported and will result in unpredictable behavior."
	},
	"Decal": {
		"brief_description": "Node that projects a texture onto a [MeshInstance3D](../MeshInstance3D).",
		"description": "[Decal](../Decal)s are used to project a texture onto a [Mesh](../Mesh) in the scene. Use Decals to add detail to a scene without affecting the underlying [Mesh](../Mesh). They are often used to add weathering to building, add dirt or mud to the ground, or add variety to props. Decals can be moved at any time, making them suitable for things like blob shadows or laser sight dots.\nThey are made of an [AABB](../AABB) and a group of [Texture2D](../Texture2D)s specifying [Color](../Color), normal, ORM (ambient occlusion, roughness, metallic), and emission. Decals are projected within their [AABB](../AABB) so altering the orientation of the Decal affects the direction in which they are projected. By default, Decals are projected down (i.e. from positive Y to negative Y).\nThe [Texture2D](../Texture2D)s associated with the Decal are automatically stored in a texture atlas which is used for drawing the decals so all decals can be drawn at once. Godot uses clustered decals, meaning they are stored in cluster data and drawn when the mesh is drawn, they are not drawn as a post-processing effect after.\n<b>Note:</b> Decals cannot affect an underlying material's transparency, regardless of its transparency mode (alpha blend, alpha scissor, alpha hash, opaque pre-pass). This means translucent or transparent areas of a material will remain translucent or transparent even if an opaque decal is applied on them.\n<b>Note:</b> Decals are only supported in the Forward+ and Mobile rendering methods, not Compatibility. When using the Mobile rendering method, only 8 decals can be displayed on each mesh resource. Attempting to display more than 8 decals on a single mesh resource will result in decals flickering in and out as the camera moves.\n<b>Note:</b> When using the Mobile rendering method, decals will only correctly affect meshes whose visibility AABB intersects with the decal's AABB. If using a shader to deform the mesh in a way that makes it go outside its AABB, <a href=\"../GeometryInstance3D#extra_cull_margin\">GeometryInstance3D.extra_cull_margin<a> must be increased on the mesh. Otherwise, the decal may not be visible on the mesh."
	},
	"DampedSpringJoint2D": {
		"brief_description": "Damped spring constraint for 2D physics.",
		"description": "Damped spring constraint for 2D physics. This resembles a spring joint that always wants to go back to a given length."
	},
	"CylinderShape3D": {
		"brief_description": "Cylinder shape for 3D collisions.",
		"description": "Cylinder shape for collisions. Like [CapsuleShape3D](../CapsuleShape3D), but without hemispheres at the cylinder's ends.\n<b>Note:</b> There are several known bugs with cylinder collision shapes. Using [CapsuleShape3D](../CapsuleShape3D) or [BoxShape3D](../BoxShape3D) instead is recommended.\n<b>Performance:</b> Being a primitive collision shape, [CylinderShape3D](../CylinderShape3D) is fast to check collisions against (though not as fast as [SphereShape3D](../SphereShape3D)). [CylinderShape3D](../CylinderShape3D) is also more demanding compared to [CapsuleShape3D](../CapsuleShape3D)."
	},
	"CylinderMesh": {
		"brief_description": "Class representing a cylindrical [PrimitiveMesh](../PrimitiveMesh).",
		"description": "Class representing a cylindrical [PrimitiveMesh](../PrimitiveMesh). This class can be used to create cones by setting either the <a href=\"#top_radius\">top_radius</a> or <a href=\"#bottom_radius\">bottom_radius</a> properties to <code>0.0</code>."
	},
	"CurveXYZTexture": {
		"brief_description": "A texture that shows 3 different curves (stored on the red, green and blue color channels).",
		"description": "Renders 3 given [Curve](../Curve)s provided to it, on the red, green and blue channels respectively. Compared to using separate [CurveTexture](../CurveTexture)s, this further simplifies the task of drawing curves and/or saving them as image files.\nIf you only need to store one curve within a single texture, use [CurveTexture](../CurveTexture) instead. See also [GradientTexture1D](../GradientTexture1D) and [GradientTexture2D](../GradientTexture2D)."
	},
	"CurveTexture": {
		"brief_description": "A texture that shows a curve.",
		"description": "Renders a given [Curve](../Curve) provided to it. Simplifies the task of drawing curves and/or saving them as image files.\nIf you need to store up to 3 curves within a single texture, use [CurveXYZTexture](../CurveXYZTexture) instead. See also [GradientTexture1D](../GradientTexture1D) and [GradientTexture2D](../GradientTexture2D)."
	},
	"Curve3D": {
		"brief_description": "Describes a Bzier curve in 3D space.",
		"description": "This class describes a Bzier curve in 3D space. It is mainly used to give a shape to a [Path3D](../Path3D), but can be manually sampled for other purposes.\nIt keeps a cache of precalculated points along the curve, to speed up further calculations."
	},
	"Curve2D": {
		"brief_description": "Describes a Bzier curve in 2D space.",
		"description": "This class describes a Bzier curve in 2D space. It is mainly used to give a shape to a [Path2D](../Path2D), but can be manually sampled for other purposes.\nIt keeps a cache of precalculated points along the curve, to speed up further calculations."
	},
	"Curve": {
		"brief_description": "A mathematic curve.",
		"description": "A curve that can be saved and re-used for other objects. By default, it ranges between <code>0</code> and <code>1</code> on the Y axis and positions points relative to the <code>0.5</code> Y position.\nSee also [Gradient](../Gradient) which is designed for color interpolation. See also [Curve2D](../Curve2D) and [Curve3D](../Curve3D)."
	},
	"CubemapArray": {
		"brief_description": "A single composite texture resource which consists of multiple [Cubemap](../Cubemap)s.",
		"description": "[CubemapArray](../CubemapArray)s are made of an array of [Cubemap](../Cubemap)s. Accordingly, like [Cubemap](../Cubemap)s they are made of multiple textures the amount of which must be divisible by 6 (one image for each face of the cube). The primary benefit of [CubemapArray](../CubemapArray)s is that they can be accessed in shader code using a single texture reference. In other words, you can pass multiple [Cubemap](../Cubemap)s into a shader using a single [CubemapArray](../CubemapArray).\nGenerally, [CubemapArray](../CubemapArray)s provide a more efficient way for storing multiple [Cubemap](../Cubemap)s compared to storing multiple [Cubemap](../Cubemap)s themselves in an array.\nInternally, Godot uses [CubemapArray](../CubemapArray)s for many effects including the [Sky](../Sky), if you set [member ProjectSettings.rendering/reflections/sky_reflections/texture_array_reflections] to <code>true</code>.\nTo create such a texture file yourself, reimport your image files using the Godot Editor import presets.\n<b>Note:</b> [CubemapArray](../CubemapArray) is not supported in the OpenGL 3 rendering backend."
	},
	"Cubemap": {
		"brief_description": "6-sided texture typically used in 3D rendering.",
		"description": "A cubemap is made of 6 textures organized in layers. They are typically used for faking reflections in 3D rendering (see [ReflectionProbe](../ReflectionProbe)). It can be used to make an object look as if it's reflecting its surroundings. This usually delivers much better performance than other reflection methods.\nThis resource is typically used as a uniform in custom shaders. Few core Godot methods make use of [Cubemap](../Cubemap) resources.\nTo create such a texture file yourself, reimport your image files using the Godot Editor import presets.\n<b>Note:</b> Godot doesn't support using cubemaps in a [PanoramaSkyMaterial](../PanoramaSkyMaterial). You can use [this tool](https://danilw.github.io/GLSL-howto/cubemap_to_panorama_js/cubemap_to_panorama.html) to convert a cubemap to an equirectangular sky map."
	},
	"CryptoKey": {
		"brief_description": "A cryptographic key (RSA).",
		"description": "The CryptoKey class represents a cryptographic key. Keys can be loaded and saved like any other [Resource](../Resource).\nThey can be used to generate a self-signed [X509Certificate](../X509Certificate) via <a href=\"../Crypto#generate_self_signed_certificate\">Crypto.generate_self_signed_certificate<a> and as private key in <a href=\"../StreamPeerTLS#accept_stream\">StreamPeerTLS.accept_stream<a> along with the appropriate certificate."
	},
	"Crypto": {
		"brief_description": "Access to advanced cryptographic functionalities.",
		"description": "The Crypto class allows you to access some more advanced cryptographic functionalities in Godot.\nFor now, this includes generating cryptographically secure random bytes, RSA keys and self-signed X509 certificates generation, asymmetric key encryption/decryption, and signing/verification.\n<!-- <codeblocks> -->\n<code>\nextends Node\n\nvar crypto = Crypto.new()\nvar key = CryptoKey.new()\nvar cert = X509Certificate.new()\n\nfunc _ready():\n\t# Generate new RSA key.\n\tkey = crypto.generate_rsa(4096)\n\t# Generate new self-signed certificate with the given key.\n\tcert = crypto.generate_self_signed_certificate(key, \"CN=mydomain.com,O=My Game Company,C=IT\")\n\t# Save key and certificate in the user folder.\n\tkey.save(\"user://generated.key\")\n\tcert.save(\"user://generated.crt\")\n\t# Encryption\n\tvar data = \"Some data\"\n\tvar encrypted = crypto.encrypt(key, data.to_utf8())\n\t# Decryption\n\tvar decrypted = crypto.decrypt(key, encrypted)\n\t# Signing\n\tvar signature = crypto.sign(HashingContext.HASH_SHA256, data.sha256_buffer(), key)\n\t# Verifying\n\tvar verified = crypto.verify(HashingContext.HASH_SHA256, data.sha256_buffer(), signature, key)\n\t# Checks\n\tassert(verified)\n\tassert(data.to_utf8() == decrypted)\n</code>\n```csharp\nusing Godot;\nusing System.Diagnostics;\n\npublic partial class MyNode : Node\n{\n\tprivate Crypto _crypto = new Crypto();\n\tprivate CryptoKey _key = new CryptoKey();\n\tprivate X509Certificate _cert = new X509Certificate();\n\n\tpublic override void _Ready()\n\t{\n\t\t// Generate new RSA key.\n\t\t_key = _crypto.GenerateRsa(4096);\n\t\t// Generate new self-signed certificate with the given key.\n\t\t_cert = _crypto.GenerateSelfSignedCertificate(_key, \"CN=mydomain.com,O=My Game Company,C=IT\");\n\t\t// Save key and certificate in the user folder.\n\t\t_key.Save(\"user://generated.key\");\n\t\t_cert.Save(\"user://generated.crt\");\n\t\t// Encryption\n\t\tstring data = \"Some data\";\n\t\tbyte[] encrypted = _crypto.Encrypt(_key, data.ToUtf8());\n\t\t// Decryption\n\t\tbyte[] decrypted = _crypto.Decrypt(_key, encrypted);\n\t\t// Signing\n\t\tbyte[] signature = _crypto.Sign(HashingContext.HashType.Sha256, Data.Sha256Buffer(), _key);\n\t\t// Verifying\n\t\tbool verified = _crypto.Verify(HashingContext.HashType.Sha256, Data.Sha256Buffer(), signature, _key);\n\t\t// Checks\n\t\tDebug.Assert(verified);\n\t\tDebug.Assert(data.ToUtf8() == decrypted);\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"CPUParticles3D": {
		"brief_description": "CPU-based 3D particle emitter.",
		"description": "CPU-based 3D particle node used to create a variety of particle systems and effects.\nSee also [GPUParticles3D](../GPUParticles3D), which provides the same functionality with hardware acceleration, but may not run on older devices."
	},
	"CPUParticles2D": {
		"brief_description": "CPU-based 2D particle emitter.",
		"description": "CPU-based 2D particle node used to create a variety of particle systems and effects.\nSee also [GPUParticles2D](../GPUParticles2D), which provides the same functionality with hardware acceleration, but may not run on older devices."
	},
	"ConvexPolygonShape3D": {
		"brief_description": "Convex polygon shape resource for 3D physics.",
		"description": "3D convex polygon shape resource to be added as a <i>direct</i> child of a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D) using a [CollisionShape3D](../CollisionShape3D) node.\nThe shape is a <i>solid</i> that includes all the points that it encloses, as opposed to [ConcavePolygonShape3D](../ConcavePolygonShape3D) which is hollow if it encloses anything. See also [CollisionPolygon3D](../CollisionPolygon3D).\nThe solid nature of the shape makes it well-suited for both detection and physics; in physics body interactions this allows depenetrating even those shapes which end up (e.g. due to high speed) fully inside the convex shape (similarly to primitive shapes, but unlike [ConcavePolygonShape3D](../ConcavePolygonShape3D) and [HeightMapShape3D](../HeightMapShape3D)). The convexity restricts the possible geometric shape of a single [ConvexPolygonShape3D](../ConvexPolygonShape3D): it cannot be concave.\n<b>Convex decomposition:</b> Concave objects' collisions can be represented accurately using <i>several</i> convex shapes. This allows dynamic physics bodies to have complex concave collisions (at a performance cost). It can be achieved by using several [ConvexPolygonShape3D](../ConvexPolygonShape3D) nodes or by using the [CollisionPolygon3D](../CollisionPolygon3D) node. To generate a collision polygon from a mesh, select the [MeshInstance3D](../MeshInstance3D) node, go to the <b>Mesh</b> menu that appears above the viewport and choose <b>Create Multiple Convex Collision Siblings</b>. Alternatively, <a href=\"../MeshInstance3D#create_multiple_convex_collisions\">MeshInstance3D.create_multiple_convex_collisions<a> can be called in a script to perform this decomposition at run-time.\n<b>Performance:</b> [ConvexPolygonShape3D](../ConvexPolygonShape3D) is faster to check collisions against compared to [ConcavePolygonShape3D](../ConcavePolygonShape3D), but it is slower than primitive collision shapes such as [SphereShape3D](../SphereShape3D) or [BoxShape3D](../BoxShape3D). Its use should generally be limited to medium-sized objects that cannot have their collision accurately represented by primitive shapes."
	},
	"ConvexPolygonShape2D": {
		"brief_description": "Convex polygon shape resource for 2D physics.",
		"description": "2D convex polygon shape to be added as a <i>direct</i> child of a [PhysicsBody2D](../PhysicsBody2D) or [Area2D](../Area2D) using a [CollisionShape2D](../CollisionShape2D) node.\nThe shape is a <i>solid</i> that includes all the points that it encloses, as opposed to [ConcavePolygonShape2D](../ConcavePolygonShape2D) which is hollow if it encloses anything. See also [CollisionPolygon2D](../CollisionPolygon2D).\nThe solid nature of the shape makes it well-suited for both detection and physics; in physics body interactions this allows depenetrating even those shapes which end up (e.g. due to high speed) fully inside the convex shape (similarly to primitive shapes, but unlike [ConcavePolygonShape2D](../ConcavePolygonShape2D)). The convexity limits the possible geometric shape of a single [ConvexPolygonShape2D](../ConvexPolygonShape2D): it cannot be concave.\n<b>Convex decomposition:</b> Concave objects' collisions can be represented accurately using <i>several</i> convex shapes. This allows dynamic physics bodies to have complex concave collisions (at a performance cost). It can be achieved using several [ConvexPolygonShape2D](../ConvexPolygonShape2D) nodes or by using the [CollisionPolygon2D](../CollisionPolygon2D) node in Solids build mode. To generate a collision polygon from a sprite, select the [Sprite2D](../Sprite2D) node, go to the <b>Sprite2D</b> menu that appears above the viewport, and choose <b>Create Polygon2D Sibling</b>.\n<b>Performance:</b> [ConvexPolygonShape2D](../ConvexPolygonShape2D) is faster to check collisions against compared to [ConcavePolygonShape2D](../ConcavePolygonShape2D), but it is slower than primitive collision shapes such as [CircleShape2D](../CircleShape2D) or [RectangleShape2D](../RectangleShape2D). Its use should generally be limited to medium-sized objects that cannot have their collision accurately represented by primitive shapes."
	},
	"Control": {
		"brief_description": "All user interface nodes inherit from Control. A control's anchors and offsets adapt its position and size relative to its parent.",
		"description": "Base class for all UI-related nodes. [Control](../Control) features a bounding rectangle that defines its extents, an anchor position relative to its parent control or the current viewport, and offsets relative to the anchor. The offsets update automatically when the node, any of its parents, or the screen size change.\nFor more information on Godot's UI system, anchors, offsets, and containers, see the related tutorials in the manual. To build flexible UIs, you'll need a mix of UI elements that inherit from [Control](../Control) and [Container](../Container) nodes.\n<b>User Interface nodes and input</b>\nGodot propagates input events via viewports. Each [Viewport](../Viewport) is responsible for propagating [InputEvent](../InputEvent)s to their child nodes. As the <a href=\"../SceneTree#root\">SceneTree.root<a> is a [Window](../Window), this already happens automatically for all UI elements in your game.\nInput events are propagated through the [SceneTree](../SceneTree) from the root node to all child nodes by calling <a href=\"../Node#_input\">Node._input<a>. For UI elements specifically, it makes more sense to override the virtual method <a href=\"#_gui_input\">_gui_input</a>, which filters out unrelated input events, such as by checking z-order, <a href=\"#mouse_filter\">mouse_filter</a>, focus, or if the event was inside of the control's bounding box.\nCall <a href=\"#accept_event\">accept_event</a> so no other node receives the event. Once you accept an input, it becomes handled so <a href=\"../Node#_unhandled_input\">Node._unhandled_input<a> will not process it.\nOnly one [Control](../Control) node can be in focus. Only the node in focus will receive events. To get the focus, call <a href=\"#grab_focus\">grab_focus</a>. [Control](../Control) nodes lose focus when another node grabs it, or if you hide the node in focus.\nSets <a href=\"#mouse_filter\">mouse_filter</a> to <a href=\"#MOUSE_FILTER_IGNORE\">MOUSE_FILTER_IGNORE</a> to tell a [Control](../Control) node to ignore mouse or touch events. You'll need it if you place an icon on top of a button.\n[Theme](../Theme) resources change the Control's appearance. If you change the [Theme](../Theme) on a [Control](../Control) node, it affects all of its children. To override some of the theme's parameters, call one of the <code>add_theme_*_override</code> methods, like <a href=\"#add_theme_font_override\">add_theme_font_override</a>. You can override the theme with the Inspector.\n<b>Note:</b> Theme items are <i>not</i> [Object](../Object) properties. This means you can't access their values using <a href=\"../Object#get\">Object.get<a> and <a href=\"../Object#set\">Object.set<a>. Instead, use the <code>get_theme_*</code> and <code>add_theme_*_override</code> methods provided by this class."
	},
	"Container": {
		"brief_description": "Base node for containers.",
		"description": "Base node for containers. A [Container](../Container) contains other controls and automatically arranges them in a certain way.\nA Control can inherit this to create custom container classes."
	},
	"ConfirmationDialog": {
		"brief_description": "Dialog for confirmation of actions.",
		"description": "Dialog for confirmation of actions. This dialog inherits from [AcceptDialog](../AcceptDialog), but has by default an OK and Cancel button (in host OS order).\nTo get cancel action, you can use:\n<!-- <codeblocks> -->\n<code>\nget_cancel_button().pressed.connect(self.canceled)\n</code>\n```csharp\nGetCancelButton().Pressed += Canceled;\n```\n<!-- </codeblocks> -->"
	},
	"ConfigFile": {
		"brief_description": "Helper class to handle INI-style files.",
		"description": "This helper class can be used to store [Variant](../Variant) values on the filesystem using INI-style formatting. The stored values are identified by a section and a key:\n<code>\n[section](../section)\nsome_key=42\nstring_example=\"Hello World3D!\"\na_vector=Vector3(1, 0, 2)\n</code>\nThe stored data can be saved to or parsed from a file, though ConfigFile objects can also be used directly without accessing the filesystem.\nThe following example shows how to create a simple [ConfigFile](../ConfigFile) and save it on disc:\n<!-- <codeblocks> -->\n<code>\n# Create new ConfigFile object.\nvar config = ConfigFile.new()\n\n# Store some values.\nconfig.set_value(\"Player1\", \"player_name\", \"Steve\")\nconfig.set_value(\"Player1\", \"best_score\", 10)\nconfig.set_value(\"Player2\", \"player_name\", \"V3geta\")\nconfig.set_value(\"Player2\", \"best_score\", 9001)\n\n# Save it to a file (overwrite if already exists).\nconfig.save(\"user://scores.cfg\")\n</code>\n```csharp\n// Create new ConfigFile object.\nvar config = new ConfigFile();\n\n// Store some values.\nconfig.SetValue(\"Player1\", \"player_name\", \"Steve\");\nconfig.SetValue(\"Player1\", \"best_score\", 10);\nconfig.SetValue(\"Player2\", \"player_name\", \"V3geta\");\nconfig.SetValue(\"Player2\", \"best_score\", 9001);\n\n// Save it to a file (overwrite if already exists).\nconfig.Save(\"user://scores.cfg\");\n```\n<!-- </codeblocks> -->\nThis example shows how the above file could be loaded:\n<!-- <codeblocks> -->\n<code>\nvar score_data = {}\nvar config = ConfigFile.new()\n\n# Load data from a file.\nvar err = config.load(\"user://scores.cfg\")\n\n# If the file didn't load, ignore it.\nif err != OK:\n\treturn\n\n# Iterate over all sections.\nfor player in config.get_sections():\n\t# Fetch the data for each section.\n\tvar player_name = config.get_value(player, \"player_name\")\n\tvar player_score = config.get_value(player, \"best_score\")\n\tscore_data[player_name](../player_name) = player_score\n</code>\n```csharp\nvar score_data = new Godot.Collections.Dictionary();\nvar config = new ConfigFile();\n\n// Load data from a file.\nError err = config.Load(\"user://scores.cfg\");\n\n// If the file didn't load, ignore it.\nif (err != Error.Ok)\n{\n\treturn;\n}\n\n// Iterate over all sections.\nforeach (String player in config.GetSections())\n{\n\t// Fetch the data for each section.\n\tvar player_name = (String)config.GetValue(player, \"player_name\");\n\tvar player_score = (int)config.GetValue(player, \"best_score\");\n\tscore_data[player_name](../player_name) = player_score;\n}\n```\n<!-- </codeblocks> -->\nAny operation that mutates the ConfigFile such as <a href=\"#set_value\">set_value</a>, <a href=\"#clear\">clear</a>, or <a href=\"#erase_section\">erase_section</a>, only changes what is loaded in memory. If you want to write the change to a file, you have to save the changes with <a href=\"#save\">save</a>, <a href=\"#save_encrypted\">save_encrypted</a>, or <a href=\"#save_encrypted_pass\">save_encrypted_pass</a>.\nKeep in mind that section and property names can't contain spaces. Anything after a space will be ignored on save and on load.\nConfigFiles can also contain manually written comment lines starting with a semicolon (<code>;</code>). Those lines will be ignored when parsing the file. Note that comments will be lost when saving the ConfigFile. This can still be useful for dedicated server configuration files, which are typically never overwritten without explicit user action.\n<b>Note:</b> The file extension given to a ConfigFile does not have any impact on its formatting or behavior. By convention, the <code>.cfg</code> extension is used here, but any other extension such as <code>.ini</code> is also valid. Since neither <code>.cfg</code> nor <code>.ini</code> are standardized, Godot's ConfigFile formatting may differ from files written by other programs."
	},
	"ConeTwistJoint3D": {
		"brief_description": "A twist joint between two 3D PhysicsBodies.",
		"description": "The joint can rotate the bodies across an axis defined by the local x-axes of the [Joint3D](../Joint3D).\nThe twist axis is initiated as the X axis of the [Joint3D](../Joint3D).\nOnce the Bodies swing, the twist axis is calculated as the middle of the x-axes of the Joint3D in the local space of the two Bodies. See also [Generic6DOFJoint3D](../Generic6DOFJoint3D)."
	},
	"ConcavePolygonShape3D": {
		"brief_description": "Concave polygon shape resource (also called \"trimesh\") for 3D physics.",
		"description": "3D concave polygon shape resource (also called \"trimesh\") to be added as a <i>direct</i> child of a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D) using a [CollisionShape3D](../CollisionShape3D) node.\nThe shape consists of a collection of triangle faces, and as such it does not include any \"inside\" that the faces might be enclosing. If the faces enclose anything, then the shape is <i>hollow</i>, as opposed to a [ConvexPolygonShape3D](../ConvexPolygonShape3D) which is solid. See also [CollisionPolygon3D](../CollisionPolygon3D).\nBeing made out of triangle faces, this shape is the most freely configurable single 3D shape. Despite its name, it can be used to form (hollow) polyhedra of any nature, convex or concave.\n<b>Note:</b> When used for collision, <b>ConcavePolygonShape3D</b> is intended to work with static [PhysicsBody3D](../PhysicsBody3D) nodes like [StaticBody3D](../StaticBody3D) and will not work with [CharacterBody3D](../CharacterBody3D) or [RigidBody3D](../RigidBody3D) in a mode other than Static.\n<b>Warning:</b> The nature of this shape makes it extra prone to being tunneled through by (small) fast physics bodies. For example, consider a (small) rigid body <i>Ball</i> traveling toward a static body <i>Box</i> at high speed. If the box uses a <b>ConcavePolygonShape3D</b> consisting of twelve triangle faces (two triangle faces for each of the six sides of the box), then the ball might end up inside the box or tunnel all the way through the box, if it goes fast enough. This is (partly) because the ball can only collide against the individual faces of the hollow box. In interactions with rigid bodies tunneling can be avoided by enabling continuous collision detection on the rigid body.\n<b>Warning:</b> Using this shape for an [Area3D](../Area3D) (via a [CollisionShape3D](../CollisionShape3D) node, created e.g. by using the <i>Create Trimesh Collision Sibling</i> option in the <i>Mesh</i> menu that appears when selecting a [MeshInstance3D](../MeshInstance3D) node) may give unexpected results: the area will only detect collisions with the triangle faces in the [ConcavePolygonShape3D](../ConcavePolygonShape3D) (and not with any \"inside\" of the shape, for example); moreover it will only detect all such collisions if <a href=\"#backface_collision\">backface_collision</a> is <code>true</code>.\n<b>Performance:</b> Due to its complexity, [ConcavePolygonShape3D](../ConcavePolygonShape3D) is the slowest collision shape to check collisions against. Its use should generally be limited to level geometry. For convex geometry, using [ConvexPolygonShape3D](../ConvexPolygonShape3D) will perform better. For dynamic physics bodies that need concave collision, several [ConvexPolygonShape3D](../ConvexPolygonShape3D)s can be used to represent its collision by using convex decomposition; see [ConvexPolygonShape3D](../ConvexPolygonShape3D)'s documentation for instructions. However, consider using primitive collision shapes such as [SphereShape3D](../SphereShape3D) or [BoxShape3D](../BoxShape3D) first."
	},
	"ConcavePolygonShape2D": {
		"brief_description": "Concave polygon shape resource for 2D physics.",
		"description": "2D concave polygon shape to be added as a <i>direct</i> child of a [PhysicsBody2D](../PhysicsBody2D) or [Area2D](../Area2D) using a [CollisionShape2D](../CollisionShape2D) node.\nThe shape consists of a collection of line segments, and as such it does not include any \"inside\" that the segments might be enclosing. If the segments do enclose anything, then the shape is <i>hollow</i>, as opposed to a [ConvexPolygonShape2D](../ConvexPolygonShape2D) which is solid. See also [CollisionPolygon2D](../CollisionPolygon2D).\nBeing made out of line segments, this shape is the most freely configurable single 2D shape. It can be used to form (hollow) polygons of any nature, convex or concave.\n<b>Note:</b> When used for collision, <b>ConcavePolygonShape2D</b> is intended to work with static [PhysicsBody2D](../PhysicsBody2D) nodes like [StaticBody2D](../StaticBody2D) and is not recommended to use with [RigidBody2D](../RigidBody2D) nodes in a mode other than Static. A [CollisionPolygon2D](../CollisionPolygon2D) in convex decomposition mode (solids) or several convex objects are advised for that instead. Otherwise, a concave polygon 2D shape is better suited for static bodies.\n<b>Warning:</b> The nature of this shape makes it extra prone to being tunneled through by (small) fast physics bodies. For example, consider a (small) rigid body <i>Ball</i> traveling toward a static body <i>Box</i> at high speed. If the box uses a <b>ConcavePolygonShape2D</b> consisting of four segments, then the ball might end up inside the box or tunnel all the way through the box, if it goes fast enough. This is (partly) because the ball can only collide against the individual segments of the hollow box. In interactions with rigid bodies tunneling can be avoided by enabling continuous collision detection on the rigid body.\n<b>Warning:</b> Using this shape for an [Area2D](../Area2D) (via a [CollisionShape2D](../CollisionShape2D) node) may give unexpected results: the area will only detect collisions with the segments in the [ConcavePolygonShape2D](../ConcavePolygonShape2D) (and not with any \"inside\" of the shape, for example).\n<b>Performance:</b> Due to its complexity, [ConcavePolygonShape2D](../ConcavePolygonShape2D) is the slowest collision shape to check collisions against. Its use should generally be limited to level geometry. For convex geometry, using [ConvexPolygonShape2D](../ConvexPolygonShape2D) will perform better. For dynamic physics bodies that need concave collision, several [ConvexPolygonShape2D](../ConvexPolygonShape2D)s can be used to represent its collision by using convex decomposition; see [ConvexPolygonShape2D](../ConvexPolygonShape2D)'s documentation for instructions. However, consider using primitive collision shapes such as [CircleShape2D](../CircleShape2D) or [RectangleShape2D](../RectangleShape2D) first."
	},
	"CompressedTextureLayered": {
		"brief_description": "Base class for texture arrays that can optionally be compressed.",
		"description": "A texture array that is loaded from a <code>.ctexarray</code> file. This file format is internal to Godot; it is created by importing other image formats with the import system. [CompressedTexture2D](../CompressedTexture2D) can use one of 4 compresson methods:\n- Uncompressed (uncompressed on the GPU)\n- Lossless (WebP or PNG, uncompressed on the GPU)\n- Lossy (WebP, uncompressed on the GPU)\n- VRAM Compressed (compressed on the GPU)\nOnly <b>VRAM Compressed</b> actually reduces the memory usage on the GPU. The <b>Lossless</b> and <b>Lossy</b> compression methods will reduce the required storage on disk, but they will not reduce memory usage on the GPU as the texture is sent to the GPU uncompressed.\nUsing <b>VRAM Compressed</b> also improves loading times, as VRAM-compressed textures are faster to load compared to textures using lossless or lossy compression. VRAM compression can exhibit noticeable artifacts and is intended to be used for 3D rendering, not 2D."
	},
	"CompressedTexture3D": {
		"brief_description": "Texture with 3 dimensions, optionally compressed.",
		"description": "[CompressedTexture3D](../CompressedTexture3D) is the VRAM-compressed counterpart of [ImageTexture3D](../ImageTexture3D). The file extension for [CompressedTexture3D](../CompressedTexture3D) files is <code>.ctex3d</code>. This file format is internal to Godot; it is created by importing other image formats with the import system.\n[CompressedTexture3D](../CompressedTexture3D) uses VRAM compression, which allows to reduce memory usage on the GPU when rendering the texture. This also improves loading times, as VRAM-compressed textures are faster to load compared to textures using lossless compression. VRAM compression can exhibit noticeable artifacts and is intended to be used for 3D rendering, not 2D.\nSee [Texture3D](../Texture3D) for a general description of 3D textures."
	},
	"CompressedTexture2DArray": {
		"brief_description": "Array of 2-dimensional textures, optionally compressed.",
		"description": "A texture array that is loaded from a <code>.ctexarray</code> file. This file format is internal to Godot; it is created by importing other image formats with the import system. [CompressedTexture2DArray](../CompressedTexture2DArray) can use one of 4 compresson methods:\n- Uncompressed (uncompressed on the GPU)\n- Lossless (WebP or PNG, uncompressed on the GPU)\n- Lossy (WebP, uncompressed on the GPU)\n- VRAM Compressed (compressed on the GPU)\nOnly <b>VRAM Compressed</b> actually reduces the memory usage on the GPU. The <b>Lossless</b> and <b>Lossy</b> compression methods will reduce the required storage on disk, but they will not reduce memory usage on the GPU as the texture is sent to the GPU uncompressed.\nUsing <b>VRAM Compressed</b> also improves loading times, as VRAM-compressed textures are faster to load compared to textures using lossless or lossy compression. VRAM compression can exhibit noticeable artifacts and is intended to be used for 3D rendering, not 2D.\nSee [Texture2DArray](../Texture2DArray) for a general description of texture arrays."
	},
	"CompressedTexture2D": {
		"brief_description": "Texture with 2 dimensions, optionally compressed.",
		"description": "A texture that is loaded from a <code>.ctex</code> file. This file format is internal to Godot; it is created by importing other image formats with the import system. [CompressedTexture2D](../CompressedTexture2D) can use one of 4 compression methods (including a lack of any compression):\n- Uncompressed (uncompressed on the GPU)\n- Lossless (WebP or PNG, uncompressed on the GPU)\n- Lossy (WebP, uncompressed on the GPU)\n- VRAM Compressed (compressed on the GPU)\nOnly <b>VRAM Compressed</b> actually reduces the memory usage on the GPU. The <b>Lossless</b> and <b>Lossy</b> compression methods will reduce the required storage on disk, but they will not reduce memory usage on the GPU as the texture is sent to the GPU uncompressed.\nUsing <b>VRAM Compressed</b> also improves loading times, as VRAM-compressed textures are faster to load compared to textures using lossless or lossy compression. VRAM compression can exhibit noticeable artifacts and is intended to be used for 3D rendering, not 2D."
	},
	"CompressedCubemapArray": {
		"brief_description": "Array of 6-sided textures typically used in 3D rendering, optionally compressed.",
		"description": "A cubemap array that is loaded from a <code>.ccubearray</code> file. This file format is internal to Godot; it is created by importing other image formats with the import system. [CompressedCubemapArray](../CompressedCubemapArray) can use one of 4 compresson methods:\n- Uncompressed (uncompressed on the GPU)\n- Lossless (WebP or PNG, uncompressed on the GPU)\n- Lossy (WebP, uncompressed on the GPU)\n- VRAM Compressed (compressed on the GPU)\nOnly <b>VRAM Compressed</b> actually reduces the memory usage on the GPU. The <b>Lossless</b> and <b>Lossy</b> compression methods will reduce the required storage on disk, but they will not reduce memory usage on the GPU as the texture is sent to the GPU uncompressed.\nUsing <b>VRAM Compressed</b> also improves loading times, as VRAM-compressed textures are faster to load compared to textures using lossless or lossy compression. VRAM compression can exhibit noticeable artifacts and is intended to be used for 3D rendering, not 2D.\nSee [CubemapArray](../CubemapArray) for a general description of cubemap arrays."
	},
	"CompressedCubemap": {
		"brief_description": "6-sided texture typically used in 3D rendering, optionally compressed.",
		"description": "A cubemap that is loaded from a <code>.ccube</code> file. This file format is internal to Godot; it is created by importing other image formats with the import system. [CompressedCubemap](../CompressedCubemap) can use one of 4 compresson methods:\n- Uncompressed (uncompressed on the GPU)\n- Lossless (WebP or PNG, uncompressed on the GPU)\n- Lossy (WebP, uncompressed on the GPU)\n- VRAM Compressed (compressed on the GPU)\nOnly <b>VRAM Compressed</b> actually reduces the memory usage on the GPU. The <b>Lossless</b> and <b>Lossy</b> compression methods will reduce the required storage on disk, but they will not reduce memory usage on the GPU as the texture is sent to the GPU uncompressed.\nUsing <b>VRAM Compressed</b> also improves loading times, as VRAM-compressed textures are faster to load compared to textures using lossless or lossy compression. VRAM compression can exhibit noticeable artifacts and is intended to be used for 3D rendering, not 2D.\nSee [Cubemap](../Cubemap) for a general description of cubemaps."
	},
	"ColorRect": {
		"brief_description": "Colored rectangle.",
		"description": "Displays a rectangle filled with a solid <a href=\"#color\">color</a>. If you need to display the border alone, consider using [ReferenceRect](../ReferenceRect) instead."
	},
	"ColorPickerButton": {
		"brief_description": "Button that pops out a [ColorPicker](../ColorPicker).",
		"description": "Encapsulates a [ColorPicker](../ColorPicker) making it accessible by pressing a button. Pressing the button will toggle the [ColorPicker](../ColorPicker) visibility.\nSee also [BaseButton](../BaseButton) which contains common properties and methods associated with this node.\n<b>Note:</b> By default, the button may not be wide enough for the color preview swatch to be visible. Make sure to set <a href=\"../Control#custom_minimum_size\">Control.custom_minimum_size<a> to a big enough value to give the button enough space."
	},
	"ColorPicker": {
		"brief_description": "Color picker control.",
		"description": "Displays a color picker widget. Useful for selecting a color from an RGB/RGBA colorspace.\n<b>Note:</b> This control is the color picker widget itself. You can use a [ColorPickerButton](../ColorPickerButton) instead if you need a button that brings up a [ColorPicker](../ColorPicker) in a pop-up."
	},
	"Color": {
		"brief_description": "Color built-in type, in RGBA format.",
		"description": "A color represented in RGBA format by red (<a href=\"#r\">r</a>), green (<a href=\"#g\">g</a>), blue (<a href=\"#b\">b</a>), and alpha (<a href=\"#a\">a</a>) components. Each component is a 16-bit floating-point value, usually ranging from 0 to 1. Some properties (such as <a href=\"../CanvasItem#modulate\">CanvasItem.modulate<a>) may support values greater than 1, for overbright or High Dynamic Range colors. If you want to supply values in a range of 0 to 255, you should use [method @GDScript.Color8].\nColors can also be created by name from a set of standardized colors, through the [String](../String) constructor, <a href=\"#from_string\">from_string</a>, or by directly fetching the color constants documented here. The standardized color set is based on the [X11 color names](https://en.wikipedia.org/wiki/X11_color_names), with the addition of <a href=\"#TRANSPARENT\">TRANSPARENT</a>.\n<b>Note:</b> In a boolean context, a Color will evaluate to <code>false</code> if it's equal to <code>Color(0, 0, 0, 1)</code> (opaque black). Otherwise, a Color will always evaluate to <code>true</code>.\n[Color constants cheatsheet](https://raw.githubusercontent.com/godotengine/godot-docs/master/img/color_constants.png)"
	},
	"CollisionShape3D": {
		"brief_description": "Node that represents collision shape data in 3D space.",
		"description": "Editor facility for creating and editing collision shapes in 3D space. Set the <a href=\"#shape\">shape</a> property to configure the shape.\nYou can use this node to represent all sorts of collision shapes, for example, add this to an [Area3D](../Area3D) to give it a detection shape, or add it to a [PhysicsBody3D](../PhysicsBody3D) to create a solid object.\n<b>Warning:</b> A non-uniformly scaled CollisionShape3D node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size of its <a href=\"#shape\">shape</a> resource instead."
	},
	"CollisionShape2D": {
		"brief_description": "Node that represents collision shape data in 2D space.",
		"description": "Editor facility for creating and editing collision shapes in 2D space. Set the <a href=\"#shape\">shape</a> property to configure the shape.\nYou can use this node to represent all sorts of collision shapes, for example, add this to an [Area2D](../Area2D) to give it a detection shape, or add it to a [PhysicsBody2D](../PhysicsBody2D) to create a solid object."
	},
	"CollisionPolygon3D": {
		"brief_description": "Node that represents a 3D collision polygon, given by the thickening of a 2D polygon in the local XY plane along the local Z axis.",
		"description": "Provides a 3D collision polygon to a [CollisionObject3D](../CollisionObject3D) parent, by thickening a 2D (convex or concave) polygon in the local XY plane along the local Z axis. The 2D polygon in the local XY plane can be drawn in the editor or specified by a list of vertices. That 2D polygon is thickened evenly in the local Z and -Z directions.\nThis node has the same effect as several [ConvexPolygonShape3D](../ConvexPolygonShape3D) nodes, created by thickening the 2D convex polygons in the convex decomposition of the given 2D polygon (but without the overhead of multiple nodes).\n<b>Warning:</b> A non-uniformly scaled CollisionPolygon3D node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change its <a href=\"#polygon\">polygon</a>'s vertices instead."
	},
	"CollisionPolygon2D": {
		"brief_description": "Node that represents a 2D collision polygon.",
		"description": "Provides a 2D collision polygon to a [CollisionObject2D](../CollisionObject2D) parent. Polygons can be drawn in the editor or specified by a list of vertices.\nDepending on the build mode, this node effectively provides several convex shapes (by convex decomposition of the polygon) or a single concave shape made of the polygon's segments.\nIn the editor, a [CollisionPolygon2D](../CollisionPolygon2D) can be generated from a [Sprite2D](../Sprite2D)'s outline by selecting a [Sprite2D](../Sprite2D) node, going to the <b>Sprite2D</b> menu at the top of the 2D editor viewport then choosing <b>Create CollisionPolygon2D Sibling</b>."
	},
	"CollisionObject3D": {
		"brief_description": "Base node for collision objects.",
		"description": "CollisionObject3D is the base class for physics objects. It can hold any number of collision [Shape3D](../Shape3D)s. Each shape must be assigned to a <i>shape owner</i>. The CollisionObject3D can have any number of shape owners. Shape owners are not nodes and do not appear in the editor, but are accessible through code using the <code>shape_owner_*</code> methods.\n<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"CollisionObject2D": {
		"brief_description": "Base node for 2D collision objects.",
		"description": "CollisionObject2D is the base class for 2D physics objects. It can hold any number of 2D collision [Shape2D](../Shape2D)s. Each shape must be assigned to a <i>shape owner</i>. The CollisionObject2D can have any number of shape owners. Shape owners are not nodes and do not appear in the editor, but are accessible through code using the <code>shape_owner_*</code> methods.\n<b>Note:</b> Only collisions between objects within the same canvas ([Viewport](../Viewport) canvas or [CanvasLayer](../CanvasLayer)) are supported. The behavior of collisions between objects in different canvases is undefined."
	},
	"CodeHighlighter": {
		"brief_description": "A syntax highlighter for code.",
		"description": "A syntax highlighter for code."
	},
	"CodeEdit": {
		"brief_description": "Multiline text control intended for editing code.",
		"description": "CodeEdit is a specialized [TextEdit](../TextEdit) designed for editing plain text code files. It contains a bunch of features commonly found in code editors such as line numbers, line folding, code completion, indent management and string / comment management.\n<b>Note:</b> By default [CodeEdit](../CodeEdit) always use left-to-right text direction to correctly display source code."
	},
	"ClassDB": {
		"brief_description": "Class information repository.",
		"description": "Provides access to metadata stored for every available class."
	},
	"CircleShape2D": {
		"brief_description": "Circular shape resource for 2D physics.",
		"description": "2D circular shape to be added as a <i>direct</i> child of a [PhysicsBody2D](../PhysicsBody2D) or [Area2D](../Area2D) using a [CollisionShape2D](../CollisionShape2D) node. This shape is useful for modeling balls or small characters and its collision detection with everything else is very fast.\n<b>Performance:</b> Being a primitive collision shape, [CircleShape2D](../CircleShape2D) is the fastest collision shape to check collisions against, as it only requires a distance check with the shape's origin."
	},
	"CheckButton": {
		"brief_description": "Checkable button. See also [CheckBox](../CheckBox).",
		"description": "CheckButton is a toggle button displayed as a check field. It's similar to [CheckBox](../CheckBox) in functionality, but it has a different appearance. To follow established UX patterns, it's recommended to use CheckButton when toggling it has an <b>immediate</b> effect on something. For example, it could be used if toggling it enables/disables a setting without requiring the user to press a confirmation button.\nSee also [BaseButton](../BaseButton) which contains common properties and methods associated with this node."
	},
	"CheckBox": {
		"brief_description": "Binary choice user interface widget. See also [CheckButton](../CheckButton).",
		"description": "A checkbox allows the user to make a binary choice (choosing only one of two possible options). It's similar to [CheckButton](../CheckButton) in functionality, but it has a different appearance. To follow established UX patterns, it's recommended to use CheckBox when toggling it has <b>no</b> immediate effect on something. For example, it could be used when toggling it will only do something once a confirmation button is pressed.\nSee also [BaseButton](../BaseButton) which contains common properties and methods associated with this node.\n<b>Note:</b> CheckBox changes its appearance when it's configured as a radio button. See various <code>radio_*</code> theme properties. To configure CheckBox to act as a radio button, use <a href=\"../BaseButton#button_group\">BaseButton.button_group<a> and [ButtonGroup](../ButtonGroup)."
	},
	"CharFXTransform": {
		"brief_description": "Controls how an individual character will be displayed in a [RichTextEffect](../RichTextEffect).",
		"description": "By setting various properties on this object, you can control how individual characters will be displayed in a [RichTextEffect](../RichTextEffect)."
	},
	"CharacterBody3D": {
		"brief_description": "Specialized 3D physics body node for characters moved by script.",
		"description": "Character bodies are special types of bodies that are meant to be user-controlled. They are not affected by physics at all; to other types of bodies, such as a rigid body, these are the same as a [AnimatableBody3D](../AnimatableBody3D). However, they have two main uses:\n<i>Kinematic characters:</i> Character bodies have an API for moving objects with walls and slopes detection (<a href=\"#move_and_slide\">move_and_slide</a> method), in addition to collision detection (also done with <a href=\"../PhysicsBody3D#move_and_collide\">PhysicsBody3D.move_and_collide<a>). This makes them really useful to implement characters that move in specific ways and collide with the world, but don't require advanced physics.\n<i>Kinematic motion:</i> Character bodies can also be used for kinematic motion (same functionality as [AnimatableBody3D](../AnimatableBody3D)), which allows them to be moved by code and push other bodies on their path.\n<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"CharacterBody2D": {
		"brief_description": "Specialized 2D physics body node for characters moved by script.",
		"description": "Character bodies are special types of bodies that are meant to be user-controlled. They are not affected by physics at all; to other types of bodies, such as a rigid body, these are the same as a [AnimatableBody2D](../AnimatableBody2D). However, they have two main uses:\n<b>Kinematic characters:</b> Character bodies have an API for moving objects with walls and slopes detection (<a href=\"#move_and_slide\">move_and_slide</a> method), in addition to collision detection (also done with <a href=\"../PhysicsBody2D#move_and_collide\">PhysicsBody2D.move_and_collide<a>). This makes them really useful to implement characters that move in specific ways and collide with the world, but don't require advanced physics.\n<b>Kinematic motion:</b> Character bodies can also be used for kinematic motion (same functionality as [AnimatableBody2D](../AnimatableBody2D)), which allows them to be moved by code and push other bodies on their path."
	},
	"CenterContainer": {
		"brief_description": "Keeps children controls centered.",
		"description": "CenterContainer keeps children controls centered. This container keeps all children to their minimum size, in the center."
	},
	"CapsuleShape3D": {
		"brief_description": "Capsule shape resource for 3D collisions.",
		"description": "3D capsule shape to be added as a <i>direct</i> child of a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D) using a [CollisionShape3D](../CollisionShape3D) node. In 3D, a capsule is a cylinder shape with hemispheres at both ends.\n<b>Performance:</b> Being a primitive collision shape, [CapsuleShape3D](../CapsuleShape3D) is fast to check collisions against (though not as fast as [SphereShape3D](../SphereShape3D)). [CapsuleShape3D](../CapsuleShape3D) is cheaper to check collisions against compared to [CylinderShape3D](../CylinderShape3D)."
	},
	"CapsuleShape2D": {
		"brief_description": "Capsule shape resource for 2D physics.",
		"description": "2D capsule shape to be added as a <i>direct</i> child of a [PhysicsBody2D](../PhysicsBody2D) or [Area2D](../Area2D) using a [CollisionShape2D](../CollisionShape2D) node. In 2D, a capsule is a rectangle shape with half-circles at both ends.\n<b>Performance:</b> Being a primitive collision shape, [CapsuleShape2D](../CapsuleShape2D) is fast to check collisions against (though not as fast as [CircleShape2D](../CircleShape2D))."
	},
	"CapsuleMesh": {
		"brief_description": "Class representing a capsule-shaped [PrimitiveMesh](../PrimitiveMesh).",
		"description": "Class representing a capsule-shaped [PrimitiveMesh](../PrimitiveMesh)."
	},
	"CanvasTexture": {
		"brief_description": "Texture with optional normal and specular maps for use in 2D rendering.",
		"description": "[CanvasTexture](../CanvasTexture) is an alternative to [ImageTexture](../ImageTexture) for 2D rendering. It allows using normal maps and specular maps in any node that inherits from [CanvasItem](../CanvasItem). [CanvasTexture](../CanvasTexture) also allows overriding the texture's filter and repeat mode independently of the node's properties (or the project settings).\n<b>Note:</b> [CanvasTexture](../CanvasTexture) cannot be used in 3D rendering. For physically-based materials in 3D, use [BaseMaterial3D](../BaseMaterial3D) instead."
	},
	"CanvasModulate": {
		"brief_description": "Tint the entire canvas.",
		"description": "[CanvasModulate](../CanvasModulate) tints the canvas elements using its assigned <a href=\"#color\">color</a>."
	},
	"CanvasLayer": {
		"brief_description": "Canvas drawing layer.",
		"description": "Canvas drawing layer. [CanvasItem](../CanvasItem) nodes that are direct or indirect children of a [CanvasLayer](../CanvasLayer) will be drawn in that layer. The layer is a numeric index that defines the draw order. The default 2D scene renders with index 0, so a [CanvasLayer](../CanvasLayer) with index -1 will be drawn below, and one with index 1 will be drawn above. This is very useful for HUDs (in layer 1+ or above), or backgrounds (in layer -1 or below).\nEmbedded [Window](../Window)s are placed in layer 1024. CanvasItems in layer 1025 or above appear in front of embedded windows, CanvasItems in layer 1023 or below appear behind embedded windows."
	},
	"CanvasItemMaterial": {
		"brief_description": "A material for [CanvasItem](../CanvasItem)s.",
		"description": "[CanvasItemMaterial](../CanvasItemMaterial)s provide a means of modifying the textures associated with a CanvasItem. They specialize in describing blend and lighting behaviors for textures. Use a [ShaderMaterial](../ShaderMaterial) to more fully customize a material's interactions with a [CanvasItem](../CanvasItem)."
	},
	"CanvasItem": {
		"brief_description": "Base class of anything 2D.",
		"description": "Base class of anything 2D. Canvas items are laid out in a tree; children inherit and extend their parent's transform. [CanvasItem](../CanvasItem) is extended by [Control](../Control) for anything GUI-related, and by [Node2D](../Node2D) for anything related to the 2D engine.\nAny [CanvasItem](../CanvasItem) can draw. For this, <a href=\"#queue_redraw\">queue_redraw</a> is called by the engine, then <a href=\"#NOTIFICATION_DRAW\">NOTIFICATION_DRAW</a> will be received on idle time to request redraw. Because of this, canvas items don't need to be redrawn on every frame, improving the performance significantly. Several functions for drawing on the [CanvasItem](../CanvasItem) are provided (see <code>draw_*</code> functions). However, they can only be used inside <a href=\"#_draw\">_draw</a>, its corresponding <a href=\"../Object#_notification\">Object._notification<a> or methods connected to the <a href=\"#draw\">draw</a> signal.\nCanvas items are drawn in tree order. By default, children are on top of their parents so a root [CanvasItem](../CanvasItem) will be drawn behind everything. This behavior can be changed on a per-item basis.\nA [CanvasItem](../CanvasItem) can also be hidden, which will also hide its children. It provides many ways to change parameters such as modulation (for itself and its children) and self modulation (only for itself), as well as its blend mode.\nUltimately, a transform notification can be requested, which will notify the node that its global position changed in case the parent tree changed.\n<b>Note:</b> Unless otherwise specified, all methods that have angle parameters must have angles specified as <i>radians</i>. To convert degrees to radians, use [method @GlobalScope.deg_to_rad]."
	},
	"CanvasGroup": {
		"brief_description": "Merges several 2D nodes into a single draw operation.",
		"description": "Child [CanvasItem](../CanvasItem) nodes of a [CanvasGroup](../CanvasGroup) are drawn as a single object. It allows to e.g. draw overlapping translucent 2D nodes without blending (set <a href=\"../CanvasItem#self_modulate\">CanvasItem.self_modulate<a> property of [CanvasGroup](../CanvasGroup) to achieve this effect).\n<b>Note:</b> The [CanvasGroup](../CanvasGroup) uses a custom shader to read from the backbuffer to draw its children. Assigning a [Material](../Material) to the [CanvasGroup](../CanvasGroup) overrides the builtin shader. To duplicate the behavior of the builtin shader in a custom [Shader](../Shader) use the following:\n<code>\nshader_type canvas_item;\nrender_mode unshaded;\n\nuniform sampler2D screen_texture : hint_screen_texture, repeat_disable, filter_nearest;\n\nvoid fragment() {\n\tvec4 c = textureLod(screen_texture, SCREEN_UV, 0.0);\n\n\tif (c.a > 0.0001) {\n\t\tc.rgb /= c.a;\n\t}\n\n\tCOLOR *= c;\n}\n</code>\n<b>Note:</b> Since [CanvasGroup](../CanvasGroup) and <a href=\"../CanvasItem#clip_children\">CanvasItem.clip_children<a> both utilize the backbuffer, children of a [CanvasGroup](../CanvasGroup) who have their <a href=\"../CanvasItem#clip_children\">CanvasItem.clip_children<a> set to anything other than <a href=\"../CanvasItem#CLIP_CHILDREN_DISABLED\">CanvasItem.CLIP_CHILDREN_DISABLED<a> will not function correctly."
	},
	"CameraTexture": {
		"brief_description": "Texture provided by a [CameraFeed](../CameraFeed).",
		"description": "This texture gives access to the camera texture provided by a [CameraFeed](../CameraFeed).\n<b>Note:</b> Many cameras supply YCbCr images which need to be converted in a shader."
	},
	"CameraServer": {
		"brief_description": "Server keeping track of different cameras accessible in Godot.",
		"description": "The [CameraServer](../CameraServer) keeps track of different cameras accessible in Godot. These are external cameras such as webcams or the cameras on your phone.\nIt is notably used to provide AR modules with a video feed from the camera.\n<b>Note:</b> This class is currently only implemented on macOS and iOS. On other platforms, no [CameraFeed](../CameraFeed)s will be available."
	},
	"CameraFeed": {
		"brief_description": "A camera feed gives you access to a single physical camera attached to your device.",
		"description": "A camera feed gives you access to a single physical camera attached to your device. When enabled, Godot will start capturing frames from the camera which can then be used. See also [CameraServer](../CameraServer).\n<b>Note:</b> Many cameras will return YCbCr images which are split into two textures and need to be combined in a shader. Godot does this automatically for you if you set the environment to show the camera image in the background."
	},
	"CameraAttributesPractical": {
		"brief_description": "Camera settings in an easy to use format.",
		"description": "Controls camera-specific attributes such as auto-exposure, depth of field, and exposure override.\nWhen used in a [WorldEnvironment](../WorldEnvironment) it provides default settings for exposure, auto-exposure, and depth of field that will be used by all cameras without their own [CameraAttributes](../CameraAttributes), including the editor camera. When used in a [Camera3D](../Camera3D) it will override any [CameraAttributes](../CameraAttributes) set in the [WorldEnvironment](../WorldEnvironment). When used in [VoxelGI](../VoxelGI) or [LightmapGI](../LightmapGI), only the exposure settings will be used."
	},
	"CameraAttributesPhysical": {
		"brief_description": "Physically-based camera settings.",
		"description": "[CameraAttributesPhysical](../CameraAttributesPhysical) is used to set rendering settings based on a physically-based camera's settings. It is responsible for exposure, auto-exposure, and depth of field.\nWhen used in a [WorldEnvironment](../WorldEnvironment) it provides default settings for exposure, auto-exposure, and depth of field that will be used by all cameras without their own [CameraAttributes](../CameraAttributes), including the editor camera. When used in a [Camera3D](../Camera3D) it will override any [CameraAttributes](../CameraAttributes) set in the [WorldEnvironment](../WorldEnvironment) and will override the [Camera3D](../Camera3D)s <a href=\"../Camera3D#far\">Camera3D.far<a>, <a href=\"../Camera3D#near\">Camera3D.near<a>, <a href=\"../Camera3D#fov\">Camera3D.fov<a>, and <a href=\"../Camera3D#keep_aspect\">Camera3D.keep_aspect<a> properties. When used in [VoxelGI](../VoxelGI) or [LightmapGI](../LightmapGI), only the exposure settings will be used.\nThe default settings are intended for use in an outdoor environment, tips for settings for use in an indoor environment can be found in each setting's documentation.\n<b>Note:</b> Depth of field blur is only supported in the Forward+ and Mobile rendering methods, not Compatibility."
	},
	"CameraAttributes": {
		"brief_description": "Parent class for camera settings.",
		"description": "Controls camera-specific attributes such as depth of field and exposure override.\nWhen used in a [WorldEnvironment](../WorldEnvironment) it provides default settings for exposure, auto-exposure, and depth of field that will be used by all cameras without their own [CameraAttributes](../CameraAttributes), including the editor camera. When used in a [Camera3D](../Camera3D) it will override any [CameraAttributes](../CameraAttributes) set in the [WorldEnvironment](../WorldEnvironment). When used in [VoxelGI](../VoxelGI) or [LightmapGI](../LightmapGI), only the exposure settings will be used.\nSee also [Environment](../Environment) for general 3D environment settings.\nThis is a pure virtual class that is inherited by [CameraAttributesPhysical](../CameraAttributesPhysical) and [CameraAttributesPractical](../CameraAttributesPractical)."
	},
	"Camera3D": {
		"brief_description": "Camera node, displays from a point of view.",
		"description": "[Camera3D](../Camera3D) is a special node that displays what is visible from its current location. Cameras register themselves in the nearest [Viewport](../Viewport) node (when ascending the tree). Only one camera can be active per viewport. If no viewport is available ascending the tree, the camera will register in the global viewport. In other words, a camera just provides 3D display capabilities to a [Viewport](../Viewport), and, without one, a scene registered in that [Viewport](../Viewport) (or higher viewports) can't be displayed."
	},
	"Camera2D": {
		"brief_description": "Camera node for 2D scenes.",
		"description": "Camera node for 2D scenes. It forces the screen (current layer) to scroll following this node. This makes it easier (and faster) to program scrollable scenes than manually changing the position of [CanvasItem](../CanvasItem)-based nodes.\nCameras register themselves in the nearest [Viewport](../Viewport) node (when ascending the tree). Only one camera can be active per viewport. If no viewport is available ascending the tree, the camera will register in the global viewport.\nThis node is intended to be a simple helper to get things going quickly, but more functionality may be desired to change how the camera works. To make your own custom camera node, inherit it from [Node2D](../Node2D) and change the transform of the canvas by setting <a href=\"../Viewport#canvas_transform\">Viewport.canvas_transform<a> in [Viewport](../Viewport) (you can obtain the current [Viewport](../Viewport) by using <a href=\"../Node#get_viewport\">Node.get_viewport<a>).\nNote that the [Camera2D](../Camera2D) node's <code>position</code> doesn't represent the actual position of the screen, which may differ due to applied smoothing or limits. You can use <a href=\"#get_screen_center_position\">get_screen_center_position</a> to get the real position."
	},
	"CallbackTweener": {
		"brief_description": "Calls the specified method after optional delay.",
		"description": "[CallbackTweener](../CallbackTweener) is used to call a method in a tweening sequence. See <a href=\"../Tween#tween_callback\">Tween.tween_callback<a> for more usage information.\n<b>Note:</b> <a href=\"../Tween#tween_callback\">Tween.tween_callback<a> is the only correct way to create [CallbackTweener](../CallbackTweener). Any [CallbackTweener](../CallbackTweener) created manually will not function correctly."
	},
	"Callable": {
		"brief_description": "Built-in type representing a method in an object instance or a standalone function.",
		"description": "[Callable](../Callable) is a built-in [Variant](../Variant) type that represents a function. It can either be a method within an [Object](../Object) instance, or a standalone function not related to any object, like a lambda function. Like all [Variant](../Variant) types, it can be stored in variables and passed to other functions. It is most commonly used for signal callbacks.\n<b>Example:</b>\n<!-- <codeblocks> -->\n<code>\nfunc print_args(arg1, arg2, arg3 = \"\"):\n\tprints(arg1, arg2, arg3)\n\nfunc test():\n\tvar callable = Callable(self, \"print_args\")\n\tcallable.call(\"hello\", \"world\")  # Prints \"hello world \".\n\tcallable.call(Vector2.UP, 42, callable)  # Prints \"(0, -1) 42 Node(node.gd)::print_args\".\n\tcallable.call(\"invalid\")  # Invalid call, should have at least 2 arguments.\n</code>\n```csharp\n// Default parameter values are not supported.\npublic void PrintArgs(Variant arg1, Variant arg2, Variant arg3 = default)\n{\n\tGD.PrintS(arg1, arg2, arg3);\n}\n\npublic void Test()\n{\n\t// Invalid calls fail silently.\n\tCallable callable = new Callable(this, MethodName.PrintArgs);\n\tcallable.Call(\"hello\", \"world\"); // Default parameter values are not supported, should have 3 arguments.\n\tcallable.Call(Vector2.Up, 42, callable); // Prints \"(0, -1) 42 Node(Node.cs)::PrintArgs\".\n\tcallable.Call(\"invalid\"); // Invalid call, should have 3 arguments.\n}\n```\n<!-- </codeblocks> -->\nIn GDScript, it's possible to create lambda functions within a method. Lambda functions are custom callables that are not associated with an [Object](../Object) instance. Optionally, lambda functions can also be named. The name will be displayed in the debugger, or when calling <a href=\"#get_method\">get_method</a>.\n<code>\nfunc _init():\n\tvar my_lambda = func (message):\n\t\tprint(message)\n\n\t# Prints Hello everyone!\n\tmy_lambda.call(\"Hello everyone!\")\n\n\t# Prints \"Attack!\", when the button_pressed signal is emitted.\n\tbutton_pressed.connect(func(): print(\"Attack!\"))\n</code>"
	},
	"ButtonGroup": {
		"brief_description": "Group of Buttons.",
		"description": "Group of [BaseButton](../BaseButton). The members of this group are treated like radio buttons in the sense that only one button can be pressed at the same time. Some types of buttons (such as [CheckBox](../CheckBox)) may have a special appearance for this state.\nEvery member of the ButtonGroup should have <a href=\"../BaseButton#toggle_mode\">BaseButton.toggle_mode<a> set to <code>true</code>."
	},
	"Button": {
		"brief_description": "Standard themed Button.",
		"description": "Button is the standard themed button. It can contain text and an icon, and will display them according to the current [Theme](../Theme).\n<b>Example of creating a button and assigning an action when pressed by code:</b>\n<!-- <codeblocks> -->\n<code>\nfunc _ready():\n\tvar button = Button.new()\n\tbutton.text = \"Click me\"\n\tbutton.pressed.connect(self._button_pressed)\n\tadd_child(button)\n\nfunc _button_pressed():\n\tprint(\"Hello world!\")\n</code>\n```csharp\npublic override void _Ready()\n{\n\tvar button = new Button();\n\tbutton.Text = \"Click me\";\n\tbutton.Pressed += ButtonPressed;\n\tAddChild(button);\n}\n\nprivate void ButtonPressed()\n{\n\tGD.Print(\"Hello world!\");\n}\n```\n<!-- </codeblocks> -->\nButtons (like all Control nodes) can also be created in the editor, but some situations may require creating them from code.\nSee also [BaseButton](../BaseButton) which contains common properties and methods associated with this node.\n<b>Note:</b> Buttons do not interpret touch input and therefore don't support multitouch, since mouse emulation can only press one button at a given time. Use [TouchScreenButton](../TouchScreenButton) for buttons that trigger gameplay movement or actions, as [TouchScreenButton](../TouchScreenButton) supports multitouch."
	},
	"BoxShape3D": {
		"brief_description": "Box shape resource for 3D collisions.",
		"description": "3D box shape to be added as a <i>direct</i> child of a [PhysicsBody3D](../PhysicsBody3D) or [Area3D](../Area3D) using a [CollisionShape3D](../CollisionShape3D) node.\n<b>Performance:</b> Being a primitive collision shape, [BoxShape3D](../BoxShape3D) is fast to check collisions against (though not as fast as [SphereShape3D](../SphereShape3D))."
	},
	"BoxOccluder3D": {
		"brief_description": "Cuboid shape for use with occlusion culling in [OccluderInstance3D](../OccluderInstance3D).",
		"description": "[BoxOccluder3D](../BoxOccluder3D) stores a cuboid shape that can be used by the engine's occlusion culling system.\nSee [OccluderInstance3D](../OccluderInstance3D)'s documentation for instructions on setting up occlusion culling."
	},
	"BoxMesh": {
		"brief_description": "Generate an axis-aligned box [PrimitiveMesh](../PrimitiveMesh).",
		"description": "Generate an axis-aligned box [PrimitiveMesh](../PrimitiveMesh).\nThe box's UV layout is arranged in a 32 layout that allows texturing each face individually. To apply the same texture on all faces, change the material's UV property to <code>Vector3(3, 2, 1)</code>. This is equivalent to adding <code>UV *= vec2(3.0, 2.0)</code> in a vertex shader.\n<b>Note:</b> When using a large textured [BoxMesh](../BoxMesh) (e.g. as a floor), you may stumble upon UV jittering issues depending on the camera angle. To solve this, increase <a href=\"#subdivide_depth\">subdivide_depth</a>, <a href=\"#subdivide_height\">subdivide_height</a> and <a href=\"#subdivide_width\">subdivide_width</a> until you no longer notice UV jittering."
	},
	"BoxContainer": {
		"brief_description": "Base class for box containers.",
		"description": "Arranges child [Control](../Control) nodes vertically or horizontally, and rearranges them automatically when their minimum size changes."
	},
	"bool": {
		"brief_description": "Boolean built-in type.",
		"description": "Boolean is a built-in type. There are two boolean values: <code>true</code> and <code>false</code>. You can think of it as a switch with on or off (1 or 0) setting. Booleans are used in programming for logic in condition statements, like <code>if</code> statements.\nBooleans can be directly used in <code>if</code> statements. The code below demonstrates this on the <code>if can_shoot:</code> line. You don't need to use <code>== true</code>, you only need <code>if can_shoot:</code>. Similarly, use <code>if not can_shoot:</code> rather than <code>== false</code>.\n<!-- <codeblocks> -->\n<code>\nvar _can_shoot = true\n\nfunc shoot():\n\tif _can_shoot:\n\t\tpass # Perform shooting actions here.\n</code>\n```csharp\nprivate bool _canShoot = true;\n\npublic void Shoot()\n{\n\tif (_canShoot)\n\t{\n\t\t// Perform shooting actions here.\n\t}\n}\n```\n<!-- </codeblocks> -->\nThe following code will only create a bullet if both conditions are met: action \"shoot\" is pressed and if <code>can_shoot</code> is <code>true</code>.\n<b>Note:</b> <code>Input.is_action_pressed(\"shoot\")</code> is also a boolean that is <code>true</code> when \"shoot\" is pressed and <code>false</code> when \"shoot\" isn't pressed.\n<!-- <codeblocks> -->\n<code>\nvar _can_shoot = true\n\nfunc shoot():\n\tif _can_shoot and Input.is_action_pressed(\"shoot\"):\n\t\tcreate_bullet()\n</code>\n```csharp\nprivate bool _canShoot = true;\n\npublic void Shoot()\n{\n\tif (_canShoot && Input.IsActionPressed(\"shoot\"))\n\t{\n\t\tCreateBullet();\n\t}\n}\n```\n<!-- </codeblocks> -->\nThe following code will set <code>can_shoot</code> to <code>false</code> and start a timer. This will prevent player from shooting until the timer runs out. Next <code>can_shoot</code> will be set to <code>true</code> again allowing player to shoot once again.\n<!-- <codeblocks> -->\n<code>\nvar _can_shoot = true\n@onready var _cool_down = $CoolDownTimer\n\nfunc shoot():\n\tif _can_shoot and Input.is_action_pressed(\"shoot\"):\n\t\tcreate_bullet()\n\t\t_can_shoot = false\n\t\t_cool_down.start()\n\nfunc _on_cool_down_timer_timeout():\n\t_can_shoot = true\n</code>\n```csharp\nprivate bool _canShoot = true;\nprivate Timer _coolDown;\n\npublic override void _Ready()\n{\n\t_coolDown = GetNode<Timer>(\"CoolDownTimer\");\n}\n\npublic void Shoot()\n{\n\tif (_canShoot && Input.IsActionPressed(\"shoot\"))\n\t{\n\t\tCreateBullet();\n\t\t_canShoot = false;\n\t\t_coolDown.Start();\n\t}\n}\n\npublic void OnCoolDownTimerTimeout()\n{\n\t_canShoot = true;\n}\n```\n<!-- </codeblocks> -->"
	},
	"BoneMap": {
		"brief_description": "Bone map for retargeting.",
		"description": "This class contains a hashmap that uses a list of bone names in [SkeletonProfile](../SkeletonProfile) as key names.\nBy assigning the actual [Skeleton3D](../Skeleton3D) bone name as the key value, it maps the [Skeleton3D](../Skeleton3D) to the [SkeletonProfile](../SkeletonProfile)."
	},
	"BoneAttachment3D": {
		"brief_description": "A node that will attach to a bone.",
		"description": "This node will allow you to select a bone for this node to attach to. The BoneAttachment3D node can copy the transform of the select bone, or can override the transform of the selected bone.\nThe BoneAttachment3D node must either be a child of a [Skeleton3D](../Skeleton3D) node or be given an external [Skeleton3D](../Skeleton3D) to use in order to function properly."
	},
	"Bone2D": {
		"brief_description": "Joint used with [Skeleton2D](../Skeleton2D) to control and animate other nodes.",
		"description": "Use a hierarchy of <code>Bone2D</code> bound to a [Skeleton2D](../Skeleton2D) to control, and animate other [Node2D](../Node2D) nodes.\nYou can use <code>Bone2D</code> and <code>Skeleton2D</code> nodes to animate 2D meshes created with the Polygon 2D UV editor.\nEach bone has a <a href=\"#rest\">rest</a> transform that you can reset to with <a href=\"#apply_rest\">apply_rest</a>. These rest poses are relative to the bone's parent.\nIf in the editor, you can set the rest pose of an entire skeleton using a menu option, from the code, you need to iterate over the bones to set their individual rest poses."
	},
	"BitMap": {
		"brief_description": "Boolean matrix.",
		"description": "A two-dimensional array of boolean values, can be used to efficiently store a binary matrix (every matrix element takes only one bit) and query the values using natural cartesian coordinates."
	},
	"Basis": {
		"brief_description": "33 matrix datatype.",
		"description": "33 matrix used for 3D rotation and scale. Almost always used as an orthogonal basis for a [Transform3D](../Transform3D).\nContains 3 vector fields X, Y and Z as its columns, which are typically interpreted as the local basis vectors of a transformation. For such use, it is composed of a scaling and a rotation matrix, in that order (M = R.S).\nCan also be accessed as array of 3D vectors. These vectors are normally orthogonal to each other, but are not necessarily normalized (due to scaling).\nFor more information, read the \"Matrices and transforms\" documentation article."
	},
	"BaseMaterial3D": {
		"brief_description": "Default 3D rendering material.",
		"description": "This provides a default material with a wide variety of rendering features and properties without the need to write shader code. See the tutorial below for details."
	},
	"BaseButton": {
		"brief_description": "Base class for different kinds of buttons.",
		"description": "BaseButton is the abstract base class for buttons, so it shouldn't be used directly (it doesn't display anything). Other types of buttons inherit from it."
	},
	"BackBufferCopy": {
		"brief_description": "Copies a region of the screen (or the whole screen) to a buffer so it can be accessed in your shader scripts using the screen texture (i.e. a uniform sampler with ``hint_screen_texture``).",
		"description": "Node for back-buffering the currently-displayed screen. The region defined in the [BackBufferCopy](../BackBufferCopy) node is buffered with the content of the screen it covers, or the entire screen according to the copy mode set. Use the screen texture in your shader scripts to access the buffer.\n<b>Note:</b> Since this node inherits from [Node2D](../Node2D) (and not [Control](../Control)), anchors and margins won't apply to child [Control](../Control)-derived nodes. This can be problematic when resizing the window. To avoid this, add [Control](../Control)-derived nodes as <i>siblings</i> to the [BackBufferCopy](../BackBufferCopy) node instead of adding them as children."
	},
	"AudioStreamWAV": {
		"brief_description": "Stores audio data loaded from WAV files.",
		"description": "AudioStreamWAV stores sound samples loaded from WAV files. To play the stored sound, use an [AudioStreamPlayer](../AudioStreamPlayer) (for non-positional audio) or [AudioStreamPlayer2D](../AudioStreamPlayer2D)/[AudioStreamPlayer3D](../AudioStreamPlayer3D) (for positional audio). The sound can be looped.\nThis class can also be used to store dynamically-generated PCM audio data. See also [AudioStreamGenerator](../AudioStreamGenerator) for procedural audio generation."
	},
	"AudioStreamRandomizer": {
		"brief_description": "Wraps a pool of audio streams with pitch and volume shifting.",
		"description": "Picks a random AudioStream from the pool, depending on the playback mode, and applies random pitch shifting and volume shifting during playback."
	},
	"AudioStreamPolyphonic": {
		"brief_description": "AudioStream that lets the user play custom streams at any time from code, simultaneously using a single player.",
		"description": "AudioStream that lets the user play custom streams at any time from code, simultaneously using a single player.\nPlayback control is done via the [AudioStreamPlaybackPolyphonic](../AudioStreamPlaybackPolyphonic) instance set inside the player, which can be obtained via <a href=\"../AudioStreamPlayer#get_stream_playback\">AudioStreamPlayer.get_stream_playback<a>, <a href=\"../AudioStreamPlayer2D#get_stream_playback\">AudioStreamPlayer2D.get_stream_playback<a> or <a href=\"../AudioStreamPlayer3D#get_stream_playback\">AudioStreamPlayer3D.get_stream_playback<a> methods. Obtaining the playback instance is only valid after the <code>stream</code> property is set as an [AudioStreamPolyphonic](../AudioStreamPolyphonic) in those players."
	},
	"AudioStreamPlayer3D": {
		"brief_description": "Plays positional sound in 3D space.",
		"description": "Plays audio with positional sound effects, based on the relative position of the audio listener. Positional effects include distance attenuation, directionality, and the Doppler effect. For greater realism, a low-pass filter is applied to distant sounds. This can be disabled by setting <a href=\"#attenuation_filter_cutoff_hz\">attenuation_filter_cutoff_hz</a> to <code>20500</code>.\nBy default, audio is heard from the camera position. This can be changed by adding an [AudioListener3D](../AudioListener3D) node to the scene and enabling it by calling <a href=\"../AudioListener3D#make_current\">AudioListener3D.make_current<a> on it.\nSee also [AudioStreamPlayer](../AudioStreamPlayer) to play a sound non-positionally.\n<b>Note:</b> Hiding an [AudioStreamPlayer3D](../AudioStreamPlayer3D) node does not disable its audio output. To temporarily disable an [AudioStreamPlayer3D](../AudioStreamPlayer3D)'s audio output, set <a href=\"#volume_db\">volume_db</a> to a very low value like <code>-100</code> (which isn't audible to human hearing)."
	},
	"AudioStreamPlayer2D": {
		"brief_description": "Plays positional sound in 2D space.",
		"description": "Plays audio that is attenuated with distance to the listener.\nBy default, audio is heard from the screen center. This can be changed by adding an [AudioListener2D](../AudioListener2D) node to the scene and enabling it by calling <a href=\"../AudioListener2D#make_current\">AudioListener2D.make_current<a> on it.\nSee also [AudioStreamPlayer](../AudioStreamPlayer) to play a sound non-positionally.\n<b>Note:</b> Hiding an [AudioStreamPlayer2D](../AudioStreamPlayer2D) node does not disable its audio output. To temporarily disable an [AudioStreamPlayer2D](../AudioStreamPlayer2D)'s audio output, set <a href=\"#volume_db\">volume_db</a> to a very low value like <code>-100</code> (which isn't audible to human hearing)."
	},
	"AudioStreamPlayer": {
		"brief_description": "Plays back audio non-positionally.",
		"description": "Plays an audio stream non-positionally.\nTo play audio positionally, use [AudioStreamPlayer2D](../AudioStreamPlayer2D) or [AudioStreamPlayer3D](../AudioStreamPlayer3D) instead of [AudioStreamPlayer](../AudioStreamPlayer)."
	},
	"AudioStreamPlaybackResampled": {
		"brief_description": "",
		"description": ""
	},
	"AudioStreamPlaybackPolyphonic": {
		"brief_description": "Playback instance for [AudioStreamPolyphonic](../AudioStreamPolyphonic).",
		"description": "Playback instance for [AudioStreamPolyphonic](../AudioStreamPolyphonic). After setting the <code>stream</code> property of [AudioStreamPlayer](../AudioStreamPlayer), [AudioStreamPlayer2D](../AudioStreamPlayer2D), or [AudioStreamPlayer3D](../AudioStreamPlayer3D), the playback instance can be obtained by calling <a href=\"../AudioStreamPlayer#get_stream_playback\">AudioStreamPlayer.get_stream_playback<a>, <a href=\"../AudioStreamPlayer2D#get_stream_playback\">AudioStreamPlayer2D.get_stream_playback<a> or <a href=\"../AudioStreamPlayer3D#get_stream_playback\">AudioStreamPlayer3D.get_stream_playback<a> methods."
	},
	"AudioStreamPlayback": {
		"brief_description": "Meta class for playing back audio.",
		"description": "Can play, loop, pause a scroll through audio. See [AudioStream](../AudioStream) and [AudioStreamOggVorbis](../AudioStreamOggVorbis) for usage."
	},
	"AudioStreamMicrophone": {
		"brief_description": "Plays real-time audio input data.",
		"description": "When used directly in an [AudioStreamPlayer](../AudioStreamPlayer) node, [AudioStreamMicrophone](../AudioStreamMicrophone) plays back microphone input in real-time. This can be used in conjunction with [AudioEffectCapture](../AudioEffectCapture) to process the data or save it.\n<b>Note:</b> [member ProjectSettings.audio/driver/enable_input] must be <code>true</code> for audio input to work. See also that setting's description for caveats related to permissions and operating system privacy settings."
	},
	"AudioStreamGeneratorPlayback": {
		"brief_description": "Plays back audio generated using [AudioStreamGenerator](../AudioStreamGenerator).",
		"description": "This class is meant to be used with [AudioStreamGenerator](../AudioStreamGenerator) to play back the generated audio in real-time."
	},
	"AudioStreamGenerator": {
		"brief_description": "Audio stream that generates sounds procedurally.",
		"description": "This audio stream does not play back sounds, but expects a script to generate audio data for it instead. See also [AudioStreamGeneratorPlayback](../AudioStreamGeneratorPlayback).\nSee also [AudioEffectSpectrumAnalyzer](../AudioEffectSpectrumAnalyzer) for performing real-time audio spectrum analysis.\n<b>Note:</b> Due to performance constraints, this class is best used from C# or from a compiled language via GDExtension. If you still want to use this class from GDScript, consider using a lower <a href=\"#mix_rate\">mix_rate</a> such as 11,025 Hz or 22,050 Hz."
	},
	"AudioStream": {
		"brief_description": "Base class for audio streams.",
		"description": "Base class for audio streams. Audio streams are used for sound effects and music playback, and support WAV (via [AudioStreamWAV](../AudioStreamWAV)) and Ogg (via [AudioStreamOggVorbis](../AudioStreamOggVorbis)) file formats."
	},
	"AudioServer": {
		"brief_description": "Server interface for low-level audio access.",
		"description": "[AudioServer](../AudioServer) is a low-level server interface for audio access. It is in charge of creating sample data (playable audio) as well as its playback via a voice interface."
	},
	"AudioListener3D": {
		"brief_description": "Overrides the location sounds are heard from.",
		"description": "Once added to the scene tree and enabled using <a href=\"#make_current\">make_current</a>, this node will override the location sounds are heard from. This can be used to listen from a location different from the [Camera3D](../Camera3D)."
	},
	"AudioListener2D": {
		"brief_description": "Overrides the location sounds are heard from.",
		"description": "Once added to the scene tree and enabled using <a href=\"#make_current\">make_current</a>, this node will override the location sounds are heard from. Only one [AudioListener2D](../AudioListener2D) can be current. Using <a href=\"#make_current\">make_current</a> will disable the previous [AudioListener2D](../AudioListener2D).\nIf there is no active [AudioListener2D](../AudioListener2D) in the current [Viewport](../Viewport), center of the screen will be used as a hearing point for the audio. [AudioListener2D](../AudioListener2D) needs to be inside [SceneTree](../SceneTree) to function."
	},
	"AudioEffectStereoEnhance": {
		"brief_description": "An audio effect that can be used to adjust the intensity of stereo panning.",
		"description": "An audio effect that can be used to adjust the intensity of stereo panning."
	},
	"AudioEffectSpectrumAnalyzerInstance": {
		"brief_description": "",
		"description": ""
	},
	"AudioEffectSpectrumAnalyzer": {
		"brief_description": "Audio effect that can be used for real-time audio visualizations.",
		"description": "This audio effect does not affect sound output, but can be used for real-time audio visualizations.\nSee also [AudioStreamGenerator](../AudioStreamGenerator) for procedurally generating sounds."
	},
	"AudioEffectReverb": {
		"brief_description": "Adds a reverberation audio effect to an Audio bus.",
		"description": "Simulates the sound of acoustic environments such as rooms, concert halls, caverns, or an open spaces."
	},
	"AudioEffectRecord": {
		"brief_description": "Audio effect used for recording the sound from an audio bus.",
		"description": "Allows the user to record the sound from an audio bus. This can include all audio output by Godot when used on the \"Master\" audio bus.\nCan be used (with an [AudioStreamMicrophone](../AudioStreamMicrophone)) to record from a microphone.\nIt sets and gets the format in which the audio file will be recorded (8-bit, 16-bit, or compressed). It checks whether or not the recording is active, and if it is, records the sound. It then returns the recorded sample."
	},
	"AudioEffectPitchShift": {
		"brief_description": "Adds a pitch-shifting audio effect to an audio bus.\nRaises or lowers the pitch of original sound.",
		"description": "Allows modulation of pitch independently of tempo. All frequencies can be increased/decreased with minimal effect on transients."
	},
	"AudioEffectPhaser": {
		"brief_description": "Adds a phaser audio effect to an audio bus.\nCombines the original signal with a copy that is slightly out of phase with the original.",
		"description": "Combines phase-shifted signals with the original signal. The movement of the phase-shifted signals is controlled using a low-frequency oscillator."
	},
	"AudioEffectPanner": {
		"brief_description": "Adds a panner audio effect to an audio bus. Pans sound left or right.",
		"description": "Determines how much of an audio signal is sent to the left and right buses."
	},
	"AudioEffectNotchFilter": {
		"brief_description": "Adds a notch filter to the Audio bus.",
		"description": "Attenuates frequencies in a narrow band around the <a href=\"../AudioEffectFilter#cutoff_hz\">AudioEffectFilter.cutoff_hz<a> and cuts frequencies outside of this range."
	},
	"AudioEffectLowShelfFilter": {
		"brief_description": "Adds a low-shelf filter to the audio bus.",
		"description": "Reduces all frequencies below the <a href=\"../AudioEffectFilter#cutoff_hz\">AudioEffectFilter.cutoff_hz<a>."
	},
	"AudioEffectLowPassFilter": {
		"brief_description": "Adds a low-pass filter to the audio bus.",
		"description": "Cuts frequencies higher than the <a href=\"../AudioEffectFilter#cutoff_hz\">AudioEffectFilter.cutoff_hz<a> and allows lower frequencies to pass."
	},
	"AudioEffectLimiter": {
		"brief_description": "Adds a soft-clip limiter audio effect to an Audio bus.",
		"description": "A limiter is similar to a compressor, but it's less flexible and designed to disallow sound going over a given dB threshold. Adding one in the Master bus is always recommended to reduce the effects of clipping.\nSoft clipping starts to reduce the peaks a little below the threshold level and progressively increases its effect as the input level increases such that the threshold is never exceeded."
	},
	"AudioEffectInstance": {
		"brief_description": "",
		"description": ""
	},
	"AudioEffectHighShelfFilter": {
		"brief_description": "Adds a high-shelf filter to the audio bus.",
		"description": "Reduces all frequencies above the <a href=\"../AudioEffectFilter#cutoff_hz\">AudioEffectFilter.cutoff_hz<a>."
	},
	"AudioEffectHighPassFilter": {
		"brief_description": "Adds a high-pass filter to the audio bus.",
		"description": "Cuts frequencies lower than the <a href=\"../AudioEffectFilter#cutoff_hz\">AudioEffectFilter.cutoff_hz<a> and allows higher frequencies to pass."
	},
	"AudioEffectFilter": {
		"brief_description": "Adds a filter to the audio bus.",
		"description": "Allows frequencies other than the <a href=\"#cutoff_hz\">cutoff_hz</a> to pass."
	},
	"AudioEffectEQ6": {
		"brief_description": "Adds a 6-band equalizer audio effect to an audio bus. Gives you control over frequencies from 32 Hz to 10000 Hz.\nEach frequency can be modulated between -60/+24 dB.",
		"description": "Frequency bands:\nBand 1: 32 Hz\nBand 2: 100 Hz\nBand 3: 320 Hz\nBand 4: 1000 Hz\nBand 5: 3200 Hz\nBand 6: 10000 Hz\nSee also [AudioEffectEQ](../AudioEffectEQ), [AudioEffectEQ10](../AudioEffectEQ10), [AudioEffectEQ21](../AudioEffectEQ21)."
	},
	"AudioEffectEQ21": {
		"brief_description": "Adds a 21-band equalizer audio effect to an Audio bus. Gives you control over frequencies from 22 Hz to 22000 Hz.\nEach frequency can be modulated between -60/+24 dB.",
		"description": "Frequency bands:\nBand 1: 22 Hz\nBand 2: 32 Hz\nBand 3: 44 Hz\nBand 4: 63 Hz\nBand 5: 90 Hz\nBand 6: 125 Hz\nBand 7: 175 Hz\nBand 8: 250 Hz\nBand 9: 350 Hz\nBand 10: 500 Hz\nBand 11: 700 Hz\nBand 12: 1000 Hz\nBand 13: 1400 Hz\nBand 14: 2000 Hz\nBand 15: 2800 Hz\nBand 16: 4000 Hz\nBand 17: 5600 Hz\nBand 18: 8000 Hz\nBand 19: 11000 Hz\nBand 20: 16000 Hz\nBand 21: 22000 Hz\nSee also [AudioEffectEQ](../AudioEffectEQ), [AudioEffectEQ6](../AudioEffectEQ6), [AudioEffectEQ10](../AudioEffectEQ10)."
	},
	"AudioEffectEQ10": {
		"brief_description": "Adds a 10-band equalizer audio effect to an Audio bus. Gives you control over frequencies from 31 Hz to 16000 Hz.\nEach frequency can be modulated between -60/+24 dB.",
		"description": "Frequency bands:\nBand 1: 31 Hz\nBand 2: 62 Hz\nBand 3: 125 Hz\nBand 4: 250 Hz\nBand 5: 500 Hz\nBand 6: 1000 Hz\nBand 7: 2000 Hz\nBand 8: 4000 Hz\nBand 9: 8000 Hz\nBand 10: 16000 Hz\nSee also [AudioEffectEQ](../AudioEffectEQ), [AudioEffectEQ6](../AudioEffectEQ6), [AudioEffectEQ21](../AudioEffectEQ21)."
	},
	"AudioEffectEQ": {
		"brief_description": "Base class for audio equalizers. Gives you control over frequencies.\nUse it to create a custom equalizer if [AudioEffectEQ6](../AudioEffectEQ6), [AudioEffectEQ10](../AudioEffectEQ10) or [AudioEffectEQ21](../AudioEffectEQ21) don't fit your needs.",
		"description": "AudioEffectEQ gives you control over frequencies. Use it to compensate for existing deficiencies in audio. AudioEffectEQs are useful on the Master bus to completely master a mix and give it more character. They are also useful when a game is run on a mobile device, to adjust the mix to that kind of speakers (it can be added but disabled when headphones are plugged)."
	},
	"AudioEffectDistortion": {
		"brief_description": "Adds a distortion audio effect to an Audio bus.\nModifies the sound to make it distorted.",
		"description": "Different types are available: clip, tan, lo-fi (bit crushing), overdrive, or waveshape.\nBy distorting the waveform the frequency content changes, which will often make the sound \"crunchy\" or \"abrasive\". For games, it can simulate sound coming from some saturated device or speaker very efficiently."
	},
	"AudioEffectDelay": {
		"brief_description": "Adds a delay audio effect to an audio bus. Plays input signal back after a period of time.\nTwo tap delay and feedback options.",
		"description": "Plays input signal back after a period of time. The delayed signal may be played back multiple times to create the sound of a repeating, decaying echo. Delay effects range from a subtle echo effect to a pronounced blending of previous sounds with new sounds."
	},
	"AudioEffectCompressor": {
		"brief_description": "Adds a compressor audio effect to an audio bus.\nReduces sounds that exceed a certain threshold level, smooths out the dynamics and increases the overall volume.",
		"description": "Dynamic range compressor reduces the level of the sound when the amplitude goes over a certain threshold in Decibels. One of the main uses of a compressor is to increase the dynamic range by clipping as little as possible (when sound goes over 0dB).\nCompressor has many uses in the mix:\n- In the Master bus to compress the whole output (although an [AudioEffectLimiter](../AudioEffectLimiter) is probably better).\n- In voice channels to ensure they sound as balanced as possible.\n- Sidechained. This can reduce the sound level sidechained with another audio bus for threshold detection. This technique is common in video game mixing to the level of music and SFX while voices are being heard.\n- Accentuates transients by using a wider attack, making effects sound more punchy."
	},
	"AudioEffectChorus": {
		"brief_description": "Adds a chorus audio effect.",
		"description": "Adds a chorus audio effect. The effect applies a filter with voices to duplicate the audio source and manipulate it through the filter."
	},
	"AudioEffectCapture": {
		"brief_description": "Captures audio from an audio bus in real-time.",
		"description": "AudioEffectCapture is an AudioEffect which copies all audio frames from the attached audio effect bus into its internal ring buffer.\nApplication code should consume these audio frames from this ring buffer using <a href=\"#get_buffer\">get_buffer</a> and process it as needed, for example to capture data from an [AudioStreamMicrophone](../AudioStreamMicrophone), implement application-defined effects, or to transmit audio over the network. When capturing audio data from a microphone, the format of the samples will be stereo 32-bit floating point PCM.\n<b>Note:</b> [member ProjectSettings.audio/driver/enable_input] must be <code>true</code> for audio input to work. See also that setting's description for caveats related to permissions and operating system privacy settings."
	},
	"AudioEffectBandPassFilter": {
		"brief_description": "Adds a band pass filter to the audio bus.",
		"description": "Attenuates the frequencies inside of a range around the <a href=\"../AudioEffectFilter#cutoff_hz\">AudioEffectFilter.cutoff_hz<a> and cuts frequencies outside of this band."
	},
	"AudioEffectBandLimitFilter": {
		"brief_description": "Adds a band limit filter to the audio bus.",
		"description": "Limits the frequencies in a range around the <a href=\"../AudioEffectFilter#cutoff_hz\">AudioEffectFilter.cutoff_hz<a> and allows frequencies outside of this range to pass."
	},
	"AudioEffectAmplify": {
		"brief_description": "Adds an amplifying audio effect to an audio bus.",
		"description": "Increases or decreases the volume being routed through the audio bus."
	},
	"AudioEffect": {
		"brief_description": "Audio effect for audio.",
		"description": "Base resource for audio bus. Applies an audio effect on the bus that the resource is applied on."
	},
	"AudioBusLayout": {
		"brief_description": "Stores information about the audio buses.",
		"description": "Stores position, muting, solo, bypass, effects, effect position, volume, and the connections between buses. See [AudioServer](../AudioServer) for usage."
	},
	"AtlasTexture": {
		"brief_description": "A texture that crops out part of another Texture2D.",
		"description": "[Texture2D](../Texture2D) resource that draws only part of its <a href=\"#atlas\">atlas</a> texture, as defined by the <a href=\"#region\">region</a>. An additional <a href=\"#margin\">margin</a> can also be set, which is useful for small adjustments.\nMultiple [AtlasTexture](../AtlasTexture) resources can be cropped from the same <a href=\"#atlas\">atlas</a>. Packing many smaller textures into a singular large texture helps to optimize video memory costs and render calls.\n<b>Note:</b> [AtlasTexture](../AtlasTexture) cannot be used in an [AnimatedTexture](../AnimatedTexture), and may not tile properly in nodes such as [TextureRect](../TextureRect), when inside other [AtlasTexture](../AtlasTexture) resources."
	},
	"AStarGrid2D": {
		"brief_description": "A* (or \"A-Star\") pathfinding tailored to find the shortest paths on 2D grids.",
		"description": "Compared to [AStar2D](../AStar2D) you don't need to manually create points or connect them together. It also supports multiple type of heuristics and modes for diagonal movement. This class also provides a jumping mode which is faster to calculate than without it in the [AStar2D](../AStar2D) class.\nIn contrast to [AStar2D](../AStar2D), you only need set the <a href=\"#size\">size</a> of the grid, optionally set the <a href=\"#cell_size\">cell_size</a> and then call the <a href=\"#update\">update</a> method:\n<!-- <codeblocks> -->\n<code>\nvar astar_grid = AStarGrid2D.new()\nastar_grid.size = Vector2i(32, 32)\nastar_grid.cell_size = Vector2(16, 16)\nastar_grid.update()\nprint(astar_grid.get_id_path(Vector2i(0, 0), Vector2i(3, 4))) # prints (0, 0), (1, 1), (2, 2), (3, 3), (3, 4)\nprint(astar_grid.get_point_path(Vector2i(0, 0), Vector2i(3, 4))) # prints (0, 0), (16, 16), (32, 32), (48, 48), (48, 64)\n</code>\n```csharp\nAStarGrid2D astarGrid = new AStarGrid2D();\nastarGrid.Size = new Vector2I(32, 32);\nastarGrid.CellSize = new Vector2I(16, 16);\nastarGrid.Update();\nGD.Print(astarGrid.GetIdPath(Vector2I.Zero, new Vector2I(3, 4))); // prints (0, 0), (1, 1), (2, 2), (3, 3), (3, 4)\nGD.Print(astarGrid.GetPointPath(Vector2I.Zero, new Vector2I(3, 4))); // prints (0, 0), (16, 16), (32, 32), (48, 48), (48, 64)\n```\n<!-- </codeblocks> -->"
	},
	"AStar3D": {
		"brief_description": "An implementation of A* to find the shortest paths among connected points in space.",
		"description": "A* (A star) is a computer algorithm that is widely used in pathfinding and graph traversal, the process of plotting short paths among vertices (points), passing through a given set of edges (segments). It enjoys widespread use due to its performance and accuracy. Godot's A* implementation uses points in three-dimensional space and Euclidean distances by default.\nYou must add points manually with <a href=\"#add_point\">add_point</a> and create segments manually with <a href=\"#connect_points\">connect_points</a>. Then you can test if there is a path between two points with the <a href=\"#are_points_connected\">are_points_connected</a> function, get a path containing indices by <a href=\"#get_id_path\">get_id_path</a>, or one containing actual coordinates with <a href=\"#get_point_path\">get_point_path</a>.\nIt is also possible to use non-Euclidean distances. To do so, create a class that extends <code>AStar3D</code> and override methods <a href=\"#_compute_cost\">_compute_cost</a> and <a href=\"#_estimate_cost\">_estimate_cost</a>. Both take two indices and return a length, as is shown in the following example.\n<!-- <codeblocks> -->\n<code>\nclass MyAStar:\n\textends AStar3D\n\n\tfunc _compute_cost(u, v):\n\t\treturn abs(u - v)\n\n\tfunc _estimate_cost(u, v):\n\t\treturn min(0, abs(u - v) - 1)\n</code>\n```csharp\npublic partial class MyAStar : AStar3D\n{\n\tpublic override float _ComputeCost(long fromId, long toId)\n\t{\n\t\treturn Mathf.Abs((int)(fromId - toId));\n\t}\n\n\tpublic override float _EstimateCost(long fromId, long toId)\n\t{\n\t\treturn Mathf.Min(0, Mathf.Abs((int)(fromId - toId)) - 1);\n\t}\n}\n```\n<!-- </codeblocks> -->\n<a href=\"#_estimate_cost\">_estimate_cost</a> should return a lower bound of the distance, i.e. <code>_estimate_cost(u, v) <= _compute_cost(u, v)</code>. This serves as a hint to the algorithm because the custom <code>_compute_cost</code> might be computation-heavy. If this is not the case, make <a href=\"#_estimate_cost\">_estimate_cost</a> return the same value as <a href=\"#_compute_cost\">_compute_cost</a> to provide the algorithm with the most accurate information.\nIf the default <a href=\"#_estimate_cost\">_estimate_cost</a> and <a href=\"#_compute_cost\">_compute_cost</a> methods are used, or if the supplied <a href=\"#_estimate_cost\">_estimate_cost</a> method returns a lower bound of the cost, then the paths returned by A* will be the lowest-cost paths. Here, the cost of a path equals the sum of the <a href=\"#_compute_cost\">_compute_cost</a> results of all segments in the path multiplied by the <code>weight_scale</code>s of the endpoints of the respective segments. If the default methods are used and the <code>weight_scale</code>s of all points are set to <code>1.0</code>, then this equals the sum of Euclidean distances of all segments in the path."
	},
	"AStar2D": {
		"brief_description": "AStar class representation that uses 2D vectors as edges.",
		"description": "This is a wrapper for the [AStar3D](../AStar3D) class which uses 2D vectors instead of 3D vectors."
	},
	"AspectRatioContainer": {
		"brief_description": "Container that preserves its child controls' aspect ratio.",
		"description": "Arranges child controls in a way to preserve their aspect ratio automatically whenever the container is resized. Solves the problem where the container size is dynamic and the contents' size needs to adjust accordingly without losing proportions."
	},
	"ArrayOccluder3D": {
		"brief_description": "3D polygon shape for use with occlusion culling in [OccluderInstance3D](../OccluderInstance3D).",
		"description": "[ArrayOccluder3D](../ArrayOccluder3D) stores an arbitrary 3D polygon shape that can be used by the engine's occlusion culling system. This is analogous to [ArrayMesh](../ArrayMesh), but for occluders.\nSee [OccluderInstance3D](../OccluderInstance3D)'s documentation for instructions on setting up occlusion culling."
	},
	"ArrayMesh": {
		"brief_description": "[Mesh](../Mesh) type that provides utility for constructing a surface from arrays.",
		"description": "The [ArrayMesh](../ArrayMesh) is used to construct a [Mesh](../Mesh) by specifying the attributes as arrays.\nThe most basic example is the creation of a single triangle:\n<!-- <codeblocks> -->\n<code>\nvar vertices = PackedVector3Array()\nvertices.push_back(Vector3(0, 1, 0))\nvertices.push_back(Vector3(1, 0, 0))\nvertices.push_back(Vector3(0, 0, 1))\n\n# Initialize the ArrayMesh.\nvar arr_mesh = ArrayMesh.new()\nvar arrays = []\narrays.resize(Mesh.ARRAY_MAX)\narrays[Mesh.ARRAY_VERTEX] = vertices\n\n# Create the Mesh.\narr_mesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, arrays)\nvar m = MeshInstance3D.new()\nm.mesh = arr_mesh\n</code>\n```csharp\nvar vertices = new Vector3[]\n{\n\tnew Vector3(0, 1, 0),\n\tnew Vector3(1, 0, 0),\n\tnew Vector3(0, 0, 1),\n};\n\n// Initialize the ArrayMesh.\nvar arrMesh = new ArrayMesh();\nvar arrays = new Godot.Collections.Array();\narrays.Resize((int)Mesh.ArrayType.Max);\narrays[(int)Mesh.ArrayType.Vertex] = vertices;\n\n// Create the Mesh.\narrMesh.AddSurfaceFromArrays(Mesh.PrimitiveType.Triangles, arrays);\nvar m = new MeshInstance3D();\nm.Mesh = arrMesh;\n```\n<!-- </codeblocks> -->\nThe [MeshInstance3D](../MeshInstance3D) is ready to be added to the [SceneTree](../SceneTree) to be shown.\nSee also [ImmediateMesh](../ImmediateMesh), [MeshDataTool](../MeshDataTool) and [SurfaceTool](../SurfaceTool) for procedural geometry generation.\n<b>Note:</b> Godot uses clockwise [winding order](https://learnopengl.com/Advanced-OpenGL/Face-culling) for front faces of triangle primitive modes."
	},
	"Array": {
		"brief_description": "A generic array datatype.",
		"description": "A generic array that can contain several elements of any type, accessible by a numerical index starting at 0. Negative indices can be used to count from the back, like in Python (-1 is the last element, -2 is the second to last, etc.).\n<b>Example:</b>\n<!-- <codeblocks> -->\n<code>\nvar array = [\"One\", 2, 3, \"Four\"]\nprint(array[0](../0)) # One.\nprint(array[2](../2)) # 3.\nprint(array[-1]) # Four.\narray[2](../2) = \"Three\"\nprint(array[-2]) # Three.\n</code>\n```csharp\nvar array = new Godot.Collections.Array{\"One\", 2, 3, \"Four\"};\nGD.Print(array[0](../0)); // One.\nGD.Print(array[2](../2)); // 3.\nGD.Print(array[array.Count - 1]); // Four.\narray[2](../2) = \"Three\";\nGD.Print(array[array.Count - 2]); // Three.\n```\n<!-- </codeblocks> -->\nArrays can be concatenated using the <code>+</code> operator:\n<!-- <codeblocks> -->\n<code>\nvar array1 = [\"One\", 2]\nvar array2 = [3, \"Four\"]\nprint(array1 + array2) # [\"One\", 2, 3, \"Four\"]\n</code>\n```csharp\n// Array concatenation is not possible with C# arrays, but is with Godot.Collections.Array.\nvar array1 = new Godot.Collections.Array{\"One\", 2};\nvar array2 = new Godot.Collections.Array{3, \"Four\"};\nGD.Print(array1 + array2); // Prints [One, 2, 3, Four]\n```\n<!-- </codeblocks> -->\n<b>Note:</b> Concatenating with the <code>+=</code> operator will create a new array, which has a cost. If you want to append another array to an existing array, <a href=\"#append_array\">append_array</a> is more efficient.\n<b>Note:</b> Arrays are always passed by reference. To get a copy of an array that can be modified independently of the original array, use <a href=\"#duplicate\">duplicate</a>.\n<b>Note:</b> Erasing elements while iterating over arrays is <b>not</b> supported and will result in unpredictable behavior."
	},
	"Area3D": {
		"brief_description": "3D area for detection, as well as physics and audio influence.",
		"description": "3D area that detects [CollisionObject3D](../CollisionObject3D) nodes overlapping, entering, or exiting. Can also alter or override local physics parameters (gravity, damping) and route audio to custom audio buses.\nTo give the area its shape, add a [CollisionShape3D](../CollisionShape3D) or a [CollisionPolygon3D](../CollisionPolygon3D) node as a <i>direct</i> child (or add multiple such nodes as direct children) of the area.\n<b>Warning:</b> See [ConcavePolygonShape3D](../ConcavePolygonShape3D) (also called \"trimesh\") for a warning about possibly unexpected behavior when using that shape for an area.\n<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"Area2D": {
		"brief_description": "2D area for detection, as well as physics and audio influence.",
		"description": "2D area that detects [CollisionObject2D](../CollisionObject2D) nodes overlapping, entering, or exiting. Can also alter or override local physics parameters (gravity, damping) and route audio to custom audio buses.\nTo give the area its shape, add a [CollisionShape2D](../CollisionShape2D) or a [CollisionPolygon2D](../CollisionPolygon2D) node as a <i>direct</i> child (or add multiple such nodes as direct children) of the area.\n<b>Warning:</b> See [ConcavePolygonShape2D](../ConcavePolygonShape2D) for a warning about possibly unexpected behavior when using that shape for an area."
	},
	"AnimationTree": {
		"brief_description": "A node to be used for advanced animation transitions in an [AnimationPlayer](../AnimationPlayer).",
		"description": "A node to be used for advanced animation transitions in an [AnimationPlayer](../AnimationPlayer).\n<b>Note:</b> When linked with an [AnimationPlayer](../AnimationPlayer), several properties and methods of the corresponding [AnimationPlayer](../AnimationPlayer) will not function as expected. Playback and transitions should be handled using only the [AnimationTree](../AnimationTree) and its constituent [AnimationNode](s). The [AnimationPlayer](../AnimationPlayer) node should be used solely for adding, deleting, and editing animations."
	},
	"AnimationTrackEditPlugin": {
		"brief_description": "",
		"description": ""
	},
	"AnimationRootNode": {
		"brief_description": "The [AnimationNode](../AnimationNode) which can be set as the root of an [AnimationTree](../AnimationTree).",
		"description": ""
	},
	"AnimationPlayer": {
		"brief_description": "Player of [Animation](../Animation) resources.",
		"description": "An animation player is used for general-purpose playback of [Animation](../Animation) resources. It contains a dictionary of [AnimationLibrary](../AnimationLibrary) resources and custom blend times between animation transitions.\nSome methods and properties use a single key to reference an animation directly. These keys are formatted as the key for the library, followed by a forward slash, then the key for the animation within the library, for example <code>\"movement/run\"</code>. If the library's key is an empty string (known as the default library), the forward slash is omitted, being the same key used by the library.\n[AnimationPlayer](../AnimationPlayer) is more suited than [Tween](../Tween) for animations where you know the final values in advance. For example, fading a screen in and out is more easily done with an [AnimationPlayer](../AnimationPlayer) node thanks to the animation tools provided by the editor. That particular example can also be implemented with a [Tween](../Tween), but it requires doing everything by code.\nUpdating the target properties of animations occurs at process time."
	},
	"AnimationNodeTransition": {
		"brief_description": "A generic animation transition node for [AnimationTree](../AnimationTree).",
		"description": "Simple state machine for cases which don't require a more advanced [AnimationNodeStateMachine](../AnimationNodeStateMachine). Animations can be connected to the inputs and transition times can be specified.\nAfter setting the request and changing the animation playback, the transition node automatically clears the request on the next process frame by setting its <code>transition_request</code> value to empty.\n<b>Note:</b> When using a cross-fade, <code>current_state</code> and <code>current_index</code> change to the next state immediately after the cross-fade begins.\n<!-- <codeblocks> -->\n<code>\n# Play child animation connected to \"state_2\" port.\nanimation_tree.set(\"parameters/Transition/transition_request\", \"state_2\")\n# Alternative syntax (same result as above).\nanimation_tree[\"parameters/Transition/transition_request\"] = \"state_2\"\n\n# Get current state name (read-only).\nanimation_tree.get(\"parameters/Transition/current_state\")\n# Alternative syntax (same result as above).\nanimation_tree[\"parameters/Transition/current_state\"]\n\n# Get current state index (read-only).\nanimation_tree.get(\"parameters/Transition/current_index\"))\n# Alternative syntax (same result as above).\nanimation_tree[\"parameters/Transition/current_index\"]\n</code>\n```csharp\n// Play child animation connected to \"state_2\" port.\nanimationTree.Set(\"parameters/Transition/transition_request\", \"state_2\");\n\n// Get current state name (read-only).\nanimationTree.Get(\"parameters/Transition/current_state\");\n\n// Get current state index (read-only).\nanimationTree.Get(\"parameters/Transition/current_index\");\n```\n<!-- </codeblocks> -->"
	},
	"AnimationNodeTimeSeek": {
		"brief_description": "A time-seeking animation node to be used with [AnimationTree](../AnimationTree).",
		"description": "This node can be used to cause a seek command to happen to any sub-children of the animation graph. Use this node type to play an [Animation](../Animation) from the start or a certain playback position inside the [AnimationNodeBlendTree](../AnimationNodeBlendTree).\nAfter setting the time and changing the animation playback, the time seek node automatically goes into sleep mode on the next process frame by setting its <code>seek_request</code> value to <code>-1.0</code>.\n<!-- <codeblocks> -->\n<code>\n# Play child animation from the start.\nanimation_tree.set(\"parameters/TimeSeek/seek_request\", 0.0)\n# Alternative syntax (same result as above).\nanimation_tree[\"parameters/TimeSeek/seek_request\"] = 0.0\n\n# Play child animation from 12 second timestamp.\nanimation_tree.set(\"parameters/TimeSeek/seek_request\", 12.0)\n# Alternative syntax (same result as above).\nanimation_tree[\"parameters/TimeSeek/seek_request\"] = 12.0\n</code>\n```csharp\n// Play child animation from the start.\nanimationTree.Set(\"parameters/TimeSeek/seek_request\", 0.0);\n\n// Play child animation from 12 second timestamp.\nanimationTree.Set(\"parameters/TimeSeek/seek_request\", 12.0);\n```\n<!-- </codeblocks> -->"
	},
	"AnimationNodeTimeScale": {
		"brief_description": "A time-scaling animation node to be used with [AnimationTree](../AnimationTree).",
		"description": "Allows scaling the speed of the animation (or reversing it) in any children nodes. Setting it to 0 will pause the animation."
	},
	"AnimationNodeSync": {
		"brief_description": "The base class for [AnimationNode](../AnimationNode) which has more than two input ports and needs to synchronize them.",
		"description": ""
	},
	"AnimationNodeStateMachineTransition": {
		"brief_description": "A resource to connect each node to make a path for [AnimationNodeStateMachine](../AnimationNodeStateMachine).",
		"description": "The path generated when using <a href=\"../AnimationNodeStateMachinePlayback#travel\">AnimationNodeStateMachinePlayback.travel<a> is limited to the nodes connected by [AnimationNodeStateMachineTransition](../AnimationNodeStateMachineTransition).\nYou can set the timing and conditions of the transition in detail."
	},
	"AnimationNodeStateMachinePlayback": {
		"brief_description": "Playback control for [AnimationNodeStateMachine](../AnimationNodeStateMachine).",
		"description": "Allows control of [AnimationTree](../AnimationTree) state machines created with [AnimationNodeStateMachine](../AnimationNodeStateMachine). Retrieve with <code>$AnimationTree.get(\"parameters/playback\")</code>.\n<b>Example:</b>\n<!-- <codeblocks> -->\n<code>\nvar state_machine = $AnimationTree.get(\"parameters/playback\")\nstate_machine.travel(\"some_state\")\n</code>\n```csharp\nvar stateMachine = GetNode<AnimationTree>(\"AnimationTree\").Get(\"parameters/playback\") as AnimationNodeStateMachinePlayback;\nstateMachine.Travel(\"some_state\");\n```\n<!-- </codeblocks> -->"
	},
	"AnimationNodeStateMachine": {
		"brief_description": "State machine for control of animations.",
		"description": "Contains multiple nodes representing animation states, connected in a graph. Node transitions can be configured to happen automatically or via code, using a shortest-path algorithm. Retrieve the [AnimationNodeStateMachinePlayback](../AnimationNodeStateMachinePlayback) object from the [AnimationTree](../AnimationTree) node to control it programmatically.\n<b>Example:</b>\n<!-- <codeblocks> -->\n<code>\nvar state_machine = $AnimationTree.get(\"parameters/playback\")\nstate_machine.travel(\"some_state\")\n</code>\n```csharp\nvar stateMachine = GetNode<AnimationTree>(\"AnimationTree\").Get(\"parameters/playback\") as AnimationNodeStateMachinePlayback;\nstateMachine.Travel(\"some_state\");\n```\n<!-- </codeblocks> -->"
	},
	"AnimationNodeOutput": {
		"brief_description": "Generic output node to be added to [AnimationNodeBlendTree](../AnimationNodeBlendTree).",
		"description": ""
	},
	"AnimationNodeOneShot": {
		"brief_description": "Plays an animation once in [AnimationNodeBlendTree](../AnimationNodeBlendTree).",
		"description": "A resource to add to an [AnimationNodeBlendTree](../AnimationNodeBlendTree). This node will execute a sub-animation and return once it finishes. Blend times for fading in and out can be customized, as well as filters.\nAfter setting the request and changing the animation playback, the one-shot node automatically clears the request on the next process frame by setting its <code>request</code> value to <a href=\"#ONE_SHOT_REQUEST_NONE\">ONE_SHOT_REQUEST_NONE</a>.\n<!-- <codeblocks> -->\n<code>\n# Play child animation connected to \"shot\" port.\nanimation_tree.set(\"parameters/OneShot/request\", AnimationNodeOneShot.ONE_SHOT_REQUEST_FIRE)\n# Alternative syntax (same result as above).\nanimation_tree[\"parameters/OneShot/request\"] = AnimationNodeOneShot.ONE_SHOT_REQUEST_FIRE\n\n# Abort child animation connected to \"shot\" port.\nanimation_tree.set(\"parameters/OneShot/request\", AnimationNodeOneShot.ONE_SHOT_REQUEST_ABORT)\n# Alternative syntax (same result as above).\nanimation_tree[\"parameters/OneShot/request\"] = AnimationNodeOneShot.ONE_SHOT_REQUEST_ABORT\n\n# Get current state (read-only).\nanimation_tree.get(\"parameters/OneShot/active\"))\n# Alternative syntax (same result as above).\nanimation_tree[\"parameters/OneShot/active\"]\n</code>\n```csharp\n// Play child animation connected to \"shot\" port.\nanimationTree.Set(\"parameters/OneShot/request\", AnimationNodeOneShot.ONE_SHOT_REQUEST_FIRE);\n\n// Abort child animation connected to \"shot\" port.\nanimationTree.Set(\"parameters/OneShot/request\", AnimationNodeOneShot.ONE_SHOT_REQUEST_ABORT);\n\n// Get current state (read-only).\nanimationTree.Get(\"parameters/OneShot/active\");\n```\n<!-- </codeblocks> -->"
	},
	"AnimationNodeBlendTree": {
		"brief_description": "[AnimationTree](../AnimationTree) node resource that contains many blend type nodes.",
		"description": "This node may contain a sub-tree of any other blend type nodes, such as [AnimationNodeTransition](../AnimationNodeTransition), [AnimationNodeBlend2](../AnimationNodeBlend2), [AnimationNodeBlend3](../AnimationNodeBlend3), [AnimationNodeOneShot](../AnimationNodeOneShot), etc. This is one of the most commonly used roots.\nAn [AnimationNodeOutput](../AnimationNodeOutput) node named <code>output</code> is created by default."
	},
	"AnimationNodeBlendSpace2D": {
		"brief_description": "Blends linearly between three [AnimationNode](../AnimationNode) of any type placed in a 2D space.",
		"description": "A resource to add to an [AnimationNodeBlendTree](../AnimationNodeBlendTree).\nThis node allows you to blend linearly between three animations using a [Vector2](../Vector2) weight.\nYou can add vertices to the blend space with <a href=\"#add_blend_point\">add_blend_point</a> and automatically triangulate it by setting <a href=\"#auto_triangles\">auto_triangles</a> to <code>true</code>. Otherwise, use <a href=\"#add_triangle\">add_triangle</a> and <a href=\"#remove_triangle\">remove_triangle</a> to create up the blend space by hand."
	},
	"AnimationNodeBlendSpace1D": {
		"brief_description": "Blends linearly between two of any number of [AnimationNode](../AnimationNode) of any type placed on a virtual axis.",
		"description": "A resource to add to an [AnimationNodeBlendTree](../AnimationNodeBlendTree).\nThis is a virtual axis on which you can add any type of [AnimationNode](../AnimationNode) using <a href=\"#add_blend_point\">add_blend_point</a>.\nOutputs the linear blend of the two [AnimationNode](../AnimationNode)s closest to the node's current value.\nYou can set the extents of the axis using the <a href=\"#min_space\">min_space</a> and <a href=\"#max_space\">max_space</a>."
	},
	"AnimationNodeBlend3": {
		"brief_description": "Blends two of three animations linearly inside of an [AnimationNodeBlendTree](../AnimationNodeBlendTree).",
		"description": "A resource to add to an [AnimationNodeBlendTree](../AnimationNodeBlendTree). Blends two animations together linearly out of three based on a value in the <code>[-1.0, 1.0]</code> range.\nThis node has three inputs:\n- The base animation\n- A -blend animation to blend with when the blend amount is in the <code>[-1.0, 0.0]</code> range.\n- A +blend animation to blend with when the blend amount is in the <code>[0.0, 1.0]</code> range"
	},
	"AnimationNodeBlend2": {
		"brief_description": "Blends two animations linearly inside of an [AnimationNodeBlendTree](../AnimationNodeBlendTree).",
		"description": "A resource to add to an [AnimationNodeBlendTree](../AnimationNodeBlendTree). Blends two animations linearly based on an amount value in the <code>[0.0, 1.0]</code> range."
	},
	"AnimationNodeAnimation": {
		"brief_description": "Input animation to use in an [AnimationNodeBlendTree](../AnimationNodeBlendTree).",
		"description": "A resource to add to an [AnimationNodeBlendTree](../AnimationNodeBlendTree). Only features one output set using the <a href=\"#animation\">animation</a> property. Use it as an input for [AnimationNode](../AnimationNode) that blend animations together."
	},
	"AnimationNodeAdd3": {
		"brief_description": "Blends two of three animations additively inside of an [AnimationNodeBlendTree](../AnimationNodeBlendTree).",
		"description": "A resource to add to an [AnimationNodeBlendTree](../AnimationNodeBlendTree). Blends two animations together additively out of three based on a value in the <code>[-1.0, 1.0]</code> range.\nThis node has three inputs:\n- The base animation to add to\n- A -add animation to blend with when the blend amount is in the <code>[-1.0, 0.0]</code> range.\n- A +add animation to blend with when the blend amount is in the <code>[0.0, 1.0]</code> range"
	},
	"AnimationNodeAdd2": {
		"brief_description": "Blends two animations additively inside of an [AnimationNodeBlendTree](../AnimationNodeBlendTree).",
		"description": "A resource to add to an [AnimationNodeBlendTree](../AnimationNodeBlendTree). Blends two animations additively based on an amount value in the <code>[0.0, 1.0]</code> range."
	},
	"AnimationNode": {
		"brief_description": "Base resource for [AnimationTree](../AnimationTree) nodes.",
		"description": "Base resource for [AnimationTree](../AnimationTree) nodes. In general, it's not used directly, but you can create custom ones with custom blending formulas.\nInherit this when creating nodes mainly for use in [AnimationNodeBlendTree](../AnimationNodeBlendTree), otherwise [AnimationRootNode](../AnimationRootNode) should be used instead."
	},
	"AnimationLibrary": {
		"brief_description": "Container for [Animation](../Animation) resources.",
		"description": "An animation library stores a set of animations accessible through [StringName](../StringName) keys, for use with [AnimationPlayer](../AnimationPlayer) nodes."
	},
	"Animation": {
		"brief_description": "Contains data used to animate everything in the engine.",
		"description": "An Animation resource contains data used to animate everything in the engine. Animations are divided into tracks, and each track must be linked to a node. The state of that node can be changed through time, by adding timed keys (events) to the track.\n<!-- <codeblocks> -->\n<code>\n# This creates an animation that makes the node \"Enemy\" move to the right by\n# 100 pixels in 0.5 seconds.\nvar animation = Animation.new()\nvar track_index = animation.add_track(Animation.TYPE_VALUE)\nanimation.track_set_path(track_index, \"Enemy:position:x\")\nanimation.track_insert_key(track_index, 0.0, 0)\nanimation.track_insert_key(track_index, 0.5, 100)\n</code>\n```csharp\n// This creates an animation that makes the node \"Enemy\" move to the right by\n// 100 pixels in 0.5 seconds.\nvar animation = new Animation();\nint trackIndex = animation.AddTrack(Animation.TrackType.Value);\nanimation.TrackSetPath(trackIndex, \"Enemy:position:x\");\nanimation.TrackInsertKey(trackIndex, 0.0f, 0);\nanimation.TrackInsertKey(trackIndex, 0.5f, 100);\n```\n<!-- </codeblocks> -->\nAnimations are just data containers, and must be added to nodes such as an [AnimationPlayer](../AnimationPlayer) to be played back. Animation tracks have different types, each with its own set of dedicated methods. Check <a href=\"#TrackType\">TrackType</a> to see available types.\n<b>Note:</b> For 3D position/rotation/scale, using the dedicated <a href=\"#TYPE_POSITION_3D\">TYPE_POSITION_3D</a>, <a href=\"#TYPE_ROTATION_3D\">TYPE_ROTATION_3D</a> and <a href=\"#TYPE_SCALE_3D\">TYPE_SCALE_3D</a> track types instead of <a href=\"#TYPE_VALUE\">TYPE_VALUE</a> is recommended for performance reasons."
	},
	"AnimatedTexture": {
		"brief_description": "Proxy texture for simple frame-based animations.",
		"description": "[AnimatedTexture](../AnimatedTexture) is a resource format for frame-based animations, where multiple textures can be chained automatically with a predefined delay for each frame. Unlike [AnimationPlayer](../AnimationPlayer) or [AnimatedSprite2D](../AnimatedSprite2D), it isn't a [Node](../Node), but has the advantage of being usable anywhere a [Texture2D](../Texture2D) resource can be used, e.g. in a [TileSet](../TileSet).\nThe playback of the animation is controlled by the <a href=\"#speed_scale\">speed_scale</a> property, as well as each frame's duration (see <a href=\"#set_frame_duration\">set_frame_duration</a>). The animation loops, i.e. it will restart at frame 0 automatically after playing the last frame.\n[AnimatedTexture](../AnimatedTexture) currently requires all frame textures to have the same size, otherwise the bigger ones will be cropped to match the smallest one.\n<b>Note:</b> AnimatedTexture doesn't support using [AtlasTexture](../AtlasTexture)s. Each frame needs to be a separate [Texture2D](../Texture2D).\n<b>Warning:</b> AnimatedTexture is deprecated, and might be removed in a future release. Its current implementation is not efficient for the modern renderers."
	},
	"AnimatedSprite3D": {
		"brief_description": "2D sprite node in 3D world, that can use multiple 2D textures for animation.",
		"description": "[AnimatedSprite3D](../AnimatedSprite3D) is similar to the [Sprite3D](../Sprite3D) node, except it carries multiple textures as animation <a href=\"#sprite_frames\">sprite_frames</a>. Animations are created using a [SpriteFrames](../SpriteFrames) resource, which allows you to import image files (or a folder containing said files) to provide the animation frames for the sprite. The [SpriteFrames](../SpriteFrames) resource can be configured in the editor via the SpriteFrames bottom panel."
	},
	"AnimatedSprite2D": {
		"brief_description": "Sprite node that contains multiple textures as frames to play for animation.",
		"description": "[AnimatedSprite2D](../AnimatedSprite2D) is similar to the [Sprite2D](../Sprite2D) node, except it carries multiple textures as animation frames. Animations are created using a [SpriteFrames](../SpriteFrames) resource, which allows you to import image files (or a folder containing said files) to provide the animation frames for the sprite. The [SpriteFrames](../SpriteFrames) resource can be configured in the editor via the SpriteFrames bottom panel."
	},
	"AnimatableBody3D": {
		"brief_description": "Physics body for 3D physics which moves only by script or animation. Useful for moving platforms and doors.",
		"description": "Animatable body for 3D physics.\nAn animatable body can't be moved by external forces or contacts, but can be moved by script or animation to affect other bodies in its path. It is ideal for implementing moving objects in the environment, such as moving platforms or doors.\nWhen the body is moved manually, either from code or from an [AnimationPlayer](../AnimationPlayer) (with <a href=\"../AnimationPlayer#playback_process_mode\">AnimationPlayer.playback_process_mode<a> set to <code>physics</code>), the physics will automatically compute an estimate of their linear and angular velocity. This makes them very useful for moving platforms or other AnimationPlayer-controlled objects (like a door, a bridge that opens, etc).\n<b>Warning:</b> With a non-uniform scale this node will probably not function as expected. Please make sure to keep its scale uniform (i.e. the same on all axes), and change the size(s) of its collision shape(s) instead."
	},
	"AnimatableBody2D": {
		"brief_description": "Physics body for 2D physics which moves only by script or animation. Useful for moving platforms and doors.",
		"description": "Animatable body for 2D physics.\nAn animatable body can't be moved by external forces or contacts, but can be moved by script or animation to affect other bodies in its path. It is ideal for implementing moving objects in the environment, such as moving platforms or doors.\nWhen the body is moved manually, either from code or from an [AnimationPlayer](../AnimationPlayer) (with <a href=\"../AnimationPlayer#playback_process_mode\">AnimationPlayer.playback_process_mode<a> set to <code>physics</code>), the physics will automatically compute an estimate of their linear and angular velocity. This makes them very useful for moving platforms or other AnimationPlayer-controlled objects (like a door, a bridge that opens, etc)."
	},
	"AESContext": {
		"brief_description": "Interface to low level AES encryption features.",
		"description": "This class provides access to AES encryption/decryption of raw data. Both AES-ECB and AES-CBC mode are supported.\n<!-- <codeblocks> -->\n<code>\nextends Node\n\nvar aes = AESContext.new()\n\nfunc _ready():\n\tvar key = \"My secret key!!!\" # Key must be either 16 or 32 bytes.\n\tvar data = \"My secret text!!\" # Data size must be multiple of 16 bytes, apply padding if needed.\n\t# Encrypt ECB\n\taes.start(AESContext.MODE_ECB_ENCRYPT, key.to_utf8())\n\tvar encrypted = aes.update(data.to_utf8())\n\taes.finish()\n\t# Decrypt ECB\n\taes.start(AESContext.MODE_ECB_DECRYPT, key.to_utf8())\n\tvar decrypted = aes.update(encrypted)\n\taes.finish()\n\t# Check ECB\n\tassert(decrypted == data.to_utf8())\n\n\tvar iv = \"My secret iv!!!!\" # IV must be of exactly 16 bytes.\n\t# Encrypt CBC\n\taes.start(AESContext.MODE_CBC_ENCRYPT, key.to_utf8(), iv.to_utf8())\n\tencrypted = aes.update(data.to_utf8())\n\taes.finish()\n\t# Decrypt CBC\n\taes.start(AESContext.MODE_CBC_DECRYPT, key.to_utf8(), iv.to_utf8())\n\tdecrypted = aes.update(encrypted)\n\taes.finish()\n\t# Check CBC\n\tassert(decrypted == data.to_utf8())\n</code>\n```csharp\nusing Godot;\nusing System.Diagnostics;\n\npublic partial class MyNode : Node\n{\n\tprivate AesContext _aes = new AesContext();\n\n\tpublic override void _Ready()\n\t{\n\t\tstring key = \"My secret key!!!\"; // Key must be either 16 or 32 bytes.\n\t\tstring data = \"My secret text!!\"; // Data size must be multiple of 16 bytes, apply padding if needed.\n\t\t// Encrypt ECB\n\t\t_aes.Start(AesContext.Mode.EcbEncrypt, key.ToUtf8());\n\t\tbyte[] encrypted = _aes.Update(data.ToUtf8());\n\t\t_aes.Finish();\n\t\t// Decrypt ECB\n\t\t_aes.Start(AesContext.Mode.EcbDecrypt, key.ToUtf8());\n\t\tbyte[] decrypted = _aes.Update(encrypted);\n\t\t_aes.Finish();\n\t\t// Check ECB\n\t\tDebug.Assert(decrypted == data.ToUtf8());\n\n\t\tstring iv = \"My secret iv!!!!\"; // IV must be of exactly 16 bytes.\n\t\t// Encrypt CBC\n\t\t_aes.Start(AesContext.Mode.EcbEncrypt, key.ToUtf8(), iv.ToUtf8());\n\t\tencrypted = _aes.Update(data.ToUtf8());\n\t\t_aes.Finish();\n\t\t// Decrypt CBC\n\t\t_aes.Start(AesContext.Mode.EcbDecrypt, key.ToUtf8(), iv.ToUtf8());\n\t\tdecrypted = _aes.Update(encrypted);\n\t\t_aes.Finish();\n\t\t// Check CBC\n\t\tDebug.Assert(decrypted == data.ToUtf8());\n\t}\n}\n```\n<!-- </codeblocks> -->"
	},
	"AcceptDialog": {
		"brief_description": "Base dialog for user notification.",
		"description": "This dialog is useful for small notifications to the user about an event. It can only be accepted or closed, with the same result."
	},
	"AABB": {
		"brief_description": "Axis-Aligned Bounding Box.",
		"description": "[AABB](../AABB) consists of a position, a size, and several utility functions. It is typically used for fast overlap tests.\nIt uses floating-point coordinates. The 2D counterpart to [AABB](../AABB) is [Rect2](../Rect2).\nNegative values for <a href=\"#size\">size</a> are not supported and will not work for most methods. Use <a href=\"#abs\">abs</a> to get an AABB with a positive size.\n<b>Note:</b> Unlike [Rect2](../Rect2), [AABB](../AABB) does not have a variant that uses integer coordinates."
	},
	"@GlobalScope": {
		"brief_description": "Global scope constants and functions.",
		"description": "A list of global scope enumerated constants and built-in functions. This is all that resides in the globals, constants regarding error codes, keycodes, property hints, etc.\nSingletons are also documented here, since they can be accessed from anywhere.\nFor the entries related to GDScript which can be accessed in any script see [@GDScript]."
	},
	"ZIPReader": {
		"brief_description": "Allows reading the content of a zip file.",
		"description": "This class implements a reader that can extract the content of individual files inside a zip archive.\n<code>\nfunc read_zip_file():\n\tvar reader := ZIPReader.new()\n\tvar err := reader.open(\"user://archive.zip\")\n\tif err != OK:\n\t\treturn PackedByteArray()\n\tvar res := reader.read_file(\"hello.txt\")\n\treader.close()\n\treturn res\n</code>"
	},
	"ZIPPacker": {
		"brief_description": "Allows the creation of zip files.",
		"description": "This class implements a writer that allows storing the multiple blobs in a zip archive.\n<code>\nfunc write_zip_file():\n\tvar writer := ZIPPacker.new()\n\tvar err := writer.open(\"user://archive.zip\")\n\tif err != OK:\n\t\treturn err\n\twriter.start_file(\"hello.txt\")\n\twriter.write_file(\"Hello World\".to_utf8_buffer())\n\twriter.close_file()\n\n\twriter.close()\n\treturn OK\n</code>"
	},
	"WebXRInterface": {
		"brief_description": "XR interface using WebXR.",
		"description": "WebXR is an open standard that allows creating VR and AR applications that run in the web browser.\nAs such, this interface is only available when running in Web exports.\nWebXR supports a wide range of devices, from the very capable (like Valve Index, HTC Vive, Oculus Rift and Quest) down to the much less capable (like Google Cardboard, Oculus Go, GearVR, or plain smartphones).\nSince WebXR is based on JavaScript, it makes extensive use of callbacks, which means that [WebXRInterface](../WebXRInterface) is forced to use signals, where other XR interfaces would instead use functions that return a result immediately. This makes [WebXRInterface](../WebXRInterface) quite a bit more complicated to initialize than other XR interfaces.\nHere's the minimum code required to start an immersive VR session:\n<code>\nextends Node3D\n\nvar webxr_interface\nvar vr_supported = false\n\nfunc _ready():\n\t# We assume this node has a button as a child.\n\t# This button is for the user to consent to entering immersive VR mode.\n\t$Button.pressed.connect(self._on_button_pressed)\n\n\twebxr_interface = XRServer.find_interface(\"WebXR\")\n\tif webxr_interface:\n\t\t# WebXR uses a lot of asynchronous callbacks, so we connect to various\n\t\t# signals in order to receive them.\n\t\twebxr_interface.session_supported.connect(self._webxr_session_supported)\n\t\twebxr_interface.session_started.connect(self._webxr_session_started)\n\t\twebxr_interface.session_ended.connect(self._webxr_session_ended)\n\t\twebxr_interface.session_failed.connect(self._webxr_session_failed)\n\n\t\t# This returns immediately - our _webxr_session_supported() method\n\t\t# (which we connected to the \"session_supported\" signal above) will\n\t\t# be called sometime later to let us know if it's supported or not.\n\t\twebxr_interface.is_session_supported(\"immersive-vr\")\n\nfunc _webxr_session_supported(session_mode, supported):\n\tif session_mode == 'immersive-vr':\n\t\tvr_supported = supported\n\nfunc _on_button_pressed():\n\tif not vr_supported:\n\t\tOS.alert(\"Your browser doesn't support VR\")\n\t\treturn\n\n\t# We want an immersive VR session, as opposed to AR ('immersive-ar') or a\n\t# simple 3DoF viewer ('viewer').\n\twebxr_interface.session_mode = 'immersive-vr'\n\t# 'bounded-floor' is room scale, 'local-floor' is a standing or sitting\n\t# experience (it puts you 1.6m above the ground if you have 3DoF headset),\n\t# whereas as 'local' puts you down at the XROrigin.\n\t# This list means it'll first try to request 'bounded-floor', then\n\t# fallback on 'local-floor' and ultimately 'local', if nothing else is\n\t# supported.\n\twebxr_interface.requested_reference_space_types = 'bounded-floor, local-floor, local'\n\t# In order to use 'local-floor' or 'bounded-floor' we must also\n\t# mark the features as required or optional.\n\twebxr_interface.required_features = 'local-floor'\n\twebxr_interface.optional_features = 'bounded-floor'\n\n\t# This will return false if we're unable to even request the session,\n\t# however, it can still fail asynchronously later in the process, so we\n\t# only know if it's really succeeded or failed when our\n\t# _webxr_session_started() or _webxr_session_failed() methods are called.\n\tif not webxr_interface.initialize():\n\t\tOS.alert(\"Failed to initialize\")\n\t\treturn\n\nfunc _webxr_session_started():\n\t$Button.visible = false\n\t# This tells Godot to start rendering to the headset.\n\tget_viewport().use_xr = true\n\t# This will be the reference space type you ultimately got, out of the\n\t# types that you requested above. This is useful if you want the game to\n\t# work a little differently in 'bounded-floor' versus 'local-floor'.\n\tprint (\"Reference space type: \" + webxr_interface.reference_space_type)\n\nfunc _webxr_session_ended():\n\t$Button.visible = true\n\t# If the user exits immersive mode, then we tell Godot to render to the web\n\t# page again.\n\tget_viewport().use_xr = false\n\nfunc _webxr_session_failed(message):\n\tOS.alert(\"Failed to initialize: \" + message)\n</code>\nThere are a couple ways to handle \"controller\" input:\n- Using [XRController3D](../XRController3D) nodes and their <a href=\"../XRController3D#button_pressed\">XRController3D.button_pressed<a> and <a href=\"../XRController3D#button_released\">XRController3D.button_released<a> signals. This is how controllers are typically handled in XR apps in Godot, however, this will only work with advanced VR controllers like the Oculus Touch or Index controllers, for example.\n- Using the <a href=\"#select\">select</a>, <a href=\"#squeeze\">squeeze</a> and related signals. This method will work for both advanced VR controllers, and non-traditional input sources like a tap on the screen, a spoken voice command or a button press on the device itself.\nYou can use both methods to allow your game or app to support a wider or narrower set of devices and input methods, or to allow more advanced interactions with more advanced devices."
	},
	"WebSocketPeer": {
		"brief_description": "A WebSocket connection.",
		"description": "This class represents WebSocket connection, and can be used as a WebSocket client (RFC 6455-compliant) or as a remote peer of a WebSocket server.\nYou can send WebSocket binary frames using <a href=\"../PacketPeer#put_packet\">PacketPeer.put_packet<a>, and WebSocket text frames using <a href=\"#send\">send</a> (prefer text frames when interacting with text-based API). You can check the frame type of the last packet via <a href=\"#was_string_packet\">was_string_packet</a>.\nTo start a WebSocket client, first call <a href=\"#connect_to_url\">connect_to_url</a>, then regularly call <a href=\"#poll\">poll</a> (e.g. during [Node](../Node) process). You can query the socket state via <a href=\"#get_ready_state\">get_ready_state</a>, get the number of pending packets using <a href=\"../PacketPeer#get_available_packet_count\">PacketPeer.get_available_packet_count<a>, and retrieve them via <a href=\"../PacketPeer#get_packet\">PacketPeer.get_packet<a>.\n<!-- <codeblocks> -->\n<code>\nextends Node\n\nvar socket = WebSocketPeer.new()\n\nfunc _ready():\n\tsocket.connect_to_url(\"wss://example.com\")\n\nfunc _process(delta):\n\tsocket.poll()\n\tvar state = socket.get_ready_state()\n\tif state == WebSocketPeer.STATE_OPEN:\n\t\twhile socket.get_available_packet_count():\n\t\t\tprint(\"Packet: \", socket.get_packet())\n\telif state == WebSocketPeer.STATE_CLOSING:\n\t\t# Keep polling to achieve proper close.\n\t\tpass\n\telif state == WebSocketPeer.STATE_CLOSED:\n\t\tvar code = socket.get_close_code()\n\t\tvar reason = socket.get_close_reason()\n\t\tprint(\"WebSocket closed with code: %d, reason %s. Clean: %s\" % [code, reason, code != -1])\n\t\tset_process(false) # Stop processing.\n</code>\n<!-- </codeblocks> -->\nTo use the peer as part of a WebSocket server refer to <a href=\"#accept_stream\">accept_stream</a> and the online tutorial."
	},
	"WebSocketMultiplayerPeer": {
		"brief_description": "Base class for WebSocket server and client.",
		"description": "Base class for WebSocket server and client, allowing them to be used as multiplayer peer for the [MultiplayerAPI](../MultiplayerAPI).\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"WebRTCPeerConnectionExtension": {
		"brief_description": "",
		"description": ""
	},
	"WebRTCPeerConnection": {
		"brief_description": "Interface to a WebRTC peer connection.",
		"description": "A WebRTC connection between the local computer and a remote peer. Provides an interface to connect, maintain and monitor the connection.\nSetting up a WebRTC connection between two peers from now on) may not seem a trivial task, but it can be broken down into 3 main steps:\n- The peer that wants to initiate the connection (<code>A</code> from now on) creates an offer and send it to the other peer (<code>B</code> from now on).\n- <code>B</code> receives the offer, generate and answer, and sends it to <code>A</code>).\n- <code>A</code> and <code>B</code> then generates and exchange ICE candidates with each other.\nAfter these steps, the connection should become connected. Keep on reading or look into the tutorial for more information."
	},
	"WebRTCMultiplayerPeer": {
		"brief_description": "A simple interface to create a peer-to-peer mesh network composed of [WebRTCPeerConnection](../WebRTCPeerConnection) that is compatible with the [MultiplayerAPI](../MultiplayerAPI).",
		"description": "This class constructs a full mesh of [WebRTCPeerConnection](../WebRTCPeerConnection) (one connection for each peer) that can be used as a <a href=\"../MultiplayerAPI#multiplayer_peer\">MultiplayerAPI.multiplayer_peer<a>.\nYou can add each [WebRTCPeerConnection](../WebRTCPeerConnection) via <a href=\"#add_peer\">add_peer</a> or remove them via <a href=\"#remove_peer\">remove_peer</a>. Peers must be added in <a href=\"../WebRTCPeerConnection#STATE_NEW\">WebRTCPeerConnection.STATE_NEW<a> state to allow it to create the appropriate channels. This class will not create offers nor set descriptions, it will only poll them, and notify connections and disconnections.\nWhen creating the peer via <a href=\"#create_client\">create_client</a> or <a href=\"#create_server\">create_server</a> the <a href=\"../MultiplayerPeer#is_server_relay_supported\">MultiplayerPeer.is_server_relay_supported<a> method will return <code>true</code> enabling peer exchange and packet relaying when supported by the [MultiplayerAPI](../MultiplayerAPI) implementation.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"WebRTCDataChannelExtension": {
		"brief_description": "",
		"description": ""
	},
	"WebRTCDataChannel": {
		"brief_description": "",
		"description": ""
	},
	"AudioStreamPlaybackOggVorbis": {
		"brief_description": "",
		"description": ""
	},
	"AudioStreamOggVorbis": {
		"brief_description": "",
		"description": ""
	},
	"UPNPDevice": {
		"brief_description": "Universal Plug and Play (UPnP) device.",
		"description": "Universal Plug and Play (UPnP) device. See [UPNP](../UPNP) for UPnP discovery and utility functions. Provides low-level access to UPNP control commands. Allows to manage port mappings (port forwarding) and to query network information of the device (like local and external IP address and status). Note that methods on this class are synchronous and block the calling thread."
	},
	"UPNP": {
		"brief_description": "Universal Plug and Play (UPnP) functions for network device discovery, querying and port forwarding.",
		"description": "This class can be used to discover compatible [UPNPDevice](../UPNPDevice)s on the local network and execute commands on them, like managing port mappings (for port forwarding/NAT traversal) and querying the local and remote network IP address. Note that methods on this class are synchronous and block the calling thread.\nTo forward a specific port (here <code>7777</code>, note both <a href=\"#discover\">discover</a> and <a href=\"#add_port_mapping\">add_port_mapping</a> can return errors that should be checked):\n<code>\nvar upnp = UPNP.new()\nupnp.discover()\nupnp.add_port_mapping(7777)\n</code>\nTo close a specific port (e.g. after you have finished using it):\n<code>\nupnp.delete_port_mapping(port)\n</code>\n<b>Note:</b> UPnP discovery blocks the current thread. To perform discovery without blocking the main thread, use [Thread](../Thread)s like this:\n<code>\n# Emitted when UPnP port mapping setup is completed (regardless of success or failure).\nsignal upnp_completed(error)\n\n# Replace this with your own server port number between 1024 and 65535.\nconst SERVER_PORT = 3928\nvar thread = null\n\nfunc _upnp_setup(server_port):\n\t# UPNP queries take some time.\n\tvar upnp = UPNP.new()\n\tvar err = upnp.discover()\n\n\tif err != OK:\n\t\tpush_error(str(err))\n\t\temit_signal(\"upnp_completed\", err)\n\t\treturn\n\n\tif upnp.get_gateway() and upnp.get_gateway().is_valid_gateway():\n\t\tupnp.add_port_mapping(server_port, server_port, ProjectSettings.get_setting(\"application/config/name\"), \"UDP\")\n\t\tupnp.add_port_mapping(server_port, server_port, ProjectSettings.get_setting(\"application/config/name\"), \"TCP\")\n\t\temit_signal(\"upnp_completed\", OK)\n\nfunc _ready():\n\tthread = Thread.new()\n\tthread.start(_upnp_setup.bind(SERVER_PORT))\n\nfunc _exit_tree():\n\t# Wait for thread finish here to handle game exit while the thread is running.\n\tthread.wait_to_finish()\n</code>\n<b>Terminology:</b> In the context of UPnP networking, \"gateway\" (or \"internet gateway device\", short IGD) refers to network devices that allow computers in the local network to access the internet (\"wide area network\", WAN). These gateways are often also called \"routers\".\n<b>Pitfalls:</b>\n- As explained above, these calls are blocking and shouldn't be run on the main thread, especially as they can block for multiple seconds at a time. Use threading!\n- Networking is physical and messy. Packets get lost in transit or get filtered, addresses, free ports and assigned mappings change, and devices may leave or join the network at any time. Be mindful of this, be diligent when checking and handling errors, and handle these gracefully if you can: add clear error UI, timeouts and re-try handling.\n- Port mappings may change (and be removed) at any time, and the remote/external IP address of the gateway can change likewise. You should consider re-querying the external IP and try to update/refresh the port mapping periodically (for example, every 5 minutes and on networking failures).\n- Not all devices support UPnP, and some users disable UPnP support. You need to handle this (e.g. documenting and requiring the user to manually forward ports, or adding alternative methods of NAT traversal, like a relay/mirror server, or NAT hole punching, STUN/TURN, etc.).\n- Consider what happens on mapping conflicts. Maybe multiple users on the same network would like to play your game at the same time, or maybe another application uses the same port. Make the port configurable, and optimally choose a port automatically (re-trying with a different port on failure).\n<b>Further reading:</b> If you want to know more about UPnP (and the Internet Gateway Device (IGD) and Port Control Protocol (PCP) specifically), [Wikipedia](https://en.wikipedia.org/wiki/Universal_Plug_and_Play) is a good first stop, the specification can be found at the [Open Connectivity Foundation](https://openconnectivity.org/developer/specifications/upnp-resources/upnp/) and Godot's implementation is based on the [MiniUPnP client](https://github.com/miniupnp/miniupnp)."
	},
	"VideoStreamTheora": {
		"brief_description": "[VideoStream](../VideoStream) resource for Ogg Theora videos.",
		"description": "[VideoStream](../VideoStream) resource handling the [Ogg Theora](https://www.theora.org/) video format with <code>.ogv</code> extension. The Theora codec is decoded on the CPU.\n<b>Note:</b> While Ogg Theora videos can also have an <code>.ogg</code> extension, you will have to rename the extension to <code>.ogv</code> to use those videos within Godot."
	},
	"TextServerFallback": {
		"brief_description": "Fallback implementation of the Text Server, without BiDi and complex text layout support.",
		"description": ""
	},
	"TextServerAdvanced": {
		"brief_description": "Text Server using HarfBuzz, ICU and SIL Graphite to support BiDi, complex text layouts and contextual OpenType features.",
		"description": ""
	},
	"RegExMatch": {
		"brief_description": "Contains the results of a [RegEx](../RegEx) search.",
		"description": "Contains the results of a single [RegEx](../RegEx) match returned by <a href=\"../RegEx#search\">RegEx.search<a> and <a href=\"../RegEx#search_all\">RegEx.search_all<a>. It can be used to find the position and range of the match and its capturing groups, and it can extract its substring for you."
	},
	"RegEx": {
		"brief_description": "Class for searching text for patterns using regular expressions.",
		"description": "A regular expression (or regex) is a compact language that can be used to recognize strings that follow a specific pattern, such as URLs, email addresses, complete sentences, etc. For example, a regex of <code>ab[0-9]</code> would find any string that is <code>ab</code> followed by any number from <code>0</code> to <code>9</code>. For a more in-depth look, you can easily find various tutorials and detailed explanations on the Internet.\nTo begin, the RegEx object needs to be compiled with the search pattern using <a href=\"#compile\">compile</a> before it can be used.\n<code>\nvar regex = RegEx.new()\nregex.compile(\"\\\\w-(\\\\d+)\")\n</code>\nThe search pattern must be escaped first for GDScript before it is escaped for the expression. For example, <code>compile(\"\\\\d+\")</code> would be read by RegEx as <code>\\d+</code>. Similarly, <code>compile(\"\\\"(?:\\\\\\\\.|[^\\\"])*\\\"\")</code> would be read as <code>\"(?:\\\\.|[^\"])*\"</code>.\nUsing <a href=\"#search\">search</a>, you can find the pattern within the given text. If a pattern is found, [RegExMatch](../RegExMatch) is returned and you can retrieve details of the results using methods such as <a href=\"../RegExMatch#get_string\">RegExMatch.get_string<a> and <a href=\"../RegExMatch#get_start\">RegExMatch.get_start<a>.\n<code>\nvar regex = RegEx.new()\nregex.compile(\"\\\\w-(\\\\d+)\")\nvar result = regex.search(\"abc n-0123\")\nif result:\n\tprint(result.get_string()) # Would print n-0123\n</code>\nThe results of capturing groups <code>()</code> can be retrieved by passing the group number to the various methods in [RegExMatch](../RegExMatch). Group 0 is the default and will always refer to the entire pattern. In the above example, calling <code>result.get_string(1)</code> would give you <code>0123</code>.\nThis version of RegEx also supports named capturing groups, and the names can be used to retrieve the results. If two or more groups have the same name, the name would only refer to the first one with a match.\n<code>\nvar regex = RegEx.new()\nregex.compile(\"d(?<digit>[0-9]+)|x(?<digit>[0-9a-f]+)\")\nvar result = regex.search(\"the number is x2f\")\nif result:\n\tprint(result.get_string(\"digit\")) # Would print 2f\n</code>\nIf you need to process multiple results, <a href=\"#search_all\">search_all</a> generates a list of all non-overlapping results. This can be combined with a <code>for</code> loop for convenience.\n<code>\nfor result in regex.search_all(\"d01, d03, d0c, x3f and x42\"):\n\tprint(result.get_string(\"digit\"))\n# Would print 01 03 0 3f 42\n</code>\n<b>Example of splitting a string using a RegEx:</b>\n<code>\nvar regex = RegEx.new()\nregex.compile(\"\\\\S+\") # Negated whitespace character class.\nvar results = []\nfor result in regex.search_all(\"One  Two \\n\\tThree\"):\n\tresults.push_back(result.get_string())\n# The `results` array now contains \"One\", \"Two\", \"Three\".\n</code>\n<b>Note:</b> Godot's regex implementation is based on the [PCRE2](https://www.pcre.org/) library. You can view the full pattern reference [here](https://www.pcre.org/current/doc/html/pcre2pattern.html).\n<b>Tip:</b> You can use [Regexr](https://regexr.com/) to test regular expressions online."
	},
	"OpenXRIPBinding": {
		"brief_description": "Defines a binding between an [OpenXRAction](../OpenXRAction) and an XR input or output.",
		"description": "This binding resource binds an [OpenXRAction](../OpenXRAction) to inputs or outputs. As most controllers have left hand and right versions that are handled by the same interaction profile we can specify multiple bindings. For instance an action \"Fire\" could be bound to both \"/user/hand/left/input/trigger\" and \"/user/hand/right/input/trigger\"."
	},
	"OpenXRInterface": {
		"brief_description": "Our OpenXR interface.",
		"description": "The OpenXR interface allows Godot to interact with OpenXR runtimes and make it possible to create XR experiences and games.\nDue to the needs of OpenXR this interface works slightly different than other plugin based XR interfaces. It needs to be initialized when Godot starts. You need to enable OpenXR, settings for this can be found in your games project settings under the XR heading. You do need to mark a viewport for use with XR in order for Godot to know which render result should be output to the headset."
	},
	"OpenXRInteractionProfile": {
		"brief_description": "Suggested bindings object for OpenXR.",
		"description": "This object stores suggested bindings for an interaction profile. Interaction profiles define the meta data for a tracked XR device such as an XR controller.\nFor more information see the [interaction profiles info in the OpenXR specification](https://www.khronos.org/registry/OpenXR/specs/1.0/html/xrspec.html#semantic-path-interaction-profiles)."
	},
	"OpenXRHand": {
		"brief_description": "Node supporting finger tracking in OpenXR.",
		"description": "This node enables OpenXR's hand tracking functionality. The node should be a child node of an [XROrigin3D](../XROrigin3D) node, tracking will update its position to where the player's actual hand is positioned. This node also updates the skeleton of a properly skinned hand model. The hand mesh should be a child node of this node."
	},
	"OpenXRActionSet": {
		"brief_description": "Collection of [OpenXRAction](../OpenXRAction) resources that make up an action set.",
		"description": "Action sets in OpenXR define a collection of actions that can be activated in unison. This allows games to easily change between different states that require different inputs or need to reinterpret inputs. For instance we could have an action set that is active when a menu is open, an action set that is active when the player is freely walking around and an action set that is active when the player is controlling a vehicle.\nAction sets can contain the same action with the same name, if such action sets are active at the same time the action set with the highest priority defines which binding is active."
	},
	"OpenXRActionMap": {
		"brief_description": "Collection of [OpenXRActionSet](../OpenXRActionSet) and [OpenXRInteractionProfile](../OpenXRInteractionProfile) resources for the OpenXR module.",
		"description": "OpenXR uses an action system similar to Godots Input map system to bind inputs and outputs on various types of XR controllers to named actions. OpenXR specifies more detail on these inputs and outputs than Godot supports.\nAnother important distinction is that OpenXR offers no control over these bindings. The bindings we register are suggestions, it is up to the XR runtime to offer users the ability to change these bindings. This allows the XR runtime to fill in the gaps if new hardware becomes available.\nThe action map therefore needs to be loaded at startup and can't be changed afterwards. This resource is a container for the entire action map."
	},
	"OpenXRAction": {
		"brief_description": "An OpenXR action.",
		"description": "This resource defines an OpenXR action. Actions can be used both for inputs (buttons/joystick/trigger/etc) and outputs (haptics).\nOpenXR performs automatic conversion between action type and input type whenever possible. An analog trigger bound to a boolean action will thus return <code>false</code> if the trigger is depressed and <code>true</code> if pressed fully.\nActions are not directly bound to specific devices, instead OpenXR recognizes a limited number of top level paths that identify devices by usage. We can restrict which devices an action can be bound to by these top level paths. For instance an action that should only be used for hand held controllers can have the top level paths \"/user/hand/left\" and \"/user/hand/right\" associated with them. See the [reserved path section in the OpenXR specification](https://www.khronos.org/registry/OpenXR/specs/1.0/html/xrspec.html#semantic-path-reserved) for more info on the top level paths.\nNote that the name of the resource is used to register the action with."
	},
	"OggPacketSequencePlayback": {
		"brief_description": "",
		"description": ""
	},
	"OggPacketSequence": {
		"brief_description": "A sequence of Ogg packets.",
		"description": "A sequence of Ogg packets."
	},
	"NoiseTexture2D": {
		"brief_description": "A texture filled with noise generated by a [Noise](../Noise) object.",
		"description": "Uses [FastNoiseLite](../FastNoiseLite) or other libraries to fill the texture data of your desired size.\nNoiseTexture2D can also generate normalmap textures.\nThe class uses [Thread](../Thread)s to generate the texture data internally, so <a href=\"../Texture2D#get_image\">Texture2D.get_image<a> may return <code>null</code> if the generation process has not completed yet. In that case, you need to wait for the texture to be generated before accessing the image and the generated byte data:\n<code>\nvar texture = NoiseTexture2D.new()\ntexture.noise = FastNoiseLite.new()\nawait texture.changed\nvar image = texture.get_image()\nvar data = image.get_data()\n</code>"
	},
	"Noise": {
		"brief_description": "Abstract base class for noise generators.",
		"description": "This class defines the interface for noise generation libraries to inherit from.\nA default get_seamless_noise() implementation is provided for libraries that do not provide seamless noise. This function requests a larger image from get_image(), reverses the quadrants of the image, then uses the strips of extra width to blend over the seams.\nInheriting noise classes can optionally override this function to provide a more optimal algorithm."
	},
	"FastNoiseLite": {
		"brief_description": "Generates noise using the FastNoiseLite library.",
		"description": "This class generates noise using the FastNoiseLite library, which is a collection of several noise algorithms including Cellular, Perlin, Value, and more.\nMost generated noise values are in the range of <code>[-1,1]</code>, however not always. Some of the cellular noise algorithms return results above <code>1</code>."
	},
	"SceneReplicationConfig": {
		"brief_description": "Configuration for properties to synchronize with a [MultiplayerSynchronizer](../MultiplayerSynchronizer).",
		"description": ""
	},
	"SceneMultiplayer": {
		"brief_description": "High-level multiplayer API implementation.",
		"description": "This class is the default implementation of [MultiplayerAPI](../MultiplayerAPI), used to provide multiplayer functionalities in Godot Engine.\nThis implementation supports RPCs via <a href=\"../Node#rpc\">Node.rpc<a> and <a href=\"../Node#rpc_id\">Node.rpc_id<a> and requires <a href=\"../MultiplayerAPI#rpc\">MultiplayerAPI.rpc<a> to be passed a [Node](../Node) (it will fail for other object types).\nThis implementation additionally provide [SceneTree](../SceneTree) replication via the [MultiplayerSpawner](../MultiplayerSpawner) and [MultiplayerSynchronizer](../MultiplayerSynchronizer) nodes, and the [SceneReplicationConfig](../SceneReplicationConfig) resource.\n<b>Note:</b> The high-level multiplayer API protocol is an implementation detail and isn't meant to be used by non-Godot servers. It may change without notice.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"MultiplayerSynchronizer": {
		"brief_description": "Synchronizes properties from the multiplayer authority to the remote peers.",
		"description": "By default, [MultiplayerSynchronizer](../MultiplayerSynchronizer) synchronizes configured properties to all peers.\nVisibility can be handled directly with <a href=\"#set_visibility_for\">set_visibility_for</a> or as-needed with <a href=\"#add_visibility_filter\">add_visibility_filter</a> and <a href=\"#update_visibility\">update_visibility</a>.\n[MultiplayerSpawner](../MultiplayerSpawner)s will handle nodes according to visibility of synchronizers as long as the node at <a href=\"#root_path\">root_path</a> was spawned by one.\nInternally, [MultiplayerSynchronizer](../MultiplayerSynchronizer) uses <a href=\"../MultiplayerAPI#object_configuration_add\">MultiplayerAPI.object_configuration_add<a> to notify synchronization start passing the [Node](../Node) at <a href=\"#root_path\">root_path</a> as the <code>object</code> and itself as the <code>configuration</code>, and uses <a href=\"../MultiplayerAPI#object_configuration_remove\">MultiplayerAPI.object_configuration_remove<a> to notify synchronization end in a similar way."
	},
	"MultiplayerSpawner": {
		"brief_description": "Automatically replicates spawnable nodes from the authority to other multiplayer peers.",
		"description": "Spawnable scenes can be configured in the editor or through code (see <a href=\"#add_spawnable_scene\">add_spawnable_scene</a>).\nAlso supports custom node spawns through <a href=\"#spawn\">spawn</a>, calling <a href=\"#spawn_function\">spawn_function</a> on all peers.\nInternally, [MultiplayerSpawner](../MultiplayerSpawner) uses <a href=\"../MultiplayerAPI#object_configuration_add\">MultiplayerAPI.object_configuration_add<a> to notify spawns passing the spawned node as the <code>object</code> and itself as the <code>configuration</code>, and <a href=\"../MultiplayerAPI#object_configuration_remove\">MultiplayerAPI.object_configuration_remove<a> to notify despawns in a similar way."
	},
	"GodotSharp": {
		"brief_description": "Bridge between Godot and the Mono runtime (Mono-enabled builds only).",
		"description": "This class is a bridge between Godot and the Mono runtime. It exposes several low-level operations and is only available in Mono-enabled Godot builds.\nSee also [CSharpScript](../CSharpScript)."
	},
	"CSharpScript": {
		"brief_description": "A script implemented in the C# programming language (Mono-enabled builds only).",
		"description": "This class represents a C# script. It is the C# equivalent of the [GDScript](../GDScript) class and is only available in Mono-enabled Godot builds.\nSee also [GodotSharp](../GodotSharp)."
	},
	"MobileVRInterface": {
		"brief_description": "Generic mobile VR implementation.",
		"description": "This is a generic mobile VR implementation where you need to provide details about the phone and HMD used. It does not rely on any existing framework. This is the most basic interface we have. For the best effect, you need a mobile phone with a gyroscope and accelerometer.\nNote that even though there is no positional tracking, the camera will assume the headset is at a height of 1.85 meters. You can change this by setting <a href=\"#eye_height\">eye_height</a>.\nYou can initialize this interface as follows:\n<code>\nvar interface = XRServer.find_interface(\"Native mobile\")\nif interface and interface.initialize():\n\tget_viewport().xr = true\n</code>"
	},
	"AudioStreamMP3": {
		"brief_description": "MP3 audio stream driver.",
		"description": "MP3 audio stream driver. See <a href=\"#data\">data</a> if you want to load an MP3 file at run-time."
	},
	"GridMap": {
		"brief_description": "Node for 3D tile-based maps.",
		"description": "GridMap lets you place meshes on a grid interactively. It works both from the editor and from scripts, which can help you create in-game level editors.\nGridMaps use a [MeshLibrary](../MeshLibrary) which contains a list of tiles. Each tile is a mesh with materials plus optional collision and navigation shapes.\nA GridMap contains a collection of cells. Each grid cell refers to a tile in the [MeshLibrary](../MeshLibrary). All cells in the map have the same dimensions.\nInternally, a GridMap is split into a sparse collection of octants for efficient rendering and physics processing. Every octant has the same dimensions and can contain several cells.\n<b>Note:</b> GridMap doesn't extend [VisualInstance3D](../VisualInstance3D) and therefore can't be hidden or cull masked based on <a href=\"../VisualInstance3D#layers\">VisualInstance3D.layers<a>. If you make a light not affect the first layer, the whole GridMap won't be lit by the light in question."
	},
	"GLTFTextureSampler": {
		"brief_description": "Represents a GLTF texture sampler",
		"description": "Represents a texture sampler as defined by the base GLTF spec. Texture samplers in GLTF specify how to sample data from the texture's base image, when rendering the texture on an object."
	},
	"GLTFTexture": {
		"brief_description": "",
		"description": ""
	},
	"GLTFState": {
		"brief_description": "Represents all data of a GLTF file.",
		"description": "Contains all nodes and resources of a GLTF file. This is used by [GLTFDocument](../GLTFDocument) as data storage, which allows [GLTFDocument](../GLTFDocument) and all [GLTFDocumentExtension](../GLTFDocumentExtension) classes to remain stateless.\nGLTFState can be populated by [GLTFDocument](../GLTFDocument) reading a file or by converting a Godot scene. Then the data can either be used to create a Godot scene or save to a GLTF file. The code that converts to/from a Godot scene can be intercepted at arbitrary points by [GLTFDocumentExtension](../GLTFDocumentExtension) classes. This allows for custom data to be stored in the GLTF file or for custom data to be converted to/from Godot nodes."
	},
	"GLTFSpecGloss": {
		"brief_description": "Archived GLTF extension for specular/glossy materials.",
		"description": "KHR_materials_pbrSpecularGlossiness is an archived GLTF extension. This means that it is deprecated and not recommended for new files. However, it is still supported for loading old files."
	},
	"GLTFSkin": {
		"brief_description": "",
		"description": ""
	},
	"GLTFSkeleton": {
		"brief_description": "",
		"description": ""
	},
	"GLTFNode": {
		"brief_description": "GLTF node class.",
		"description": "Represents a GLTF node. GLTF nodes may have names, transforms, children (other GLTF nodes), and more specialized properties (represented by their own classes).\nGLTF nodes generally exist inside of [GLTFState](../GLTFState) which represents all data of a GLTF file. Most of GLTFNode's properties are indices of other data in the GLTF file. You can extend a GLTF node with additional properties by using <a href=\"#get_additional_data\">get_additional_data</a> and <a href=\"#set_additional_data\">set_additional_data</a>."
	},
	"GLTFMesh": {
		"brief_description": "",
		"description": ""
	},
	"GLTFLight": {
		"brief_description": "Represents a GLTF light.",
		"description": "Represents a light as defined by the <code>KHR_lights_punctual</code> GLTF extension."
	},
	"GLTFDocumentExtensionConvertImporterMesh": {
		"brief_description": "",
		"description": ""
	},
	"GLTFDocumentExtension": {
		"brief_description": "[GLTFDocument](../GLTFDocument) extension class.",
		"description": "Extends the functionality of the [GLTFDocument](../GLTFDocument) class by allowing you to run arbitrary code at various stages of GLTF import or export.\nTo use, make a new class extending GLTFDocumentExtension, override any methods you need, make an instance of your class, and register it using <a href=\"../GLTFDocument#register_gltf_document_extension\">GLTFDocument.register_gltf_document_extension<a>.\n<b>Note:</b> Like GLTFDocument itself, all GLTFDocumentExtension classes must be stateless in order to function properly. If you need to store data, use the <code>set_additional_data</code> and <code>get_additional_data</code> methods in [GLTFState](../GLTFState) or [GLTFNode](../GLTFNode)."
	},
	"GLTFDocument": {
		"brief_description": "",
		"description": "Append a glTF2 3d format from a file, buffer or scene and then write to the filesystem, buffer or scene."
	},
	"GLTFCamera": {
		"brief_description": "Represents a GLTF camera.",
		"description": "Represents a camera as defined by the base GLTF spec."
	},
	"GLTFBufferView": {
		"brief_description": "",
		"description": ""
	},
	"GLTFAnimation": {
		"brief_description": "",
		"description": ""
	},
	"GLTFAccessor": {
		"brief_description": "",
		"description": ""
	},
	"EditorSceneFormatImporterGLTF": {
		"brief_description": "",
		"description": ""
	},
	"EditorSceneFormatImporterFBX": {
		"brief_description": "Importer for the <code>.fbx</code> scene file format.",
		"description": "Imports Autodesk FBX 3D scenes by way of converting them to glTF 2.0 using the FBX2glTF command line tool.\nThe location of the FBX2glTF binary is set via the <code>filesystem/import/fbx/fbx2gltf_path</code> editor setting.\nThis importer is only used if [member ProjectSettings.filesystem/import/fbx/enabled] is enabled, otherwise <code>.fbx</code> files present in the project folder are not imported."
	},
	"EditorSceneFormatImporterBlend": {
		"brief_description": "Importer for Blender's <code>.blend</code> scene file format.",
		"description": "Imports Blender scenes in the <code>.blend</code> file format through the glTF 2.0 3D import pipeline. This importer requires Blender to be installed by the user, so that it can be used to export the scene as glTF 2.0.\nThe location of the Blender binary is set via the <code>filesystem/import/blender/blender3_path</code> editor setting.\nThis importer is only used if [member ProjectSettings.filesystem/import/blender/enabled] is enabled, otherwise <code>.blend</code> files present in the project folder are not imported.\nBlend import requires Blender 3.0.\nInternally, the EditorSceneFormatImporterBlend uses the Blender glTF \"Use Original\" mode to reference external textures."
	},
	"GDScript": {
		"brief_description": "A script implemented in the GDScript programming language.",
		"description": "A script implemented in the GDScript programming language. The script extends the functionality of all objects that instantiate it.\n<a href=\"#new\">new</a> creates a new instance of the script. <a href=\"../Object#set_script\">Object.set_script<a> extends an existing object, if that object's class matches one of the script's base classes."
	},
	"@GDScript": {
		"brief_description": "Built-in GDScript functions.",
		"description": "A list of GDScript-specific utility functions and annotations accessible from any script.\nFor the list of the global functions and constants see [@GlobalScope]."
	},
	"ENetPacketPeer": {
		"brief_description": "A wrapper class for an [ENetPeer](http://enet.bespin.org/group__peer.html).",
		"description": "A PacketPeer implementation representing a peer of an [ENetConnection](../ENetConnection).\nThis class cannot be instantiated directly but can be retrieved during <a href=\"../ENetConnection#service\">ENetConnection.service<a> or via <a href=\"../ENetConnection#get_peers\">ENetConnection.get_peers<a>.\n<b>Note:</b> When exporting to Android, make sure to enable the <code>INTERNET</code> permission in the Android export preset before exporting the project or using one-click deploy. Otherwise, network communication of any kind will be blocked by Android."
	},
	"ENetMultiplayerPeer": {
		"brief_description": "A MultiplayerPeer implementation using the [ENet](http://enet.bespin.org/index.html) library.",
		"description": "A MultiplayerPeer implementation that should be passed to <a href=\"../MultiplayerAPI#multiplayer_peer\">MultiplayerAPI.multiplayer_peer<a> after being initialized as either a client, server, or mesh. Events can then be handled by connecting to [MultiplayerAPI](../MultiplayerAPI) signals. See [ENetConnection](../ENetConnection) for more information on the ENet library wrapper.\n<b>Note:</b> ENet only uses UDP, not TCP. When forwarding the server port to make your server accessible on the public Internet, you only need to forward the server port in UDP. You can use the [UPNP](../UPNP) class to try to forward the server port automatically when starting the server."
	},
	"ENetConnection": {
		"brief_description": "A wrapper class for an [ENetHost](http://enet.bespin.org/group__host.html).",
		"description": "ENet's purpose is to provide a relatively thin, simple and robust network communication layer on top of UDP (User Datagram Protocol)."
	},
	"CSGTorus3D": {
		"brief_description": "A CSG Torus shape.",
		"description": "This node allows you to create a torus for use with the CSG system.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	},
	"CSGSphere3D": {
		"brief_description": "A CSG Sphere shape.",
		"description": "This node allows you to create a sphere for use with the CSG system.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	},
	"CSGShape3D": {
		"brief_description": "The CSG base class.",
		"description": "This is the CSG base class that provides CSG operation support to the various CSG nodes in Godot.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	},
	"CSGPrimitive3D": {
		"brief_description": "Base class for CSG primitives.",
		"description": "Parent class for various CSG primitives. It contains code and functionality that is common between them. It cannot be used directly. Instead use one of the various classes that inherit from it.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	},
	"CSGPolygon3D": {
		"brief_description": "Extrudes a 2D polygon shape to create a 3D mesh.",
		"description": "An array of 2D points is extruded to quickly and easily create a variety of 3D meshes. See also [CSGMesh3D](../CSGMesh3D) for using 3D meshes as CSG nodes.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	},
	"CSGMesh3D": {
		"brief_description": "A CSG Mesh shape that uses a mesh resource.",
		"description": "This CSG node allows you to use any mesh resource as a CSG shape, provided it is closed, does not self-intersect, does not contain internal faces and has no edges that connect to more than two faces. See also [CSGPolygon3D](../CSGPolygon3D) for drawing 2D extruded polygons to be used as CSG nodes.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	},
	"CSGCylinder3D": {
		"brief_description": "A CSG Cylinder shape.",
		"description": "This node allows you to create a cylinder (or cone) for use with the CSG system.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	},
	"CSGCombiner3D": {
		"brief_description": "A CSG node that allows you to combine other CSG modifiers.",
		"description": "For complex arrangements of shapes, it is sometimes needed to add structure to your CSG nodes. The CSGCombiner3D node allows you to create this structure. The node encapsulates the result of the CSG operations of its children. In this way, it is possible to do operations on one set of shapes that are children of one CSGCombiner3D node, and a set of separate operations on a second set of shapes that are children of a second CSGCombiner3D node, and then do an operation that takes the two end results as its input to create the final shape.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	},
	"CSGBox3D": {
		"brief_description": "A CSG Box shape.",
		"description": "This node allows you to create a box for use with the CSG system.\n<b>Note:</b> CSG nodes are intended to be used for level prototyping. Creating CSG nodes has a significant CPU cost compared to creating a [MeshInstance3D](../MeshInstance3D) with a [PrimitiveMesh](../PrimitiveMesh). Moving a CSG node within another CSG node also has a significant CPU cost, so it should be avoided during gameplay."
	}
}